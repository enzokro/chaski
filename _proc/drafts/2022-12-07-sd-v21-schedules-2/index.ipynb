{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "author: enzokro\n",
    "badges: true\n",
    "categories:\n",
    "- diffusion\n",
    "- assifier-free guidance\n",
    "- deep learning\n",
    "date: 12/10/2022\n",
    "image: better_village.png\n",
    "jupyter: python3\n",
    "output-file: index.html\n",
    "title: Introducion dynamic Classifier-free Guidance for Diffusion Models\n",
    "toc: true\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714710df-5448-41d1-a36e-8b21c327bbf1",
   "metadata": {},
   "source": [
    "> Making Classifier-free Guidance a dynamic process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5799b3-e47f-419d-b77a-3387b8108dae",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "070ea001-ffc0-4455-8bad-09cacd35dcc5",
   "metadata": {},
   "source": [
    "This notebook introduces dynamic Classifier-free Guidance (`dCFG`) for diffusion models.  \n",
    "\n",
    "`dCFG` makes it so that Classifier-free Guidance changes at each timestep in the diffusion process. We cover why this might be important in the section below.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ebd6e0ec",
   "metadata": {},
   "source": [
    "## Previous work on `dCFG`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e800943a",
   "metadata": {},
   "source": [
    "We previously ran an [exploratory series](https://enzokro.dev/blog/posts/2022-11-26-guidance-expts-8) on `dCFG` on the `v1` Stable Diffusion models. Then, we made a short introduction notebook on `dCFG` for the [Stable Diffusion v2.0 model](https://enzokro.dev/blog/posts/2022-11-28-sd-v2-schedules-1/).  \n",
    "\n",
    "With the release of the new and improved [Stable Diffusion v2-1](https://huggingface.co/stabilityai/stable-diffusion-2-1) model, it seems like a great time to take a step back, recap what we've learned so far, and put our approach on more solid footing.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd83ef5",
   "metadata": {},
   "source": [
    ":::: {.callout-note}  \n",
    "There are similar dynamic guidance approaches in the Imagen paper, and in applications for Text-to-Speech with diffusion.  \n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415dc872-1017-4acd-84ca-2887bce32b61",
   "metadata": {},
   "source": [
    "# Overview of Guidance for Diffusion Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca19d6c7-7b31-44b2-9546-994d53ad7ede",
   "metadata": {},
   "source": [
    "This section goes over how to generate images based on a known, given input. We shortly recap the different ways of generating images.  \n",
    "\n",
    "Specifically, we review unconditional image generation, then move on to classifier-guided generation, and finally close with classifier-free generation. This represents how people have gone from generating random photos to the incredible diffusion images floating around the web.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0cd981-54e3-4a0a-a5c8-89d5b7e488d7",
   "metadata": {},
   "source": [
    "## Unconditioned Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cc29b4-4442-4fad-9522-5538d2cc7283",
   "metadata": {},
   "source": [
    "Unconditional image generation is the bedrock of generative models. Here, we are given a collection of training images. The goal is to learn and model the probability distribution that generated these images. If we can learn or estimate this distribution, then we can sample from it to create brand new images.  \n",
    "\n",
    "Ideally, we would have a grand Oracle that models the distribution of every single possible image. This Oracle would then, in theory, be able to generate absolutely any image we can think of. Unfortunately creating this Oracle would require an almost infinite amount of data, assuming we could even gather it in the first place (we can't). The best we can do then is to gather a subset of the images we care the most about. For example, if we are trying to generate outdoor landscapes, we could gather images of nature. The more images we gather the better.  \n",
    "\n",
    "The goal is to make our training image set large and diverse enough to represent the topic or subject (aka distribution) that we want to generate. Once we have this training image set, there is a wide range of Machine Learning approaches to both model and sample from its distribution. The most popular generation approaches are detailed in this [excellent blog post](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/) by Lilian Weng. These approaches include:  \n",
    "\n",
    "- GANs  \n",
    "- Flow-based models  \n",
    "- Variational Auto-Encoders  \n",
    "- Diffusion models  \n",
    "\n",
    "Assuming our training set is large and representative enough, any of these approaches can learn to model and sample from its data-generating distribution.  \n",
    "\n",
    "This is fantastic if we want to create new styles or variants of our data. For example, if the training data was made of fashion styles, then we could generate new or unique trends. Or if the data was some sort of asset like character sprites or objects in a video game, we could generate new and creative items.  \n",
    "\n",
    "However, we often want to create and generate specific outputs. If you've used any online Stable Diffusion APIs, that's a perfect example. We want the model to specifically generate an output based on the given input text. Or, even tying it to our earlier examples, maybe we want to create a new fashion trend that's inspired by specific styles. Likewise for the video game assets, maybe we can to create a new create that's a blend of two existing monsters. This is where **guidance** comes into play. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bff1b5-f3e6-4fd5-892e-aafaf74f721b",
   "metadata": {},
   "source": [
    "## Classifier Guidance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b3e5a4-eedc-4dda-b064-8a6b910be9de",
   "metadata": {},
   "source": [
    "## Classifier-free Guidance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68724eb-d70d-4480-b395-388f2d143dcb",
   "metadata": {},
   "source": [
    "### Making it dynamic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe2b1d1-cef3-46eb-bd7c-accef11ba40c",
   "metadata": {},
   "source": [
    "## What does `dCFG` actually do?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9ea840-32dc-406a-ac6a-2d7012f3b2e8",
   "metadata": {},
   "source": [
    "# Python imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b43dae-d6fb-41cf-b04c-256350bd2f2c",
   "metadata": {},
   "source": [
    "We start with a few python imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90816aeb-943f-4e63-a492-529fae93496d",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mload_ext\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mautoreload\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mautoreload\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m2\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m      6\u001b[0m tf\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39msetLevel(\u001b[39m'\u001b[39m\u001b[39mINFO\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| include: false\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea1e75a0-0d64-436f-b9d8-d641393dca3a",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import random\n",
    "from typing import Callable, List, Dict\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# runs dCFG\n",
    "from dynamic_cfg.guidance import DynamicCFG\n",
    "\n",
    "# to load Stable Diffusion pipelines\n",
    "from dynamic_cfg.diffusion import MinimalDiffusion\n",
    "# to plot generated images\n",
    "from dynamic_cfg.utils import show_image, image_grid, plot_grid\n",
    "\n",
    "# Default schedule parameters from the blog post\n",
    "from dynamic_cfg.schedules import DEFAULT_SCHED_PARAMS, DEFAULT_T_PARAMS, get_cos_sched"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781bfabc-3659-4372-b876-b47f6ef8c37c",
   "metadata": {},
   "source": [
    "## Seed for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a85966-1de8-472a-80c7-458ef0a3b78e",
   "metadata": {},
   "source": [
    "`seed_everything` makes sure that the results are reproducible across notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58d6c482-17da-41df-9605-4759b3281944",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# set the seed for rng\n",
    "SEED = 2863311530\n",
    "def seed_everything(seed: int):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# for sampling the initial, noisy latents\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a155d7-65f5-4ac7-be83-27755827bb84",
   "metadata": {},
   "source": [
    "# Text prompt for image generations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ec08b7-205e-4a3f-be1a-e74cf0e3dd76",
   "metadata": {},
   "source": [
    "Negative prompts appear to be very helpful in `v2`. At least, more helpful than they were for `v1.x` models.  \n",
    "\n",
    "Below, we also borrow a prompt and negative-prompt format that's going around the Stable Diffusion discord. It seems to be a good starting point as the community figures out the new prompt structures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9620a51c-3961-4c75-93af-9121d3938b62",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# text prompt for image generations\n",
    "prompt = \"a futuristic metropolis collapsed by the beach on a caribbean island, dystopia, apocalyptic, sci-fi, disaster, art station, misery, cinematic, hdri, matte painting, concept art, soft render, highly detailed, cgsociety, octane render, trending on artstation, architectural HQ, 4k\"\n",
    "# prompt = \"One Second Before Awakening From a Dream Provoked by the Flight of a Bee Around a Pomegranate\"\n",
    "\n",
    "# a good negative prompt\n",
    "# neg_prompt = \"!!!!!!text!!!!!!, watermark, bad art, deformed, blurry, strange colours, sketch, lacklustre, repetitive, cropped, lowres, deformed, old, childish\"\n",
    "neg_prompt = \"(ugly, cartoon, bad anatomy, bad art, frame, deformed, disfigured, extra limbs, text, meme, low quality, mutated, ordinary, overexposed, pixelated, poorly drawn, signature, thumbnail, too dark, too light, unattractive, useless, watermark, writing, cropped:1.1)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64df2608-9ef4-4469-a45e-c4cc59e7eff5",
   "metadata": {},
   "source": [
    "# Image and Sampler parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203f4053-98c5-4c06-a589-410793cd083c",
   "metadata": {},
   "source": [
    "The images will be generated over $30$ diffusion steps. It will be a rather large `1024 x 1024` output.   \n",
    "\n",
    "We are using the `DPM++ SDE Karras` sampler with 30 steps. This sampler seems to be working the best for high-quality outputs at the moment. The `2m Karras` schedule wins out on speed, however.  \n",
    "\n",
    "If the image is too large or the generation is too slow on your machine, I'd suggest bumping down to a `768 x 768` resolution and using the `k_dpmpp_2m` sampler instead.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb50e210-14ed-43a9-a44e-53bff5858db2",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# number of diffusion steps\n",
    "num_steps = 50    \n",
    "\n",
    "# image dimensions\n",
    "height = 768 # 768\n",
    "width  = 768 # 768\n",
    "\n",
    "# group the arguments for the generation function\n",
    "gen_kwargs = {\n",
    "    'height': height,\n",
    "    'width': width, \n",
    "    'negative_prompt': neg_prompt, \n",
    "    'num_steps': num_steps,\n",
    "}\n",
    "\n",
    "# set the k-diffusion scheduler\n",
    "sampler_kls = 'k_dpmpp_sde' # 'dpm_multi'\n",
    "\n",
    "# whether to use the Karras sigma schedule\n",
    "use_karras_sigmas = True\n",
    "\n",
    "# group scheduler arguments\n",
    "sampler_kwargs = {\n",
    "    'scheduler_kls': sampler_kls,\n",
    "    'use_karras_sigmas': use_karras_sigmas,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031502b3-523a-4ee8-a6c1-4a4013f5cc43",
   "metadata": {},
   "source": [
    "# Gathering Stable Diffusion models\n",
    "\n",
    "For now, the `k_diffusion` integration is only working with the full, `768-v` model. The plan is to eventually support the base model as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c5e34b-5be8-4579-b4cb-769f49aa9386",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# to load Stable Diffusion v2-1 with our chosen sampler\n",
    "model_name = 'stabilityai/stable-diffusion-2-1'\n",
    "model_kwargs = {'unet_attn_slice': True,\n",
    "                'schedule_kwargs': sampler_kwargs,}\n",
    "\n",
    "# device and precision for the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dtype = torch.float16\n",
    "revision = \"fp16\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680d6a28-697e-4a04-a481-245304795cae",
   "metadata": {},
   "source": [
    "# Creating Guidance schedules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d4ff54-b17d-426e-99c8-7c83054e14fd",
   "metadata": {},
   "source": [
    "### Schedule parameters  \n",
    "\n",
    "Given how much the prompts have changed in v2, we are back in exploration territory as to what are the best parameters. Exciting times!  \n",
    "\n",
    "Overall, it seems that the Guidance range is broader in v2. Folks are getting good results with low CFGs (3-5) or with higher values (9+). This is likely highly dependent on both the prompt and negative-prompt. We should know more as the stability.ai team releases their guides and tips.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579ffdad-b7f1-48ab-ab06-4eba61ee5db8",
   "metadata": {},
   "source": [
    "The functions below quickly build different Guidance schedules. They are also re-used from the [previous notebooks](https://enzokro.dev/blog/posts/2022-11-26-guidance-expts-8/https://enzokro.dev/blog/posts/2022-11-26-guidance-expts-8/). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc338868-d0a5-458b-a265-faca20b8b46d",
   "metadata": {},
   "source": [
    "## Static baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95548492-c486-40ca-8e74-3572cc4a7163",
   "metadata": {},
   "source": [
    "First we create the constant, baseline Guidances.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bfed55-97bf-4d4f-99af-090174e6b490",
   "metadata": {},
   "source": [
    "## Improving the baseline with scheduled Guidance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ded516-78f4-44da-a2c0-e5fd904eef42",
   "metadata": {},
   "source": [
    "Now we build the most promising dynamic schedule: `Inverse kDecay` with a fast warmup.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a6a95c-307c-4fc4-a481-16cb9581a737",
   "metadata": {},
   "source": [
    "# Function to run the experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb60f6c3-a3a7-4a21-9519-3dccd3259178",
   "metadata": {},
   "source": [
    "The code below loads the v2 Stable Diffusion model. It's also our harness to easily run many, different experiments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941fbfca-e503-4207-9a41-d23fb89695af",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "def load_sd_model(model_name, device, dtype, revision, model_kwargs={}):\n",
    "    '''Loads the given `model_name` Stable Diffusion in `dtype` precision.  \n",
    "    \n",
    "    The model is placed on the `device` hardware. \n",
    "    Optional `model_kwargs` are passed to the model's load function.\n",
    "    '''\n",
    "    pipeline = MinimalDiffusion(model_name, device, dtype, revision, **model_kwargs)\n",
    "    pipeline.load()\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "# load the current Diffusion model\n",
    "pipeline = load_sd_model(model_name, device, dtype, revision, model_kwargs=model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc74e1c7",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "def run(pipeline, prompt, cfg_runs, gen_kwargs={},\n",
    "        norm_name='', show_each=False, test_run=False):\n",
    "    \"\"\"Runs a dynamic Classifier-free Guidance experiment. \n",
    "    \n",
    "    Generates an image for the text `prompt` given all the values in `schedules`.\n",
    "    Uses a Guidance Transformation class from the `cf_guidance` library.  \n",
    "    Stores the output images with a matching title for plotting. \n",
    "    Optionally shows each image as its generated.\n",
    "    If `test_run` is true, it runs a single schedule for testing. \n",
    "    \"\"\"\n",
    "    # store generated images and their title (the experiment name)\n",
    "    images, titles = [], []\n",
    "    \n",
    "    # optionally run a single test schedule\n",
    "    if test_run:\n",
    "        print(f'Running a single schedule for testing.')\n",
    "        cfg_runs = cfg_runs[:1]\n",
    "        \n",
    "    # run all schedule experiments\n",
    "    for i,cfg in enumerate(cfg_runs):\n",
    "        \n",
    "        # parse out the title for the current run\n",
    "        cur_title  = cfg['title']\n",
    "        titles.append(cur_title)\n",
    "        \n",
    "        # create the guidance transformation \n",
    "        sched_name = cfg['sched_name']\n",
    "        norm_name = cfg['norm_name']\n",
    "        guide_tfm = DynamicCFG(norm_name, sched_name)\n",
    "        # update its schedule parameters\n",
    "        guide_tfm.update_sched_kwargs(cfg['params'])\n",
    "        \n",
    "        print(f'Running generation [{i+1} of {len(cfg)}]: {cur_title}...')\n",
    "        with torch.no_grad(), torch.autocast(device):\n",
    "            img = pipeline.generate(prompt, dynamic_cfg=guide_tfm, **gen_kwargs)\n",
    "\n",
    "        # store the generated image\n",
    "        images.append(img)\n",
    "        # optionally plot each generated image\n",
    "        if show_each:\n",
    "            show_image(img, scale=1)\n",
    "            \n",
    "    print('Done.')\n",
    "    return {'images': images,\n",
    "            'titles': titles}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cb8c5f-4249-4ae5-ba7c-a0e9a05b6deb",
   "metadata": {},
   "source": [
    "# Generating the images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c83e662-8430-4837-8a3b-71ab5465368c",
   "metadata": {},
   "source": [
    "We put together all of the pieces above to generate images with Stable Diffusion v2. Both with our static baseline guidances, and the `Inverse-kDecay` schedules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d261b6aa-1ce2-46e6-a9fd-d0141dc62a63",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: {'model_name': 'stabilityai/stable-diffusion-2-1', 'model_kwargs': {'unet_attn_slice': True, 'schedule_kwargs': {'scheduler_kls': 'k_dpmpp_sde', 'use_karras_sigmas': True}}}\n",
      "Generation kwargs: {'height': 768, 'width': 768, 'negative_prompt': '(ugly, cartoon, bad anatomy, bad art, frame, deformed, disfigured, extra limbs, text, meme, low quality, mutated, ordinary, overexposed, pixelated, poorly drawn, signature, thumbnail, too dark, too light, unattractive, useless, watermark, writing, cropped:1.1)', 'num_steps': 50}\n",
      "Using prompt: a futuristic metropolis collapsed by the beach on a caribbean island, dystopia, apocalyptic, sci-fi, disaster, art station, misery, cinematic, hdri, matte painting, concept art, soft render, highly detailed, cgsociety, octane render, trending on artstation, architectural HQ, 4k\n",
      "Enabling default unet attention slicing.\n",
      "Using k-diffusion sampler: <dynamic_cfg.kdiff.DPMPPSDESampler object at 0x7fe6dde93f40>\n",
      "Using Guidance Normalization: no_norm\n",
      "Running experiment [1 of 1]: Param: \"max_val\", val=8...\n",
      "Using negative prompt: (ugly, cartoon, bad anatomy, bad art, frame, deformed, disfigured, extra limbs, text, meme, low quality, mutated, ordinary, overexposed, pixelated, poorly drawn, signature, thumbnail, too dark, too light, unattractive, useless, watermark, writing, cropped:1.1)\n",
      "Using Karras sigma schedule\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "503bb6ef64714b60b6b67404b8d4b22e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Using Guidance Normalization: no_norm\n",
      "Running experiment [1 of 2]: Param: \"k_decay\", val=0.1...\n",
      "Using negative prompt: (ugly, cartoon, bad anatomy, bad art, frame, deformed, disfigured, extra limbs, text, meme, low quality, mutated, ordinary, overexposed, pixelated, poorly drawn, signature, thumbnail, too dark, too light, unattractive, useless, watermark, writing, cropped:1.1)\n",
      "Using Karras sigma schedule\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_4262/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">809599653.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">29</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_4262/809599653.py'</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_4262/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1879977925.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">38</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">run</span>                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_4262/1879977925.py'</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/paperspace/repos/dynamic_cfg/dynamic_cfg/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">diffusion.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">193</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">generate</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">190 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">191 │   │   # use the k-diffusion library</span>                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">192 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.use_k_diffusion:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>193 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>latents = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.k_sampling_loop(num_steps, text, uncond, latents)               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">194 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">195 │   │   # use the diffusers scheduler loop</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">196 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/paperspace/repos/dynamic_cfg/dynamic_cfg/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">diffusion.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">241</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">k_sampling_loop</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">238 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.sampler.cv_denoiser.log_sigmas = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.sampler.cv_denoiser.log_sigmas.to(lat   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">239 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">240 │   │   # sample with k_diffusion</span>                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>241 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>latents = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.sampler.sample(                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">242 │   │   │   </span>num_steps=num_steps,                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">243 │   │   │   </span>initial_latent=latents,                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">244 │   │   │   </span>positive_conditioning=text,                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/paperspace/repos/dynamic_cfg/dynamic_cfg/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">kdiff.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">213</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">sample</span>                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">210 │   │   │   </span>sigmas = k_sampling.get_sigmas_karras(n=num_steps, sigma_min=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.1</span>, sigma_max=   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">211 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">212 │   │   │   </span>sigmas = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.cv_denoiser.get_sigmas(num_steps)[t_start:]                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>213 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>dynamic_cfg.set_timesteps(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(sigmas))                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">214 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">215 │   │   # if our number of steps is zero, just return the initial latent</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">216 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> sigmas.nelement() == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>:                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/paperspace/repos/dynamic_cfg/dynamic_cfg/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">guidance.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">47</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">set_timesteps</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">44 │   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">45 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">set_timesteps</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, num_steps):                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">46 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scheduler.set_num_steps(num_steps)                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>47 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.scheduler.set_guidance_schedule()                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">48 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/paperspace/repos/dynamic_cfg/dynamic_cfg/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">schedules.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">151</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">set_guidance_schedule</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">148 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">149 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">class</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; text-decoration: underline\">CosGuidanceSchedule</span>(GuidanceSchedule):                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">150 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">set_guidance_schedule</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, invert=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>):                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>151 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>sched = get_cos_sched(**<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.sched_kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">152 │   │   # invert k-decay schedules when k is less than one</span>                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">153 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.sched_kwargs[<span style=\"color: #808000; text-decoration-color: #808000\">'k_decay'</span>] &lt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.sched_kwargs.get(<span style=\"color: #808000; text-decoration-color: #808000\">'invert_k_sched'</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">154 │   │   │   </span>sched = [<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.sched_kwargs[<span style=\"color: #808000; text-decoration-color: #808000\">'max_val'</span>] - g + <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.sched_kwargs[<span style=\"color: #808000; text-decoration-color: #808000\">'min_val'</span>] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">get_cos_sched</span><span style=\"font-weight: bold\">()</span> got an unexpected keyword argument <span style=\"color: #008000; text-decoration-color: #008000\">'invert_k_sched'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_4262/\u001b[0m\u001b[1;33m809599653.py\u001b[0m:\u001b[94m29\u001b[0m in \u001b[92m<module>\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_4262/809599653.py'\u001b[0m                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_4262/\u001b[0m\u001b[1;33m1879977925.py\u001b[0m:\u001b[94m38\u001b[0m in \u001b[92mrun\u001b[0m                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_4262/1879977925.py'\u001b[0m                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/paperspace/repos/dynamic_cfg/dynamic_cfg/\u001b[0m\u001b[1;33mdiffusion.py\u001b[0m:\u001b[94m193\u001b[0m in \u001b[92mgenerate\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m190 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m191 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# use the k-diffusion library\u001b[0m                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m192 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.use_k_diffusion:                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m193 \u001b[2m│   │   │   \u001b[0mlatents = \u001b[96mself\u001b[0m.k_sampling_loop(num_steps, text, uncond, latents)               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m194 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m195 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# use the diffusers scheduler loop\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m196 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/paperspace/repos/dynamic_cfg/dynamic_cfg/\u001b[0m\u001b[1;33mdiffusion.py\u001b[0m:\u001b[94m241\u001b[0m in \u001b[92mk_sampling_loop\u001b[0m               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m238 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.sampler.cv_denoiser.log_sigmas = \u001b[96mself\u001b[0m.sampler.cv_denoiser.log_sigmas.to(lat   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m239 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m240 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# sample with k_diffusion\u001b[0m                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m241 \u001b[2m│   │   \u001b[0mlatents = \u001b[96mself\u001b[0m.sampler.sample(                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m242 \u001b[0m\u001b[2m│   │   │   \u001b[0mnum_steps=num_steps,                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m243 \u001b[0m\u001b[2m│   │   │   \u001b[0minitial_latent=latents,                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m244 \u001b[0m\u001b[2m│   │   │   \u001b[0mpositive_conditioning=text,                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/paperspace/repos/dynamic_cfg/dynamic_cfg/\u001b[0m\u001b[1;33mkdiff.py\u001b[0m:\u001b[94m213\u001b[0m in \u001b[92msample\u001b[0m                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m210 \u001b[0m\u001b[2m│   │   │   \u001b[0msigmas = k_sampling.get_sigmas_karras(n=num_steps, sigma_min=\u001b[94m0.1\u001b[0m, sigma_max=   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m211 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m212 \u001b[0m\u001b[2m│   │   │   \u001b[0msigmas = \u001b[96mself\u001b[0m.cv_denoiser.get_sigmas(num_steps)[t_start:]                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m213 \u001b[2m│   │   \u001b[0mdynamic_cfg.set_timesteps(\u001b[96mlen\u001b[0m(sigmas))                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m214 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m215 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# if our number of steps is zero, just return the initial latent\u001b[0m                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m216 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m sigmas.nelement() == \u001b[94m0\u001b[0m:                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/paperspace/repos/dynamic_cfg/dynamic_cfg/\u001b[0m\u001b[1;33mguidance.py\u001b[0m:\u001b[94m47\u001b[0m in \u001b[92mset_timesteps\u001b[0m                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m44 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m45 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mset_timesteps\u001b[0m(\u001b[96mself\u001b[0m, num_steps):                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m46 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.scheduler.set_num_steps(num_steps)                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m47 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.scheduler.set_guidance_schedule()                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m48 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/paperspace/repos/dynamic_cfg/dynamic_cfg/\u001b[0m\u001b[1;33mschedules.py\u001b[0m:\u001b[94m151\u001b[0m in \u001b[92mset_guidance_schedule\u001b[0m         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m148 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m149 \u001b[0m\u001b[94mclass\u001b[0m \u001b[4;92mCosGuidanceSchedule\u001b[0m(GuidanceSchedule):                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m150 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mset_guidance_schedule\u001b[0m(\u001b[96mself\u001b[0m, invert=\u001b[94mTrue\u001b[0m):                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m151 \u001b[2m│   │   \u001b[0msched = get_cos_sched(**\u001b[96mself\u001b[0m.sched_kwargs)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m152 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# invert k-decay schedules when k is less than one\u001b[0m                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m153 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m (\u001b[96mself\u001b[0m.sched_kwargs[\u001b[33m'\u001b[0m\u001b[33mk_decay\u001b[0m\u001b[33m'\u001b[0m] < \u001b[94m1\u001b[0m) \u001b[95mand\u001b[0m \u001b[96mself\u001b[0m.sched_kwargs.get(\u001b[33m'\u001b[0m\u001b[33minvert_k_sched\u001b[0m\u001b[33m'\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m154 \u001b[0m\u001b[2m│   │   │   \u001b[0msched = [\u001b[96mself\u001b[0m.sched_kwargs[\u001b[33m'\u001b[0m\u001b[33mmax_val\u001b[0m\u001b[33m'\u001b[0m] - g + \u001b[96mself\u001b[0m.sched_kwargs[\u001b[33m'\u001b[0m\u001b[33mmin_val\u001b[0m\u001b[33m'\u001b[0m] \u001b[94mfor\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0m\u001b[1;35mget_cos_sched\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m got an unexpected keyword argument \u001b[32m'invert_k_sched'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# stores the generated images\n",
    "outputs = {}\n",
    "\n",
    "# schedules to run\n",
    "baseline_expts = [\n",
    "    {'sched_name': 'constant',\n",
    "     'title': 'constant_guidance',\n",
    "     'params': {'max_val': 9},\n",
    "     'norm_name': 'no_norm',\n",
    "    }\n",
    "]\n",
    "\n",
    "# different schedules\n",
    "sched_expts = [\n",
    "\n",
    "    {'sched_name': 'linear',\n",
    "     'title': 'linear_guide_minVal_5',\n",
    "     'params': {'min_val': 5},\n",
    "     'norm_name': 'no_norm',\n",
    "    },\n",
    "\n",
    "\n",
    "    {'sched_name': 'cosine',\n",
    "     'title': 'cos_guide_kdecay_01',\n",
    "     'params': {'k_decay': 0.1, 'min_val': 5},\n",
    "     'norm_name': 'no_norm',\n",
    "    },\n",
    "\n",
    "\n",
    "    {'sched_name': 'cosine',\n",
    "     'title': 'cos_guide_kdecay_02',\n",
    "     'params': {'k_decay': 0.2, 'min_val': 5},\n",
    "     'norm_name': 'no_norm',\n",
    "    },\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "# view some info about the run\n",
    "print(f'Running model: {model_name}')\n",
    "print(f'Generation kwargs: {gen_kwargs}')\n",
    "print(f'Using prompt: {prompt}')\n",
    "\n",
    "\n",
    "# run the baseline, static Guidance\n",
    "baseline_res = run(pipeline, prompt, baseline_expts, gen_kwargs=gen_kwargs)\n",
    "outputs[(model_name,'baseline')] = baseline_res\n",
    "\n",
    "# run the scheduled Guidances\n",
    "sched_res = run(pipeline, prompt, sched_expts, gen_kwargs=gen_kwargs)\n",
    "outputs[(model_name,'scheduled')] = sched_res\n",
    "\n",
    "                            \n",
    "# cleanup GPU memory\n",
    "pipeline = None\n",
    "gc.collect()\n",
    "del pipeline\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fd42cf-5abd-4fe4-8f0a-d25669cc8dc5",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aad0d5-a319-4818-8904-70a9370ff6d7",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "# names of all the models we tried\n",
    "model_names = [\n",
    "    'stabilityai/stable-diffusion-2-1',\n",
    "    \n",
    "    ##TODO: support base model\n",
    "    # 'stabilityai/stable-diffusion-2-base',\n",
    "]\n",
    "\n",
    "# plot dimensions\n",
    "plot_height, plot_width = height, width\n",
    "# for the grid layout\n",
    "num_scheds = 3\n",
    "num_rows = 1\n",
    "\n",
    "def plot_all_results(model_name):\n",
    "    types = [\n",
    "        'baseline', \n",
    "        'scheduled',\n",
    "    ]\n",
    "    mres = [(outputs[(model_name,t)], t) for t in types]\n",
    "    for i in range(num_scheds):\n",
    "        image_grid(\n",
    "            [mres[0][0]['images'][0]] + [o[0]['images'][i] for o in mres[1:]], \n",
    "            title=[mres[0][0]['titles'][0]] + [f\"{o[0]['titles'][i]}_{o[1]}\" for o in mres[1:]],\n",
    "            rows=num_rows, width=plot_width, height=plot_height\n",
    "        )\n",
    "        plt.suptitle(f'Model: {model_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c1416f-69ac-42db-9bc8-0cbf183db9bb",
   "metadata": {},
   "source": [
    "## Stable Diffusion v2 images "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41777cc-c6ff-4e66-be67-45252c1c2c0d",
   "metadata": {},
   "source": [
    "Here we plot all of the generated images.  \n",
    "\n",
    "The image on the left is the baseline with a static, constant Guidance.\\\n",
    "The images on the right are the improvements with Guidance scheduling. Specifically, using the `Inverse-kDecay` cosine schedules with different values of `k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71ff8fe-888e-4e9c-aad2-c1268ed3965c",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "plot_all_results(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7d3315-4ade-41ff-9ba9-59d18e025768",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c86759-f34b-49d7-9555-b40970e0b414",
   "metadata": {},
   "source": [
    "In this notebook we checked whether scheduling the Classifier-free Guidance improves the images generated by Stable Diffusion v2.  \n",
    "\n",
    "At first glance, it seems that scheduling still helps! The scheduled generations have a lot more buildings and details. They seem to also better follow the prompt.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "min_diff_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4a7d19145a48f2175a23832ef860f30fd1465e55c0bdf75b01b648b330f7c6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
