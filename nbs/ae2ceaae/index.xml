<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>chaski</title>
<link>https://enzokro.dev/index.html</link>
<atom:link href="https://enzokro.dev/index.xml" rel="self" type="application/rss+xml"/>
<description>Enzo&#39;s personal Blog.</description>
<generator>quarto-1.2.269</generator>
<lastBuildDate>Sat, 26 Nov 2022 00:00:00 GMT</lastBuildDate>
<item>
  <title>Classifier-free Guidance with Cosine Schedules Pt. 6</title>
  <dc:creator>enzokro</dc:creator>
  <link>https://enzokro.dev/blog/posts/2022-11-25-guidance-expts-7/index.html</link>
  <description><![CDATA[ 



<blockquote class="blockquote">
<p>Combining the best schedules and normalizations so far.</p>
</blockquote>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>This notebook is Part 6 in a <a href="https://enzokro.dev/blog/posts/2022-11-15-guidance-expts-5/">series</a> on dynamic Classifier-free Guidance. It combines the best schedules and normalizations we’ve found so far.</p>
<section id="recap-of-parts-1-5" class="level2">
<h2 class="anchored" data-anchor-id="recap-of-parts-1-5">Recap of Parts 1-5</h2>
<p>The first five parts explored how to turn Classifier-free Guidance into a dynamic process. We found a good set of schedules and normalizations that seem to improve the output of diffusion image models.</p>
</section>
<section id="part-6-putting-it-all-together" class="level2">
<h2 class="anchored" data-anchor-id="part-6-putting-it-all-together">Part 6: Putting it all together</h2>
<p>Part 6 brings together our best approaches so far. Specifically, it explores the following schedules:</p>
<ul>
<li><code>kDecay</code> with large <img src="https://latex.codecogs.com/png.latex?k"> values.<br>
</li>
<li><code>Inverse kDecay</code> with small <img src="https://latex.codecogs.com/png.latex?k"> values.</li>
</ul>
<p>On all three Guidance normalizations:</p>
<ul>
<li><code>Prediction Normalization</code><br>
</li>
<li><code>T-Normalization</code><br>
</li>
<li><code>Full Normalization</code></li>
</ul>
</section>
</section>
<section id="python-imports" class="level1">
<h1>Python imports</h1>
<p>We start with a few python imports.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> os</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> random</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">from</span> functools <span class="im" style="color: #00769E;">import</span> partial</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-6"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb1-7"><span class="im" style="color: #00769E;">import</span> matplotlib.colors <span class="im" style="color: #00769E;">as</span> mcolors</span></code></pre></div>
</div>
<section id="seed-for-reproducibility" class="level2">
<h2 class="anchored" data-anchor-id="seed-for-reproducibility">Seed for reproducibility</h2>
<p><code>seed_everything</code> makes sure that the results are reproducible across notebooks.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;"># set the seed and pseudo random number generator</span></span>
<span id="cb2-2">SEED <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1024</span></span>
<span id="cb2-3"><span class="kw" style="color: #003B4F;">def</span> seed_everything(seed):</span>
<span id="cb2-4">    random.seed(seed)</span>
<span id="cb2-5">    os.environ[<span class="st" style="color: #20794D;">'PYTHONHASHSEED'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">str</span>(seed)</span>
<span id="cb2-6">    np.random.seed(seed)</span>
<span id="cb2-7">    generator <span class="op" style="color: #5E5E5E;">=</span> torch.manual_seed(seed)</span>
<span id="cb2-8">    torch.backends.cudnn.deterministic <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">True</span></span>
<span id="cb2-9">    torch.backends.cudnn.benchmark <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">False</span></span>
<span id="cb2-10">    <span class="cf" style="color: #003B4F;">return</span> generator</span>
<span id="cb2-11"></span>
<span id="cb2-12"><span class="co" style="color: #5E5E5E;"># for sampling the initial, noisy latents</span></span>
<span id="cb2-13">generator <span class="op" style="color: #5E5E5E;">=</span> seed_everything(SEED)</span></code></pre></div>
</div>
</section>
</section>
<section id="cosine-schedules-with-k-decay" class="level1">
<h1>Cosine schedules with k-decay</h1>
<p>We create the schedules with different <img src="https://latex.codecogs.com/png.latex?k"> values using the <code>cf_guidance</code> library.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;"># helpers to create cosine schedules</span></span>
<span id="cb3-2"><span class="im" style="color: #00769E;">from</span> cf_guidance.schedules  <span class="im" style="color: #00769E;">import</span> get_cos_sched</span>
<span id="cb3-3"></span>
<span id="cb3-4"><span class="co" style="color: #5E5E5E;"># normalizations for classifier-free guidance</span></span>
<span id="cb3-5"><span class="im" style="color: #00769E;">from</span> cf_guidance.transforms <span class="im" style="color: #00769E;">import</span> GuidanceTfm, BaseNormGuidance, TNormGuidance, FullNormGuidance</span></code></pre></div>
</div>
<p>For the other schedule parameters, we keep the <a href="https://enzokro.dev/blog/posts/2022-11-20-guidance-expts-2/#default-schedule-parameters">same values</a> from the rest of the series. The functions below are also shared with previous notebooks.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;"># Default schedule parameters from the blog post</span></span>
<span id="cb4-2"><span class="co" style="color: #5E5E5E;">######################################</span></span>
<span id="cb4-3">max_val           <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">7.5</span>   <span class="co" style="color: #5E5E5E;"># guidance scaling value</span></span>
<span id="cb4-4">min_val           <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">1.</span>    <span class="co" style="color: #5E5E5E;"># minimum guidance scaling</span></span>
<span id="cb4-5">num_steps         <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">50</span>    <span class="co" style="color: #5E5E5E;"># number of diffusion steps</span></span>
<span id="cb4-6">num_warmup_steps  <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span>     <span class="co" style="color: #5E5E5E;"># number of warmup steps</span></span>
<span id="cb4-7">warmup_init_val   <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span>     <span class="co" style="color: #5E5E5E;"># the intial warmup value</span></span>
<span id="cb4-8">num_cycles        <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.5</span>   <span class="co" style="color: #5E5E5E;"># number of cosine cycles</span></span>
<span id="cb4-9">k_decay           <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span>     <span class="co" style="color: #5E5E5E;"># k-decay for cosine curve scaling </span></span>
<span id="cb4-10"></span>
<span id="cb4-11"><span class="co" style="color: #5E5E5E;"># smaller values for T-Norm and FullNorm</span></span>
<span id="cb4-12">max_T <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.2</span></span>
<span id="cb4-13">min_T <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.01</span></span>
<span id="cb4-14"><span class="co" style="color: #5E5E5E;">######################################</span></span>
<span id="cb4-15"></span>
<span id="cb4-16">DEFAULT_COS_PARAMS <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb4-17">    <span class="st" style="color: #20794D;">'max_val'</span>:           max_val,</span>
<span id="cb4-18">    <span class="st" style="color: #20794D;">'num_steps'</span>:         num_steps,</span>
<span id="cb4-19">    <span class="st" style="color: #20794D;">'min_val'</span>:           min_val,</span>
<span id="cb4-20">    <span class="st" style="color: #20794D;">'num_cycles'</span>:        num_cycles,</span>
<span id="cb4-21">    <span class="st" style="color: #20794D;">'k_decay'</span>:           k_decay,</span>
<span id="cb4-22">    <span class="st" style="color: #20794D;">'num_warmup_steps'</span>:  num_warmup_steps,</span>
<span id="cb4-23">    <span class="st" style="color: #20794D;">'warmup_init_val'</span>:   warmup_init_val,</span>
<span id="cb4-24">}</span>
<span id="cb4-25"></span>
<span id="cb4-26">DEFAULT_T_PARAMS <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb4-27">    <span class="st" style="color: #20794D;">'max_val'</span>:           max_T,</span>
<span id="cb4-28">    <span class="st" style="color: #20794D;">'num_steps'</span>:         num_steps,</span>
<span id="cb4-29">    <span class="st" style="color: #20794D;">'min_val'</span>:           min_T,</span>
<span id="cb4-30">    <span class="st" style="color: #20794D;">'num_cycles'</span>:        num_cycles,</span>
<span id="cb4-31">    <span class="st" style="color: #20794D;">'k_decay'</span>:           k_decay,</span>
<span id="cb4-32">    <span class="st" style="color: #20794D;">'num_warmup_steps'</span>:  num_warmup_steps,</span>
<span id="cb4-33">    <span class="st" style="color: #20794D;">'warmup_init_val'</span>:   warmup_init_val,</span>
<span id="cb4-34">}</span>
<span id="cb4-35"></span>
<span id="cb4-36"><span class="kw" style="color: #003B4F;">def</span> cos_harness(default_params, <span class="op" style="color: #5E5E5E;">**</span>kwargs):</span>
<span id="cb4-37">    <span class="co" style="color: #5E5E5E;">'''Creates cosine schedules with updated parameters in `new_params`</span></span>
<span id="cb4-38"><span class="co" style="color: #5E5E5E;">    '''</span></span>
<span id="cb4-39">    <span class="co" style="color: #5E5E5E;"># start from the given baseline `default_params`</span></span>
<span id="cb4-40">    cos_params <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">dict</span>(default_params)</span>
<span id="cb4-41">    <span class="co" style="color: #5E5E5E;"># update the with the new, given parameters</span></span>
<span id="cb4-42">    cos_params.update(kwargs)</span>
<span id="cb4-43">    </span>
<span id="cb4-44">    <span class="co" style="color: #5E5E5E;"># return the new cosine schedule</span></span>
<span id="cb4-45">    sched <span class="op" style="color: #5E5E5E;">=</span> get_cos_sched(<span class="op" style="color: #5E5E5E;">**</span>cos_params)</span>
<span id="cb4-46">    <span class="cf" style="color: #003B4F;">return</span> sched</span>
<span id="cb4-47"></span>
<span id="cb4-48"></span>
<span id="cb4-49"><span class="kw" style="color: #003B4F;">def</span> create_expts(params: <span class="bu" style="color: null;">dict</span>, schedule_func) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="bu" style="color: null;">list</span>:</span>
<span id="cb4-50">    <span class="co" style="color: #5E5E5E;">'''Creates a list of experiments.</span></span>
<span id="cb4-51"><span class="co" style="color: #5E5E5E;">    </span></span>
<span id="cb4-52"><span class="co" style="color: #5E5E5E;">    Each element is a dictionary with the name, value, and schedule for a given parameter.</span></span>
<span id="cb4-53"><span class="co" style="color: #5E5E5E;">    A `title` field is also added for easy plotting.</span></span>
<span id="cb4-54"><span class="co" style="color: #5E5E5E;">    '''</span></span>
<span id="cb4-55">    names <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">sorted</span>(params)</span>
<span id="cb4-56">    expts <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb4-57">    <span class="co" style="color: #5E5E5E;"># step through parameter names and their values</span></span>
<span id="cb4-58">    <span class="cf" style="color: #003B4F;">for</span> i,name <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(names):</span>
<span id="cb4-59">        <span class="cf" style="color: #003B4F;">for</span> j,val <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(params[name]):</span>
<span id="cb4-60">            <span class="co" style="color: #5E5E5E;"># create the experiment</span></span>
<span id="cb4-61">            expt <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'param_name'</span>: name,</span>
<span id="cb4-62">                    <span class="st" style="color: #20794D;">'val'</span>: val,</span>
<span id="cb4-63">                    <span class="st" style="color: #20794D;">'schedule'</span>: schedule_func(name<span class="op" style="color: #5E5E5E;">=</span>val)}</span>
<span id="cb4-64">            <span class="co" style="color: #5E5E5E;"># name for plotting</span></span>
<span id="cb4-65">            expt[<span class="st" style="color: #20794D;">'title'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="ss" style="color: #20794D;">f'Param: "</span><span class="sc" style="color: #5E5E5E;">{</span>name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">", val=</span><span class="sc" style="color: #5E5E5E;">{</span>val<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb4-66">            <span class="co" style="color: #5E5E5E;"># add it to the experiment list</span></span>
<span id="cb4-67">            expts.append(expt)</span>
<span id="cb4-68">    <span class="cf" style="color: #003B4F;">return</span> expts</span></code></pre></div>
</div>
<p>Next we create the best k-decay cosine schedules.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="co" style="color: #5E5E5E;"># create the k-decay cosine experiments</span></span>
<span id="cb5-2">k_params <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'k_decay'</span>: [<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">5</span>]}</span>
<span id="cb5-3">k_func <span class="op" style="color: #5E5E5E;">=</span> partial(cos_harness, default_params<span class="op" style="color: #5E5E5E;">=</span>DEFAULT_COS_PARAMS)</span>
<span id="cb5-4">k_expts <span class="op" style="color: #5E5E5E;">=</span> create_expts(k_params, k_func)</span>
<span id="cb5-5"></span>
<span id="cb5-6"><span class="co" style="color: #5E5E5E;"># setup for the Inverse-k-decay cosine schedules</span></span>
<span id="cb5-7">inv_k_params <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'k_decay'</span>: [<span class="fl" style="color: #AD0000;">0.15</span>, <span class="fl" style="color: #AD0000;">0.2</span>, <span class="fl" style="color: #AD0000;">0.3</span>, <span class="fl" style="color: #AD0000;">0.5</span>, <span class="fl" style="color: #AD0000;">0.7</span>]}</span>
<span id="cb5-8">inv_k_func <span class="op" style="color: #5E5E5E;">=</span> partial(cos_harness, default_params<span class="op" style="color: #5E5E5E;">=</span>DEFAULT_COS_PARAMS)</span>
<span id="cb5-9">inv_k_expts <span class="op" style="color: #5E5E5E;">=</span> create_expts(inv_k_params, inv_k_func)</span>
<span id="cb5-10"></span>
<span id="cb5-11"><span class="co" style="color: #5E5E5E;"># invert the `k` schedules with small values</span></span>
<span id="cb5-12">tmp <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb5-13"><span class="cf" style="color: #003B4F;">for</span> s <span class="kw" style="color: #003B4F;">in</span> inv_k_expts:</span>
<span id="cb5-14">    new_vals <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">dict</span>(s)</span>
<span id="cb5-15">    inv <span class="op" style="color: #5E5E5E;">=</span> [max_val <span class="op" style="color: #5E5E5E;">-</span> g <span class="op" style="color: #5E5E5E;">+</span> min_val <span class="cf" style="color: #003B4F;">for</span> g <span class="kw" style="color: #003B4F;">in</span> s[<span class="st" style="color: #20794D;">'schedule'</span>]]</span>
<span id="cb5-16">    new_vals[<span class="st" style="color: #20794D;">'schedule'</span>] <span class="op" style="color: #5E5E5E;">=</span> inv</span>
<span id="cb5-17">    tmp.append(new_vals)</span>
<span id="cb5-18">inv_k_expts <span class="op" style="color: #5E5E5E;">=</span> tmp</span>
<span id="cb5-19"></span>
<span id="cb5-20"><span class="co" style="color: #5E5E5E;"># put all schedules together</span></span>
<span id="cb5-21">all_k_expts <span class="op" style="color: #5E5E5E;">=</span> k_expts <span class="op" style="color: #5E5E5E;">+</span> inv_k_expts</span></code></pre></div>
</div>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-25-guidance-expts-7/index_files/figure-html/cell-7-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-25-guidance-expts-7/index_files/figure-html/cell-8-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>We repeat this for the <code>T</code> and <code>Full</code> Normalizations as well</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="co" style="color: #5E5E5E;"># create the k-decay cosine experiments</span></span>
<span id="cb6-2">T_k_func <span class="op" style="color: #5E5E5E;">=</span> partial(cos_harness, default_params<span class="op" style="color: #5E5E5E;">=</span>DEFAULT_T_PARAMS)</span>
<span id="cb6-3">T_k_expts <span class="op" style="color: #5E5E5E;">=</span> create_expts(k_params, T_k_func)</span>
<span id="cb6-4"></span>
<span id="cb6-5"><span class="co" style="color: #5E5E5E;"># create the Inverse-k-decay cosine experiments</span></span>
<span id="cb6-6">T_inv_k_func <span class="op" style="color: #5E5E5E;">=</span> partial(cos_harness, default_params<span class="op" style="color: #5E5E5E;">=</span>DEFAULT_T_PARAMS)</span>
<span id="cb6-7">T_inv_k_expts <span class="op" style="color: #5E5E5E;">=</span> create_expts(inv_k_params, T_inv_k_func)</span>
<span id="cb6-8"></span>
<span id="cb6-9"><span class="co" style="color: #5E5E5E;"># stores the inverted schedules</span></span>
<span id="cb6-10">tmp <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb6-11"><span class="co" style="color: #5E5E5E;"># flip the schedules</span></span>
<span id="cb6-12"><span class="cf" style="color: #003B4F;">for</span> s <span class="kw" style="color: #003B4F;">in</span> T_inv_k_expts:</span>
<span id="cb6-13">    new_vals <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">dict</span>(s)</span>
<span id="cb6-14">    inv <span class="op" style="color: #5E5E5E;">=</span> [max_T <span class="op" style="color: #5E5E5E;">-</span> g <span class="op" style="color: #5E5E5E;">+</span> min_T <span class="cf" style="color: #003B4F;">for</span> g <span class="kw" style="color: #003B4F;">in</span> s[<span class="st" style="color: #20794D;">'schedule'</span>]]</span>
<span id="cb6-15">    new_vals[<span class="st" style="color: #20794D;">'schedule'</span>] <span class="op" style="color: #5E5E5E;">=</span> inv</span>
<span id="cb6-16">    tmp.append(new_vals)</span>
<span id="cb6-17">T_inv_k_expts <span class="op" style="color: #5E5E5E;">=</span> tmp</span>
<span id="cb6-18"></span>
<span id="cb6-19">all_T_k_expts <span class="op" style="color: #5E5E5E;">=</span> T_k_expts <span class="op" style="color: #5E5E5E;">+</span> T_inv_k_expts</span></code></pre></div>
</div>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-25-guidance-expts-7/index_files/figure-html/cell-10-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-25-guidance-expts-7/index_files/figure-html/cell-11-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="loading-the-stable-diffusion-v1-4-model-from-compvis" class="level1">
<h1>Loading the <code>Stable Diffusion v1-4</code> model from CompVis</h1>
<p>The <code>min_diffusion</code> library loads a Stable Diffusion model from the HuggingFace hub.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="co" style="color: #5E5E5E;"># to load Stable Diffusion pipelines</span></span>
<span id="cb7-2"><span class="im" style="color: #00769E;">from</span> min_diffusion.core <span class="im" style="color: #00769E;">import</span> MinimalDiffusion</span>
<span id="cb7-3"></span>
<span id="cb7-4"><span class="co" style="color: #5E5E5E;"># to plot generated images</span></span>
<span id="cb7-5"><span class="im" style="color: #00769E;">from</span> min_diffusion.utils <span class="im" style="color: #00769E;">import</span> show_image, image_grid, plot_grid</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2022-11-25 13:55:51.399114: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0</code></pre>
</div>
</div>
<p>We use it to load the <code>Stable Diffusion v1-4</code> model on the GPU, with <code>torch.float16</code> precision.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">model_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'CompVis/stable-diffusion-v1-4'</span></span>
<span id="cb9-2">device     <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'cuda'</span></span>
<span id="cb9-3">dtype      <span class="op" style="color: #5E5E5E;">=</span> torch.float16</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">pipeline <span class="op" style="color: #5E5E5E;">=</span> MinimalDiffusion(model_name, device, dtype, generator<span class="op" style="color: #5E5E5E;">=</span>generator)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">pipeline.load(better_vae<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'ema'</span>)<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Using the improved VAE "ema" from stabiliy.ai
Enabling default unet attention slicing.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/paperspace/mambaforge/envs/prod/lib/python3.8/site-packages/diffusers/utils/deprecation_utils.py:35: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a scheduler, please use &lt;class 'diffusers.schedulers.scheduling_lms_discrete.LMSDiscreteScheduler'&gt;.from_pretrained(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.
  warnings.warn(warning + message, FutureWarning)</code></pre>
</div>
</div>
</section>
<section id="text-prompt-for-image-generations" class="level1">
<h1>Text prompt for image generations</h1>
<p>We use the familiar, running prompt in our series to generate an image:</p>
<blockquote class="blockquote">
<p>“a photograph of an astronaut riding a horse”</p>
</blockquote>
<div class="cell">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="co" style="color: #5E5E5E;"># text prompt for image generations</span></span>
<span id="cb14-2">prompt <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"a photograph of an astronaut riding a horse"</span></span></code></pre></div>
</div>
<section id="image-parameters" class="level2">
<h2 class="anchored" data-anchor-id="image-parameters">Image parameters</h2>
<p>Images will be generated over <img src="https://latex.codecogs.com/png.latex?50"> diffusion steps. They will have a height and width of <code>512 x 512</code> pixels.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="co" style="color: #5E5E5E;"># the number of diffusion steps</span></span>
<span id="cb15-2">num_steps <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">50</span></span>
<span id="cb15-3"></span>
<span id="cb15-4"><span class="co" style="color: #5E5E5E;"># generated image dimensions</span></span>
<span id="cb15-5">width, height <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">512</span>, <span class="dv" style="color: #AD0000;">512</span></span></code></pre></div>
</div>
</section>
</section>
<section id="running-the-experiments" class="level1">
<h1>Running the experiments</h1>
<p>The <code>run</code> function below generates images for a given <code>prompt</code>.</p>
<p>It also stores the output images with a matching title for plotting and visualizations.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="kw" style="color: #003B4F;">def</span> run(prompt, schedules, guide_tfm<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>, generator<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb16-2">        show_each<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>, test_run<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>):</span>
<span id="cb16-3">    <span class="co" style="color: #5E5E5E;">"""Runs a dynamic Classifier-free Guidance experiment. </span></span>
<span id="cb16-4"><span class="co" style="color: #5E5E5E;">    </span></span>
<span id="cb16-5"><span class="co" style="color: #5E5E5E;">    Generates an image for the text `prompt` given all the values in `schedules`.</span></span>
<span id="cb16-6"><span class="co" style="color: #5E5E5E;">    Uses a Guidance Transformation class from the `cf_guidance` library.  </span></span>
<span id="cb16-7"><span class="co" style="color: #5E5E5E;">    Stores the output images with a matching title for plotting. </span></span>
<span id="cb16-8"><span class="co" style="color: #5E5E5E;">    Optionally shows each image as its generated.</span></span>
<span id="cb16-9"><span class="co" style="color: #5E5E5E;">    If `test_run` is true, it runs a single schedule for testing. </span></span>
<span id="cb16-10"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb16-11">    <span class="co" style="color: #5E5E5E;"># store generated images and their title (the experiment name)</span></span>
<span id="cb16-12">    images, titles <span class="op" style="color: #5E5E5E;">=</span> [], []</span>
<span id="cb16-13">    </span>
<span id="cb16-14">    <span class="co" style="color: #5E5E5E;"># make sure we have a valid guidance transform</span></span>
<span id="cb16-15">    <span class="cf" style="color: #003B4F;">assert</span> guide_tfm</span>
<span id="cb16-16">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Using Guidance Transform: </span><span class="sc" style="color: #5E5E5E;">{</span>guide_tfm<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb16-17">    </span>
<span id="cb16-18">    <span class="co" style="color: #5E5E5E;"># optionally run a single test schedule</span></span>
<span id="cb16-19">    <span class="cf" style="color: #003B4F;">if</span> test_run:</span>
<span id="cb16-20">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Running a single schedule for testing.'</span>)</span>
<span id="cb16-21">        schedules <span class="op" style="color: #5E5E5E;">=</span> schedules[:<span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb16-22">        </span>
<span id="cb16-23">    <span class="co" style="color: #5E5E5E;"># run all schedule experiments</span></span>
<span id="cb16-24">    <span class="cf" style="color: #003B4F;">for</span> i,s <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(schedules):</span>
<span id="cb16-25">        </span>
<span id="cb16-26">        <span class="co" style="color: #5E5E5E;"># parse out the title for the current run</span></span>
<span id="cb16-27">        cur_title  <span class="op" style="color: #5E5E5E;">=</span> s[<span class="st" style="color: #20794D;">'title'</span>]</span>
<span id="cb16-28">        titles.append(cur_title)</span>
<span id="cb16-29">        </span>
<span id="cb16-30">        <span class="co" style="color: #5E5E5E;"># create the guidance transformation </span></span>
<span id="cb16-31">        cur_sched <span class="op" style="color: #5E5E5E;">=</span> s[<span class="st" style="color: #20794D;">'schedule'</span>]</span>
<span id="cb16-32">        gtfm <span class="op" style="color: #5E5E5E;">=</span> guide_tfm({<span class="st" style="color: #20794D;">'g'</span>: cur_sched})</span>
<span id="cb16-33">        </span>
<span id="cb16-34">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Running experiment [</span><span class="sc" style="color: #5E5E5E;">{</span>i<span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;"> of </span><span class="sc" style="color: #5E5E5E;">{</span><span class="bu" style="color: null;">len</span>(schedules)<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">]: </span><span class="sc" style="color: #5E5E5E;">{</span>cur_title<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">...'</span>)</span>
<span id="cb16-35">        img <span class="op" style="color: #5E5E5E;">=</span> pipeline.generate(prompt, gtfm, generator<span class="op" style="color: #5E5E5E;">=</span>generator)</span>
<span id="cb16-36">        images.append(img)</span>
<span id="cb16-37">        </span>
<span id="cb16-38">        <span class="co" style="color: #5E5E5E;"># optionally plot the image</span></span>
<span id="cb16-39">        <span class="cf" style="color: #003B4F;">if</span> show_each:</span>
<span id="cb16-40">            show_image(img, scale<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb16-41"></span>
<span id="cb16-42">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Done.'</span>)</span>
<span id="cb16-43">    <span class="cf" style="color: #003B4F;">return</span> {<span class="st" style="color: #20794D;">'images'</span>: images,</span>
<span id="cb16-44">            <span class="st" style="color: #20794D;">'titles'</span>: titles}</span></code></pre></div>
</div>
<section id="creating-the-baseline-image-with-g-7.5" class="level2">
<h2 class="anchored" data-anchor-id="creating-the-baseline-image-with-g-7.5">Creating the baseline image with <img src="https://latex.codecogs.com/png.latex?G%20=%207.5"></h2>
<p>First we create the baseline image using a constant Classifier-free Guidance with <img src="https://latex.codecogs.com/png.latex?G%20=%207.5">. Since this is a constant schedule, <img src="https://latex.codecogs.com/png.latex?k"> does not come into play.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="co" style="color: #5E5E5E;"># create the baseline schedule with the new function</span></span>
<span id="cb17-2">baseline_g <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">7.5</span></span>
<span id="cb17-3">baseline_params <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'max_val'</span>: [baseline_g]}</span>
<span id="cb17-4">baseline_func <span class="op" style="color: #5E5E5E;">=</span> <span class="kw" style="color: #003B4F;">lambda</span> <span class="op" style="color: #5E5E5E;">*</span>args, <span class="op" style="color: #5E5E5E;">**</span>kwargs: [baseline_g <span class="cf" style="color: #003B4F;">for</span> _ <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(num_steps)]</span>
<span id="cb17-5">baseline_expts <span class="op" style="color: #5E5E5E;">=</span> create_expts(baseline_params, baseline_func)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">baseline_res <span class="op" style="color: #5E5E5E;">=</span> run(prompt, baseline_expts, guide_tfm<span class="op" style="color: #5E5E5E;">=</span>GuidanceTfm)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Using Guidance Transform: &lt;class 'cf_guidance.transforms.GuidanceTfm'&gt;
Running experiment [1 of 1]: Param: "max_val", val=7.5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"30363b97ed04484d96fe9a0dbff4269b","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="co" style="color: #5E5E5E;"># view the baseline image</span></span>
<span id="cb21-2">baseline_res[<span class="st" style="color: #20794D;">'images'</span>][<span class="dv" style="color: #AD0000;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-25-guidance-expts-7/index_files/figure-html/cell-21-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="improving-the-baseline-with-schedules-and-normalizations" class="level2">
<h2 class="anchored" data-anchor-id="improving-the-baseline-with-schedules-and-normalizations">Improving the baseline with schedules and normalizations</h2>
<p>Now let’s run our <code>kDecay</code> schedules with normalizations. Then we can check how it changed the baseline image.</p>
<p>Since every run starts from the exact same noisy latents, only the schedules and normalizations are affecting the output.</p>
</section>
<section id="prediction-normalization-runs" class="level2">
<h2 class="anchored" data-anchor-id="prediction-normalization-runs"><code>Prediction Normalization</code> runs</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Running the Prediction Norm experiments...'</span>)</span>
<span id="cb22-2">base_norm_res <span class="op" style="color: #5E5E5E;">=</span> run(prompt, all_k_expts, guide_tfm<span class="op" style="color: #5E5E5E;">=</span>BaseNormGuidance)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running the Prediction Norm experiments...
Using Guidance Transform: &lt;class 'cf_guidance.transforms.BaseNormGuidance'&gt;
Running experiment [1 of 8]: Param: "k_decay", val=1...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f50a98dce79e463784d4cbd536617698","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [2 of 8]: Param: "k_decay", val=2...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"53dbd5c7268545a29c37ecd5a3024d41","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [3 of 8]: Param: "k_decay", val=5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c07de3ed6b0e4a2b93e167a4aa321da8","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [4 of 8]: Param: "k_decay", val=0.15...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"882af6bb779b4f898e5f1e6fe6c0daeb","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [5 of 8]: Param: "k_decay", val=0.2...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"fe87cde82d67473581bc0d29673c060c","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [6 of 8]: Param: "k_decay", val=0.3...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"15996bbfe20d40ccb53f81ea31e4a69d","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [7 of 8]: Param: "k_decay", val=0.5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"05c4457c29714b0f878bd7c678a9f553","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [8 of 8]: Param: "k_decay", val=0.7...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"62dd7b4b388647d8b7a8b32c872a6bcc","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.</code></pre>
</div>
</div>
</section>
<section id="t-normalization-runs" class="level2">
<h2 class="anchored" data-anchor-id="t-normalization-runs"><code>T-Normalization</code> runs</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Running the T-Norm experiments...'</span>)</span>
<span id="cb32-2">T_norm_res <span class="op" style="color: #5E5E5E;">=</span> run(prompt, all_T_k_expts, guide_tfm<span class="op" style="color: #5E5E5E;">=</span>TNormGuidance)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running the T-Norm experiments...
Using Guidance Transform: &lt;class 'cf_guidance.transforms.TNormGuidance'&gt;
Running experiment [1 of 8]: Param: "k_decay", val=1...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1f0d3220554544f58264e03ac276599d","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [2 of 8]: Param: "k_decay", val=2...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7102142ef3b04b37b4833eea26c09211","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [3 of 8]: Param: "k_decay", val=5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"31b7e06225d84c26a9c8879d04f9e9d7","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [4 of 8]: Param: "k_decay", val=0.15...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1a222890025649679ac2eee9883677a4","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [5 of 8]: Param: "k_decay", val=0.2...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"250b783faad043cf9cfa3eb7cd39b537","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [6 of 8]: Param: "k_decay", val=0.3...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"9b75d89bcb30408f8cbb1c94cd7c87a1","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [7 of 8]: Param: "k_decay", val=0.5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"5603cd53e77d43d1a68932edd83aa1dd","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [8 of 8]: Param: "k_decay", val=0.7...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1e4728540fbe44fdbd5e276452f320e5","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.</code></pre>
</div>
</div>
</section>
<section id="full-normalization-runs" class="level2">
<h2 class="anchored" data-anchor-id="full-normalization-runs"><code>Full Normalization</code> runs</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Running the T-Norm experiments...'</span>)</span>
<span id="cb42-2">full_norm_res <span class="op" style="color: #5E5E5E;">=</span> run(prompt, all_T_k_expts, guide_tfm<span class="op" style="color: #5E5E5E;">=</span>FullNormGuidance)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running the T-Norm experiments...
Using Guidance Transform: &lt;class 'cf_guidance.transforms.FullNormGuidance'&gt;
Running experiment [1 of 8]: Param: "k_decay", val=1...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"0b93d84a9c764e0785a27c2781ecfddc","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [2 of 8]: Param: "k_decay", val=2...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c4b68a0d49064f938d8da8f3f7e1a867","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [3 of 8]: Param: "k_decay", val=5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ad3ffd64f15147b6a8456c0f43ee789c","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [4 of 8]: Param: "k_decay", val=0.15...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f299bc1bbc7641288bfd65084c0c7cf8","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [5 of 8]: Param: "k_decay", val=0.2...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"fc3958441fbb4b86b93cc6752b7c15a7","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [6 of 8]: Param: "k_decay", val=0.3...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"22ca110537f74dd2b98623ac67e1abbf","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [7 of 8]: Param: "k_decay", val=0.5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"49415d39c880489f8b7f8264aa504ced","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [8 of 8]: Param: "k_decay", val=0.7...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e8eee6857ad34879aa04112a98aeafd1","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.</code></pre>
</div>
</div>
</section>
</section>
<section id="results" class="level1">
<h1>Results</h1>
<section id="prediction-normalization-results" class="level2">
<h2 class="anchored" data-anchor-id="prediction-normalization-results"><code>Prediction Normalization</code> results</h2>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-25-guidance-expts-7/index_files/figure-html/cell-25-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="t-normalization-results" class="level2">
<h2 class="anchored" data-anchor-id="t-normalization-results"><code>T-Normalization</code> results</h2>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-25-guidance-expts-7/index_files/figure-html/cell-26-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="full-normalization-results" class="level2">
<h2 class="anchored" data-anchor-id="full-normalization-results"><code>Full-Normalization</code> results</h2>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-25-guidance-expts-7/index_files/figure-html/cell-27-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="analysis" class="level1">
<h1>Analysis</h1>
<p><code>Inverse kDecay</code> schedules improve the images the most. The regular <code>kDecay</code> schedules also helped, but the improvements are not as drastic.</p>
<p>The sweet spot for <code>Inverse kDecay</code> seems to be between <img src="https://latex.codecogs.com/png.latex?0.15"> and <img src="https://latex.codecogs.com/png.latex?0.3">. It is not fully constant throughout the normalizations either. Sometimes <img src="https://latex.codecogs.com/png.latex?0.15"> is better than <img src="https://latex.codecogs.com/png.latex?0.2"> and vice-versa.</p>
<p>When in doubt, it seems <img src="https://latex.codecogs.com/png.latex?0.2"> is a good middle ground. Perhaps we need to explore this range further, or increase the slope of the initial <code>kDecay</code> warmup.</p>
<section id="prediction-normalization-comparison" class="level2">
<h2 class="anchored" data-anchor-id="prediction-normalization-comparison"><code>Prediction Normalization</code> comparison</h2>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-25-guidance-expts-7/index_files/figure-html/cell-28-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="t-normalization-comparison" class="level2">
<h2 class="anchored" data-anchor-id="t-normalization-comparison"><code>T-Normalization</code> comparison</h2>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-25-guidance-expts-7/index_files/figure-html/cell-29-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="full-normalization-comparison" class="level2">
<h2 class="anchored" data-anchor-id="full-normalization-comparison"><code>Full Normalization</code> comparison</h2>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-25-guidance-expts-7/index_files/figure-html/cell-30-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="comparing-k-0.15-across-normalizations" class="level2">
<h2 class="anchored" data-anchor-id="comparing-k-0.15-across-normalizations">Comparing <img src="https://latex.codecogs.com/png.latex?k%20=%200.15"> across normalizations</h2>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-25-guidance-expts-7/index_files/figure-html/cell-31-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="comparing-k-0.2-across-normalizations" class="level2">
<h2 class="anchored" data-anchor-id="comparing-k-0.2-across-normalizations">Comparing <img src="https://latex.codecogs.com/png.latex?k%20=%200.2"> across normalizations</h2>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-25-guidance-expts-7/index_files/figure-html/cell-32-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="comparing-k-0.3-across-normalizations" class="level2">
<h2 class="anchored" data-anchor-id="comparing-k-0.3-across-normalizations">Comparing <img src="https://latex.codecogs.com/png.latex?k%20=%200.3"> across normalizations</h2>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-25-guidance-expts-7/index_files/figure-html/cell-33-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>At this point, the difference in quality between <img src="https://latex.codecogs.com/png.latex?0.15"> and <img src="https://latex.codecogs.com/png.latex?0.2"> becomes subjective. It does seem that 0.2 makes for more stable images across the normalizations. But, 0.15 fixed the astronaut’s leg and arm.</p>
<p><img src="https://latex.codecogs.com/png.latex?0.3"> still improves the image, but we start to lose texture and coherence in the background.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>In Part 6 of the series we combined our best schedules so far with normalizations.</p>
<p>We found that normalizations with an <code>Inverse kDecay</code> schedule of <img src="https://latex.codecogs.com/png.latex?k%20=%200.2"> or <img src="https://latex.codecogs.com/png.latex?k%20=%200.15"> improved on the baseline. These schedules gave the background more details, enhanced details on the floor, improved details in the astronaut’s suit, and made the horse more anatomically correct. This confirms our explorations in previous notebooks, which showed that the Guidance scaling had to warmup quickly and/or stay high for as long as possible.</p>
<p>In Part 7, we will check if these gains hold across different Stable Diffusion models.</p>


</section>

 ]]></description>
  <category>diffusion</category>
  <category>classifier-free guidance</category>
  <category>deep learning</category>
  <guid>https://enzokro.dev/blog/posts/2022-11-25-guidance-expts-7/index.html</guid>
  <pubDate>Sat, 26 Nov 2022 00:00:00 GMT</pubDate>
  <media:content url="https://enzokro.dev/blog/posts/2022-11-25-guidance-expts-7/better_horse_6.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Classifier-free Guidance with Cosine Schedules Pt. 7</title>
  <dc:creator>enzokro</dc:creator>
  <link>https://enzokro.dev/blog/posts/2022-11-26-guidance-expts-8/index.html</link>
  <description><![CDATA[ 



<blockquote class="blockquote">
<p>dynamic Classifier-free Guidance across several Diffusion models.</p>
</blockquote>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="co" style="color: #5E5E5E;"># from huggingface_hub import notebook_login</span></span>
<span id="cb1-2"><span class="co" style="color: #5E5E5E;"># notebook_login()</span></span></code></pre></div>
</div>
<p>This notebook is Part 7 in a <a href="https://enzokro.dev/blog/posts/2022-11-15-guidance-expts-6/">series</a> on dynamic Classifier-free Guidance. It checks whether our proposed schedules and normalizations improve images across Diffusion models.</p>
<section id="recap-of-parts-1-6" class="level2">
<h2 class="anchored" data-anchor-id="recap-of-parts-1-6">Recap of Parts 1-6</h2>
<p>In the first six parts, we found a good set of schedules and normalizations for a dynamic Classifier-free Guidance. The best performing schedules are used in this notebook.</p>
</section>
<section id="part-7-improvement-across-models" class="level2">
<h2 class="anchored" data-anchor-id="part-7-improvement-across-models">Part 7: Improvement across models</h2>
<p>Part 7 takes our best schedule so far, <code>Inverse kDecay</code>, and tries it on a few different models:</p>
<ul>
<li>Stable Diffusion v1-4</li>
<li>Stable Diffusion v1-5</li>
<li>Prompt Hero’s openjourney</li>
<li>Stable Diffusion 2-base</li>
</ul>
</section>
</section>
<section id="python-imports" class="level1">
<h1>Python imports</h1>
<p>We start with a few python imports.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;">import</span> os</span>
<span id="cb2-2"><span class="im" style="color: #00769E;">import</span> random</span>
<span id="cb2-3"><span class="im" style="color: #00769E;">from</span> functools <span class="im" style="color: #00769E;">import</span> partial</span>
<span id="cb2-4"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb2-5"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb2-6"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb2-7"><span class="im" style="color: #00769E;">import</span> matplotlib.colors <span class="im" style="color: #00769E;">as</span> mcolors</span></code></pre></div>
</div>
<section id="seed-for-reproducibility" class="level2">
<h2 class="anchored" data-anchor-id="seed-for-reproducibility">Seed for reproducibility</h2>
<p><code>seed_everything</code> makes sure that the results are reproducible across notebooks.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;"># set the seed and pseudo random number generator</span></span>
<span id="cb3-2"><span class="co" style="color: #5E5E5E;"># SEED = 4262829004 # cat</span></span>
<span id="cb3-3">SEED <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1337802893</span> <span class="co" style="color: #5E5E5E;"># inca</span></span>
<span id="cb3-4"><span class="co" style="color: #5E5E5E;"># SEED = 977145576 # inca2, warrior</span></span>
<span id="cb3-5"><span class="kw" style="color: #003B4F;">def</span> seed_everything(seed):</span>
<span id="cb3-6">    random.seed(seed)</span>
<span id="cb3-7">    os.environ[<span class="st" style="color: #20794D;">'PYTHONHASHSEED'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">str</span>(seed)</span>
<span id="cb3-8">    np.random.seed(seed)</span>
<span id="cb3-9">    generator <span class="op" style="color: #5E5E5E;">=</span> torch.manual_seed(seed)</span>
<span id="cb3-10">    torch.backends.cudnn.deterministic <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">True</span></span>
<span id="cb3-11">    torch.backends.cudnn.benchmark <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">False</span></span>
<span id="cb3-12">    <span class="cf" style="color: #003B4F;">return</span> generator</span>
<span id="cb3-13"></span>
<span id="cb3-14"><span class="co" style="color: #5E5E5E;"># for sampling the initial, noisy latents</span></span>
<span id="cb3-15">generator <span class="op" style="color: #5E5E5E;">=</span> seed_everything(SEED)</span></code></pre></div>
</div>
</section>
</section>
<section id="cosine-schedules-with-k-decay" class="level1">
<h1>Cosine schedules with k-decay</h1>
<p>We create the schedules with different <img src="https://latex.codecogs.com/png.latex?k"> values using the <code>cf_guidance</code> library.</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;"># helpers to create cosine schedules</span></span>
<span id="cb4-2"><span class="im" style="color: #00769E;">from</span> cf_guidance.schedules  <span class="im" style="color: #00769E;">import</span> get_cos_sched</span>
<span id="cb4-3"></span>
<span id="cb4-4"><span class="co" style="color: #5E5E5E;"># normalizations for classifier-free guidance</span></span>
<span id="cb4-5"><span class="im" style="color: #00769E;">from</span> cf_guidance.transforms <span class="im" style="color: #00769E;">import</span> GuidanceTfm, BaseNormGuidance, TNormGuidance, FullNormGuidance</span></code></pre></div>
</div>
<p>For the other schedule parameters, we keep the <a href="https://enzokro.dev/blog/posts/2022-11-20-guidance-expts-2/#default-schedule-parameters">same values</a> from the rest of the series. The functions below are also shared with previous notebooks.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="co" style="color: #5E5E5E;"># Default schedule parameters from the blog post</span></span>
<span id="cb5-2"><span class="co" style="color: #5E5E5E;">######################################</span></span>
<span id="cb5-3">max_val           <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">7.5</span>   <span class="co" style="color: #5E5E5E;"># guidance scaling value</span></span>
<span id="cb5-4">min_val           <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span>     <span class="co" style="color: #5E5E5E;"># minimum guidance scaling</span></span>
<span id="cb5-5">num_steps         <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">50</span>    <span class="co" style="color: #5E5E5E;"># number of diffusion steps</span></span>
<span id="cb5-6">num_warmup_steps  <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span>     <span class="co" style="color: #5E5E5E;"># number of warmup steps</span></span>
<span id="cb5-7">warmup_init_val   <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span>     <span class="co" style="color: #5E5E5E;"># the intial warmup value</span></span>
<span id="cb5-8">num_cycles        <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.5</span>     <span class="co" style="color: #5E5E5E;"># number of cosine cycles</span></span>
<span id="cb5-9">k_decay           <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span>     <span class="co" style="color: #5E5E5E;"># k-decay for cosine curve scaling </span></span>
<span id="cb5-10"></span>
<span id="cb5-11"><span class="co" style="color: #5E5E5E;"># smaller values for T-Norm and FullNorm</span></span>
<span id="cb5-12">max_T <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.15</span></span>
<span id="cb5-13">min_T <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.05</span></span>
<span id="cb5-14"><span class="co" style="color: #5E5E5E;">######################################</span></span>
<span id="cb5-15"></span>
<span id="cb5-16">DEFAULT_COS_PARAMS <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb5-17">    <span class="st" style="color: #20794D;">'max_val'</span>:           max_val,</span>
<span id="cb5-18">    <span class="st" style="color: #20794D;">'num_steps'</span>:         num_steps,</span>
<span id="cb5-19">    <span class="st" style="color: #20794D;">'min_val'</span>:           min_val,</span>
<span id="cb5-20">    <span class="st" style="color: #20794D;">'num_cycles'</span>:        num_cycles,</span>
<span id="cb5-21">    <span class="st" style="color: #20794D;">'k_decay'</span>:           k_decay,</span>
<span id="cb5-22">    <span class="st" style="color: #20794D;">'num_warmup_steps'</span>:  num_warmup_steps,</span>
<span id="cb5-23">    <span class="st" style="color: #20794D;">'warmup_init_val'</span>:   warmup_init_val,</span>
<span id="cb5-24">}</span>
<span id="cb5-25"></span>
<span id="cb5-26">DEFAULT_T_PARAMS <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb5-27">    <span class="st" style="color: #20794D;">'max_val'</span>:           max_T,</span>
<span id="cb5-28">    <span class="st" style="color: #20794D;">'num_steps'</span>:         num_steps,</span>
<span id="cb5-29">    <span class="st" style="color: #20794D;">'min_val'</span>:           min_T,</span>
<span id="cb5-30">    <span class="st" style="color: #20794D;">'num_cycles'</span>:        num_cycles,</span>
<span id="cb5-31">    <span class="st" style="color: #20794D;">'k_decay'</span>:           k_decay,</span>
<span id="cb5-32">    <span class="st" style="color: #20794D;">'num_warmup_steps'</span>:  num_warmup_steps,</span>
<span id="cb5-33">    <span class="st" style="color: #20794D;">'warmup_init_val'</span>:   warmup_init_val,</span>
<span id="cb5-34">}</span>
<span id="cb5-35"></span>
<span id="cb5-36"><span class="kw" style="color: #003B4F;">def</span> cos_harness(new_params<span class="op" style="color: #5E5E5E;">=</span>{}, default_params<span class="op" style="color: #5E5E5E;">=</span>{}):</span>
<span id="cb5-37">    <span class="co" style="color: #5E5E5E;">'''Creates cosine schedules with updated parameters in `new_params`</span></span>
<span id="cb5-38"><span class="co" style="color: #5E5E5E;">    '''</span></span>
<span id="cb5-39">    <span class="co" style="color: #5E5E5E;"># start from the given baseline `default_params`</span></span>
<span id="cb5-40">    cos_params <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">dict</span>(default_params)</span>
<span id="cb5-41">    <span class="co" style="color: #5E5E5E;"># update the with the new, given parameters</span></span>
<span id="cb5-42">    cos_params.update(new_params)</span>
<span id="cb5-43">    </span>
<span id="cb5-44">    <span class="co" style="color: #5E5E5E;"># return the new cosine schedule</span></span>
<span id="cb5-45">    sched <span class="op" style="color: #5E5E5E;">=</span> get_cos_sched(<span class="op" style="color: #5E5E5E;">**</span>cos_params)</span>
<span id="cb5-46">    <span class="cf" style="color: #003B4F;">return</span> sched</span>
<span id="cb5-47"></span>
<span id="cb5-48"></span>
<span id="cb5-49"><span class="kw" style="color: #003B4F;">def</span> create_expts(params: <span class="bu" style="color: null;">dict</span>, schedule_func) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="bu" style="color: null;">list</span>:</span>
<span id="cb5-50">    <span class="co" style="color: #5E5E5E;">'''Creates a list of experiments.</span></span>
<span id="cb5-51"><span class="co" style="color: #5E5E5E;">    </span></span>
<span id="cb5-52"><span class="co" style="color: #5E5E5E;">    Each element is a dictionary with the name, value, and schedule for a given parameter.</span></span>
<span id="cb5-53"><span class="co" style="color: #5E5E5E;">    A `title` field is also added for easy plotting.</span></span>
<span id="cb5-54"><span class="co" style="color: #5E5E5E;">    '''</span></span>
<span id="cb5-55">    names <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">sorted</span>(params)</span>
<span id="cb5-56">    expts <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb5-57">    <span class="co" style="color: #5E5E5E;"># step through parameter names and their values</span></span>
<span id="cb5-58">    <span class="cf" style="color: #003B4F;">for</span> i,name <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(names):</span>
<span id="cb5-59">        <span class="cf" style="color: #003B4F;">for</span> j,val <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(params[name]):</span>
<span id="cb5-60">            <span class="co" style="color: #5E5E5E;"># create the experiment</span></span>
<span id="cb5-61">            expt <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'param_name'</span>: name,</span>
<span id="cb5-62">                    <span class="st" style="color: #20794D;">'val'</span>: val,</span>
<span id="cb5-63">                    <span class="st" style="color: #20794D;">'schedule'</span>: schedule_func({name: val})}</span>
<span id="cb5-64">            <span class="co" style="color: #5E5E5E;"># name for plotting</span></span>
<span id="cb5-65">            expt[<span class="st" style="color: #20794D;">'title'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="ss" style="color: #20794D;">f'Param: "</span><span class="sc" style="color: #5E5E5E;">{</span>name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">", val=</span><span class="sc" style="color: #5E5E5E;">{</span>val<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb5-66">            <span class="co" style="color: #5E5E5E;"># add it to the experiment list</span></span>
<span id="cb5-67">            expts.append(expt)</span>
<span id="cb5-68">    <span class="cf" style="color: #003B4F;">return</span> expts</span></code></pre></div>
</div>
<p>Next we create the best k-decay cosine schedules.</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="co" style="color: #5E5E5E;"># setup for the Inverse-k-decay cosine schedules</span></span>
<span id="cb6-2">inv_k_params <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'k_decay'</span>: [<span class="fl" style="color: #AD0000;">0.15</span>]}</span>
<span id="cb6-3">inv_k_func <span class="op" style="color: #5E5E5E;">=</span> partial(cos_harness, default_params<span class="op" style="color: #5E5E5E;">=</span>DEFAULT_COS_PARAMS)</span>
<span id="cb6-4">inv_k_expts <span class="op" style="color: #5E5E5E;">=</span> create_expts(inv_k_params, inv_k_func)</span>
<span id="cb6-5"></span>
<span id="cb6-6"><span class="co" style="color: #5E5E5E;"># invert the `k` schedules</span></span>
<span id="cb6-7"><span class="cf" style="color: #003B4F;">for</span> s <span class="kw" style="color: #003B4F;">in</span> inv_k_expts:</span>
<span id="cb6-8">    s[<span class="st" style="color: #20794D;">'schedule'</span>] <span class="op" style="color: #5E5E5E;">=</span> [max_val <span class="op" style="color: #5E5E5E;">-</span> g <span class="op" style="color: #5E5E5E;">+</span> min_val <span class="cf" style="color: #003B4F;">for</span> g <span class="kw" style="color: #003B4F;">in</span> s[<span class="st" style="color: #20794D;">'schedule'</span>]]</span>
<span id="cb6-9"></span>
<span id="cb6-10"><span class="co" style="color: #5E5E5E;"># put all schedules together</span></span>
<span id="cb6-11">all_k_expts <span class="op" style="color: #5E5E5E;">=</span> inv_k_expts</span></code></pre></div>
</div>
<div class="cell" data-execution_count="7">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-26-guidance-expts-8/index_files/figure-html/cell-8-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>We repeat this for the <code>T</code> and <code>Full</code> Normalizations as well</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="co" style="color: #5E5E5E;"># create the Inverse-k-decay cosine experiments</span></span>
<span id="cb7-2">T_inv_k_func <span class="op" style="color: #5E5E5E;">=</span> partial(cos_harness, default_params<span class="op" style="color: #5E5E5E;">=</span>DEFAULT_T_PARAMS)</span>
<span id="cb7-3">T_inv_k_expts <span class="op" style="color: #5E5E5E;">=</span> create_expts(inv_k_params, T_inv_k_func)</span>
<span id="cb7-4"></span>
<span id="cb7-5"><span class="co" style="color: #5E5E5E;"># stores the inverted schedules</span></span>
<span id="cb7-6"><span class="co" style="color: #5E5E5E;"># invert the `k` schedules</span></span>
<span id="cb7-7"><span class="cf" style="color: #003B4F;">for</span> s <span class="kw" style="color: #003B4F;">in</span> T_inv_k_expts:</span>
<span id="cb7-8">    s[<span class="st" style="color: #20794D;">'schedule'</span>] <span class="op" style="color: #5E5E5E;">=</span> [max_T <span class="op" style="color: #5E5E5E;">-</span> g <span class="op" style="color: #5E5E5E;">+</span> min_T <span class="cf" style="color: #003B4F;">for</span> g <span class="kw" style="color: #003B4F;">in</span> s[<span class="st" style="color: #20794D;">'schedule'</span>]]</span>
<span id="cb7-9"></span>
<span id="cb7-10">all_T_k_expts <span class="op" style="color: #5E5E5E;">=</span> T_inv_k_expts</span></code></pre></div>
</div>
<div class="cell" data-execution_count="9">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-26-guidance-expts-8/index_files/figure-html/cell-10-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="loading-different-stablediffusion-models" class="level1">
<h1>Loading different StableDiffusion models</h1>
<p>We need to wrap our experiment pipeline in a single loop so we can easily run it with different models. To do this, we’ll move the model loading code below in its own function, and add a function cleanup gpu memory.</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="op" style="color: #5E5E5E;">%%</span>capture</span>
<span id="cb8-2"><span class="co" style="color: #5E5E5E;"># to load Stable Diffusion pipelines</span></span>
<span id="cb8-3"><span class="im" style="color: #00769E;">from</span> min_diffusion.core <span class="im" style="color: #00769E;">import</span> MinimalDiffusion</span>
<span id="cb8-4"></span>
<span id="cb8-5"><span class="co" style="color: #5E5E5E;"># to plot generated images</span></span>
<span id="cb8-6"><span class="im" style="color: #00769E;">from</span> min_diffusion.utils <span class="im" style="color: #00769E;">import</span> show_image, image_grid, plot_grid</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2022-11-26 02:49:42.635884: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-11-26 02:49:43.342102: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2022-11-26 02:49:43.342191: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2022-11-26 02:49:43.342198: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.</code></pre>
</div>
</div>
<p>We use it to load the <code>Stable Diffusion v1-4</code> model on the GPU, with <code>torch.float16</code> precision.</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="kw" style="color: #003B4F;">def</span> load_sd_model(model_name, device, dtype, model_kwargs<span class="op" style="color: #5E5E5E;">=</span>{}, generator<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb10-2">    pipeline <span class="op" style="color: #5E5E5E;">=</span> MinimalDiffusion(model_name, device, dtype, generator<span class="op" style="color: #5E5E5E;">=</span>generator)</span>
<span id="cb10-3">    pipeline.load(<span class="op" style="color: #5E5E5E;">**</span>model_kwargs)<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb10-4">    <span class="cf" style="color: #003B4F;">return</span> pipeline</span></code></pre></div>
</div>
</section>
<section id="text-prompt-for-image-generations" class="level1">
<h1>Text prompt for image generations</h1>
<p>We use the familiar, running prompt in our series to generate an image:</p>
<blockquote class="blockquote">
<p>“a photograph of an astronaut riding a horse”</p>
</blockquote>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="co" style="color: #5E5E5E;"># text prompt for image generations</span></span>
<span id="cb11-2"></span>
<span id="cb11-3"><span class="co" style="color: #5E5E5E;"># prompt = "a beautiful painting of an elegant cat, highly detailed, 4K, 8K, trending on art station, Award winning"</span></span>
<span id="cb11-4"></span>
<span id="cb11-5">prompt <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"digital painting of hanan pacha, the incan world above us where the sun and moon live, by filipe pagliuso and justin gerard, symmetric, fantasy, realistic, highly detailed, realistic, intricate, sharp focus, tarot card, portrait"</span></span>
<span id="cb11-6"><span class="co" style="color: #5E5E5E;"># prompt = "digital painting of masked incan warrior, by filipe pagliuso and justin gerard, symmetric, fantasy, highly detailed, realistic, intricate, portrait, sharp focus, tarot card, face, handsome, peruvian, ax"</span></span></code></pre></div>
</div>
<section id="image-parameters" class="level2">
<h2 class="anchored" data-anchor-id="image-parameters">Image parameters</h2>
<p>Images will be generated over <img src="https://latex.codecogs.com/png.latex?50"> diffusion steps. They will have a height and width of <code>512 x 512</code> pixels.</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;"># the number of diffusion steps</span></span>
<span id="cb12-2">num_steps <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">50</span></span>
<span id="cb12-3"></span>
<span id="cb12-4"><span class="co" style="color: #5E5E5E;"># dimensions for v1 and v2 Stable Diffusions</span></span>
<span id="cb12-5">sd2_dims <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'height'</span>: <span class="dv" style="color: #AD0000;">768</span>, <span class="st" style="color: #20794D;">'width'</span>: <span class="dv" style="color: #AD0000;">768</span>}</span>
<span id="cb12-6">sd_dims  <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'height'</span>: <span class="dv" style="color: #AD0000;">640</span>, <span class="st" style="color: #20794D;">'width'</span>: <span class="dv" style="color: #AD0000;">512</span>} <span class="co" style="color: #5E5E5E;"># goddess prompt</span></span></code></pre></div>
</div>
</section>
</section>
<section id="running-the-experiments" class="level1">
<h1>Running the experiments</h1>
<p>We modify the <code>run</code> function to now load the Stable Diffusion model internally. This makes it easy to pass in and try different generators. We add a bit of GPU cleanup at the end to make sure there is enough memory for the models.</p>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="kw" style="color: #003B4F;">def</span> run(pipeline, prompt, schedules,</span>
<span id="cb13-2">        guide_tfm<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>, generator<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>, show_each<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>, test_run<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>, gen_kwargs<span class="op" style="color: #5E5E5E;">=</span>{}):</span>
<span id="cb13-3">    <span class="co" style="color: #5E5E5E;">"""Runs a dynamic Classifier-free Guidance experiment. </span></span>
<span id="cb13-4"><span class="co" style="color: #5E5E5E;">    </span></span>
<span id="cb13-5"><span class="co" style="color: #5E5E5E;">    Generates an image for the text `prompt` given all the values in `schedules`.</span></span>
<span id="cb13-6"><span class="co" style="color: #5E5E5E;">    Uses a Guidance Transformation class from the `cf_guidance` library.  </span></span>
<span id="cb13-7"><span class="co" style="color: #5E5E5E;">    Stores the output images with a matching title for plotting. </span></span>
<span id="cb13-8"><span class="co" style="color: #5E5E5E;">    Optionally shows each image as its generated.</span></span>
<span id="cb13-9"><span class="co" style="color: #5E5E5E;">    If `test_run` is true, it runs a single schedule for testing. </span></span>
<span id="cb13-10"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb13-11">    <span class="co" style="color: #5E5E5E;"># store generated images and their title (the experiment name)</span></span>
<span id="cb13-12">    images, titles <span class="op" style="color: #5E5E5E;">=</span> [], []</span>
<span id="cb13-13">    </span>
<span id="cb13-14">    <span class="co" style="color: #5E5E5E;"># make sure we have a valid guidance transform</span></span>
<span id="cb13-15">    <span class="cf" style="color: #003B4F;">assert</span> guide_tfm</span>
<span id="cb13-16">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Using Guidance Transform: </span><span class="sc" style="color: #5E5E5E;">{</span>guide_tfm<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb13-17">    </span>
<span id="cb13-18">    <span class="co" style="color: #5E5E5E;"># optionally run a single test schedule</span></span>
<span id="cb13-19">    <span class="cf" style="color: #003B4F;">if</span> test_run:</span>
<span id="cb13-20">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Running a single schedule for testing.'</span>)</span>
<span id="cb13-21">        schedules <span class="op" style="color: #5E5E5E;">=</span> schedules[:<span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb13-22">        </span>
<span id="cb13-23">    <span class="co" style="color: #5E5E5E;"># run all schedule experiments</span></span>
<span id="cb13-24">    <span class="cf" style="color: #003B4F;">for</span> i,s <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(schedules):</span>
<span id="cb13-25">        </span>
<span id="cb13-26">        <span class="co" style="color: #5E5E5E;"># parse out the title for the current run</span></span>
<span id="cb13-27">        cur_title  <span class="op" style="color: #5E5E5E;">=</span> s[<span class="st" style="color: #20794D;">'title'</span>]</span>
<span id="cb13-28">        titles.append(cur_title)</span>
<span id="cb13-29">        </span>
<span id="cb13-30">        <span class="co" style="color: #5E5E5E;"># create the guidance transformation </span></span>
<span id="cb13-31">        cur_sched <span class="op" style="color: #5E5E5E;">=</span> s[<span class="st" style="color: #20794D;">'schedule'</span>]</span>
<span id="cb13-32">        gtfm <span class="op" style="color: #5E5E5E;">=</span> guide_tfm({<span class="st" style="color: #20794D;">'g'</span>: cur_sched})</span>
<span id="cb13-33">        </span>
<span id="cb13-34">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Running experiment [</span><span class="sc" style="color: #5E5E5E;">{</span>i<span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;"> of </span><span class="sc" style="color: #5E5E5E;">{</span><span class="bu" style="color: null;">len</span>(schedules)<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">]: </span><span class="sc" style="color: #5E5E5E;">{</span>cur_title<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">...'</span>)</span>
<span id="cb13-35">        img <span class="op" style="color: #5E5E5E;">=</span> pipeline.generate(prompt, gtfm, <span class="op" style="color: #5E5E5E;">**</span>gen_kwargs)</span>
<span id="cb13-36">        images.append(img)</span>
<span id="cb13-37">        </span>
<span id="cb13-38">        <span class="co" style="color: #5E5E5E;"># optionally plot the image</span></span>
<span id="cb13-39">        <span class="cf" style="color: #003B4F;">if</span> show_each:</span>
<span id="cb13-40">            show_image(img, scale<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb13-41">            </span>
<span id="cb13-42">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Done.'</span>)</span>
<span id="cb13-43">    <span class="cf" style="color: #003B4F;">return</span> {<span class="st" style="color: #20794D;">'images'</span>: images,</span>
<span id="cb13-44">            <span class="st" style="color: #20794D;">'titles'</span>: titles}</span></code></pre></div>
</div>
</section>
<section id="gathering-models-and-arguments" class="level1">
<h1>Gathering models and arguments</h1>
<p>Next we create the arguments and parameters to run different models.</p>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"></span>
<span id="cb14-2"><span class="co" style="color: #5E5E5E;"># group the different models to run</span></span>
<span id="cb14-3">model_expts <span class="op" style="color: #5E5E5E;">=</span> [</span>
<span id="cb14-4"></span>
<span id="cb14-5">    <span class="co" style="color: #5E5E5E;"># SD v1-4</span></span>
<span id="cb14-6">    {<span class="st" style="color: #20794D;">'model_name'</span>: <span class="st" style="color: #20794D;">'CompVis/stable-diffusion-v1-4'</span>,</span>
<span id="cb14-7">     <span class="st" style="color: #20794D;">'model_kwargs'</span>: {<span class="st" style="color: #20794D;">'better_vae'</span>: <span class="st" style="color: #20794D;">'mse'</span>}},</span>
<span id="cb14-8">    <span class="co" style="color: #5E5E5E;"># SD v1-5</span></span>
<span id="cb14-9">    {<span class="st" style="color: #20794D;">'model_name'</span>: <span class="st" style="color: #20794D;">'runwayml/stable-diffusion-v1-5'</span>,</span>
<span id="cb14-10">     <span class="st" style="color: #20794D;">'model_kwargs'</span>: {<span class="st" style="color: #20794D;">'better_vae'</span>: <span class="st" style="color: #20794D;">'mse'</span>}},</span>
<span id="cb14-11">    <span class="co" style="color: #5E5E5E;"># openjourney</span></span>
<span id="cb14-12">    {<span class="st" style="color: #20794D;">'model_name'</span>: <span class="st" style="color: #20794D;">"prompthero/openjourney"</span>,</span>
<span id="cb14-13">     <span class="st" style="color: #20794D;">'model_kwargs'</span>: {}},</span>
<span id="cb14-14">    <span class="co" style="color: #5E5E5E;"># SD 2-base</span></span>
<span id="cb14-15">    {<span class="st" style="color: #20794D;">'model_name'</span>: <span class="st" style="color: #20794D;">'stabilityai/stable-diffusion-2-base'</span>,</span>
<span id="cb14-16">     <span class="st" style="color: #20794D;">'model_kwargs'</span>: {<span class="st" style="color: #20794D;">'unet_attn_slice'</span>: <span class="va" style="color: #111111;">False</span>}},</span>
<span id="cb14-17">    <span class="co" style="color: #5E5E5E;"># # SD 2</span></span>
<span id="cb14-18">    <span class="co" style="color: #5E5E5E;"># {'model_name': 'stabilityai/stable-diffusion-2',</span></span>
<span id="cb14-19">    <span class="co" style="color: #5E5E5E;">#  'model_kwargs': {'unet_attn_slice': False}},</span></span>
<span id="cb14-20"></span>
<span id="cb14-21">]</span></code></pre></div>
</div>
<section id="creating-the-baseline-image-with-g-7.5" class="level2">
<h2 class="anchored" data-anchor-id="creating-the-baseline-image-with-g-7.5">Creating the baseline image with <img src="https://latex.codecogs.com/png.latex?G%20=%207.5"></h2>
<p>First we create the baseline image using a constant Classifier-free Guidance with <img src="https://latex.codecogs.com/png.latex?G%20=%207.5">. Since this is a constant schedule, <img src="https://latex.codecogs.com/png.latex?k"> does not come into play.</p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="co" style="color: #5E5E5E;"># create the baseline schedule with the new function</span></span>
<span id="cb15-2">baseline_g <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">7.5</span></span>
<span id="cb15-3">baseline_params <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'max_val'</span>: [baseline_g]}</span>
<span id="cb15-4">baseline_func <span class="op" style="color: #5E5E5E;">=</span> <span class="kw" style="color: #003B4F;">lambda</span> <span class="op" style="color: #5E5E5E;">*</span>args, <span class="op" style="color: #5E5E5E;">**</span>kwargs: [baseline_g <span class="cf" style="color: #003B4F;">for</span> _ <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(num_steps)]</span>
<span id="cb15-5">baseline_expts <span class="op" style="color: #5E5E5E;">=</span> create_expts(baseline_params, baseline_func)</span>
<span id="cb15-6"></span>
<span id="cb15-7"></span>
<span id="cb15-8">T_baseline_g <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.15</span></span>
<span id="cb15-9">T_baseline_params <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'max_val'</span>: [T_baseline_g]}</span>
<span id="cb15-10">T_baseline_func <span class="op" style="color: #5E5E5E;">=</span> <span class="kw" style="color: #003B4F;">lambda</span> <span class="op" style="color: #5E5E5E;">*</span>args, <span class="op" style="color: #5E5E5E;">**</span>kwargs: [T_baseline_g <span class="cf" style="color: #003B4F;">for</span> _ <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(num_steps)]</span>
<span id="cb15-11">T_baseline_expts <span class="op" style="color: #5E5E5E;">=</span> create_expts(T_baseline_params, T_baseline_func)</span></code></pre></div>
</div>
</section>
<section id="improving-the-baseline-with-schedules-and-normalizations" class="level2">
<h2 class="anchored" data-anchor-id="improving-the-baseline-with-schedules-and-normalizations">Improving the baseline with schedules and normalizations</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">outputs <span class="op" style="color: #5E5E5E;">=</span> {}</span>
<span id="cb16-2"></span>
<span id="cb16-3">device <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'cuda'</span></span>
<span id="cb16-4">dtype <span class="op" style="color: #5E5E5E;">=</span> torch.float16</span>
<span id="cb16-5"></span>
<span id="cb16-6"><span class="cf" style="color: #003B4F;">for</span> mparams <span class="kw" style="color: #003B4F;">in</span> model_expts:</span>
<span id="cb16-7">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Running model: </span><span class="sc" style="color: #5E5E5E;">{</span>mparams<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb16-8">    </span>
<span id="cb16-9">    model_name <span class="op" style="color: #5E5E5E;">=</span> mparams[<span class="st" style="color: #20794D;">'model_name'</span>]</span>
<span id="cb16-10">    model_kwargs <span class="op" style="color: #5E5E5E;">=</span> mparams[<span class="st" style="color: #20794D;">'model_kwargs'</span>]</span>
<span id="cb16-11">    </span>
<span id="cb16-12">    <span class="co" style="color: #5E5E5E;"># a bit of a manual patch, we need a keyword for openjourney model</span></span>
<span id="cb16-13">    <span class="cf" style="color: #003B4F;">if</span> <span class="st" style="color: #20794D;">'openjourney'</span> <span class="kw" style="color: #003B4F;">in</span> model_name:</span>
<span id="cb16-14">        cur_prompt <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"mdjrny-v4 style "</span> <span class="op" style="color: #5E5E5E;">+</span> prompt</span>
<span id="cb16-15">    <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb16-16">        cur_prompt <span class="op" style="color: #5E5E5E;">=</span> prompt</span>
<span id="cb16-17">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Using prompt: </span><span class="sc" style="color: #5E5E5E;">{</span>cur_prompt<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb16-18">    </span>
<span id="cb16-19">    <span class="cf" style="color: #003B4F;">if</span> model_name <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">'stabilityai/stable-diffusion-2'</span>:</span>
<span id="cb16-20">        gen_kwargs <span class="op" style="color: #5E5E5E;">=</span> sd2_dims</span>
<span id="cb16-21">    <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb16-22">        gen_kwargs <span class="op" style="color: #5E5E5E;">=</span> sd_dims</span>
<span id="cb16-23">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Generation kwargs: </span><span class="sc" style="color: #5E5E5E;">{</span>gen_kwargs<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb16-24">    </span>
<span id="cb16-25">    <span class="co" style="color: #5E5E5E;"># load the current Diffusion model</span></span>
<span id="cb16-26">    pipeline <span class="op" style="color: #5E5E5E;">=</span> load_sd_model(model_name, device, dtype, generator<span class="op" style="color: #5E5E5E;">=</span>generator,</span>
<span id="cb16-27">                             model_kwargs<span class="op" style="color: #5E5E5E;">=</span>model_kwargs)</span>
<span id="cb16-28">    </span>
<span id="cb16-29">    <span class="co" style="color: #5E5E5E;"># make the baseline for this model</span></span>
<span id="cb16-30">    baseline_res <span class="op" style="color: #5E5E5E;">=</span> run(pipeline, cur_prompt, baseline_expts, gen_kwargs<span class="op" style="color: #5E5E5E;">=</span>gen_kwargs,</span>
<span id="cb16-31">                       guide_tfm<span class="op" style="color: #5E5E5E;">=</span>GuidanceTfm, generator<span class="op" style="color: #5E5E5E;">=</span>generator)</span>
<span id="cb16-32">    outputs[(model_name,<span class="st" style="color: #20794D;">'baseline'</span>)] <span class="op" style="color: #5E5E5E;">=</span> baseline_res</span>
<span id="cb16-33">    </span>
<span id="cb16-34">    <span class="co" style="color: #5E5E5E;"># generate images with different normalizations and schedules</span></span>
<span id="cb16-35">    base_norm_res <span class="op" style="color: #5E5E5E;">=</span> run(pipeline, cur_prompt, baseline_expts <span class="op" style="color: #5E5E5E;">+</span> all_k_expts, gen_kwargs<span class="op" style="color: #5E5E5E;">=</span>gen_kwargs,</span>
<span id="cb16-36">                        guide_tfm<span class="op" style="color: #5E5E5E;">=</span>BaseNormGuidance, generator<span class="op" style="color: #5E5E5E;">=</span>generator)</span>
<span id="cb16-37">    outputs[(model_name,<span class="st" style="color: #20794D;">'baseNorm'</span>)] <span class="op" style="color: #5E5E5E;">=</span> base_norm_res</span>
<span id="cb16-38">                            </span>
<span id="cb16-39">    T_res <span class="op" style="color: #5E5E5E;">=</span> run(pipeline, cur_prompt, T_baseline_expts <span class="op" style="color: #5E5E5E;">+</span> all_T_k_expts, gen_kwargs<span class="op" style="color: #5E5E5E;">=</span>gen_kwargs,</span>
<span id="cb16-40">                guide_tfm<span class="op" style="color: #5E5E5E;">=</span>TNormGuidance, generator<span class="op" style="color: #5E5E5E;">=</span>generator)</span>
<span id="cb16-41">    outputs[(model_name,<span class="st" style="color: #20794D;">'TNorm'</span>)] <span class="op" style="color: #5E5E5E;">=</span> T_res</span>
<span id="cb16-42"></span>
<span id="cb16-43">    full_res <span class="op" style="color: #5E5E5E;">=</span> run(pipeline, cur_prompt, T_baseline_expts <span class="op" style="color: #5E5E5E;">+</span> all_T_k_expts, gen_kwargs<span class="op" style="color: #5E5E5E;">=</span>gen_kwargs,</span>
<span id="cb16-44">                   guide_tfm<span class="op" style="color: #5E5E5E;">=</span>FullNormGuidance, generator<span class="op" style="color: #5E5E5E;">=</span>generator)</span>
<span id="cb16-45">    outputs[(model_name,<span class="st" style="color: #20794D;">'FullNorm'</span>)] <span class="op" style="color: #5E5E5E;">=</span> full_res</span>
<span id="cb16-46">    </span>
<span id="cb16-47">    <span class="co" style="color: #5E5E5E;"># cleanup the model for the next run</span></span>
<span id="cb16-48">    <span class="kw" style="color: #003B4F;">del</span> pipeline</span>
<span id="cb16-49">    pipeline <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span></span>
<span id="cb16-50">    torch.cuda.empty_cache()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running model: {'model_name': 'CompVis/stable-diffusion-v1-4', 'model_kwargs': {'better_vae': 'mse'}}
Using prompt: digital painting of hanan pacha, the incan world above us where the sun and moon live, by filipe pagliuso and justin gerard, symmetric, fantasy, realistic, highly detailed, realistic, intricate, sharp focus, tarot card, portrait
Generation kwargs: {'height': 640, 'width': 512}
Using the improved VAE "mse" from stabiliy.ai
Enabling default unet attention slicing.
Using Guidance Transform: &lt;class 'cf_guidance.transforms.GuidanceTfm'&gt;
Running experiment [1 of 1]: Param: "max_val", val=7.5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f54457af83304bf899ed1c2cc69ca530","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.
Using Guidance Transform: &lt;class 'cf_guidance.transforms.BaseNormGuidance'&gt;
Running experiment [1 of 2]: Param: "max_val", val=7.5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"df0c7645d3a04030989576fabdcf8022","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [2 of 2]: Param: "k_decay", val=0.15...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"fe74a56aa16b483f80ec5ba797db6818","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.
Using Guidance Transform: &lt;class 'cf_guidance.transforms.TNormGuidance'&gt;
Running experiment [1 of 2]: Param: "max_val", val=0.15...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"5a0000bd9526423490855fcf91ee3a41","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [2 of 2]: Param: "k_decay", val=0.15...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"356e9f854ab248dfb631d6233f39e8bc","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.
Using Guidance Transform: &lt;class 'cf_guidance.transforms.FullNormGuidance'&gt;
Running experiment [1 of 2]: Param: "max_val", val=0.15...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"400e4d0c9d8843ba9181239bb4b0befd","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [2 of 2]: Param: "k_decay", val=0.15...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"98c22b6b9e3440d589aabf5261c269e0","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.
Running model: {'model_name': 'runwayml/stable-diffusion-v1-5', 'model_kwargs': {'better_vae': 'mse'}}
Using prompt: digital painting of hanan pacha, the incan world above us where the sun and moon live, by filipe pagliuso and justin gerard, symmetric, fantasy, realistic, highly detailed, realistic, intricate, sharp focus, tarot card, portrait
Generation kwargs: {'height': 640, 'width': 512}
Using the improved VAE "mse" from stabiliy.ai
Enabling default unet attention slicing.
Using Guidance Transform: &lt;class 'cf_guidance.transforms.GuidanceTfm'&gt;
Running experiment [1 of 1]: Param: "max_val", val=7.5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"cc9c4a74cd90442e94ae14720e6e9925","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.
Using Guidance Transform: &lt;class 'cf_guidance.transforms.BaseNormGuidance'&gt;
Running experiment [1 of 2]: Param: "max_val", val=7.5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b7fd633375dc4862be652551ad2683a3","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [2 of 2]: Param: "k_decay", val=0.15...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"920b391a199243de817671310d8318f7","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.
Using Guidance Transform: &lt;class 'cf_guidance.transforms.TNormGuidance'&gt;
Running experiment [1 of 2]: Param: "max_val", val=0.15...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1de0cd16a1c843a2af24dc9d7c637fb8","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [2 of 2]: Param: "k_decay", val=0.15...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"2c98767d00e648998be66cdfb02724c2","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.
Using Guidance Transform: &lt;class 'cf_guidance.transforms.FullNormGuidance'&gt;
Running experiment [1 of 2]: Param: "max_val", val=0.15...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"bd0e895e5fac4d6da8d2c7d9a5423d24","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [2 of 2]: Param: "k_decay", val=0.15...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"65c4ed4e7b05448d8a3b92e1b31ab11d","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.
Running model: {'model_name': 'prompthero/openjourney', 'model_kwargs': {}}
Using prompt: mdjrny-v4 style digital painting of hanan pacha, the incan world above us where the sun and moon live, by filipe pagliuso and justin gerard, symmetric, fantasy, realistic, highly detailed, realistic, intricate, sharp focus, tarot card, portrait
Generation kwargs: {'height': 640, 'width': 512}
Enabling default unet attention slicing.
Using Guidance Transform: &lt;class 'cf_guidance.transforms.GuidanceTfm'&gt;
Running experiment [1 of 1]: Param: "max_val", val=7.5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"137cfa0339384d56a4e5894c12c7a92d","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.
Using Guidance Transform: &lt;class 'cf_guidance.transforms.BaseNormGuidance'&gt;
Running experiment [1 of 2]: Param: "max_val", val=7.5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"acf4612343964c3a85f3f6331fc4387a","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [2 of 2]: Param: "k_decay", val=0.15...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"59a30ac6bc2948c8b3ea5cee12fb86ed","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.
Using Guidance Transform: &lt;class 'cf_guidance.transforms.TNormGuidance'&gt;
Running experiment [1 of 2]: Param: "max_val", val=0.15...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ad28ff3ce0df496c897d7f676ba6bdd1","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [2 of 2]: Param: "k_decay", val=0.15...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"3173ffd783f34c9eba6e210c32f493a5","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.
Using Guidance Transform: &lt;class 'cf_guidance.transforms.FullNormGuidance'&gt;
Running experiment [1 of 2]: Param: "max_val", val=0.15...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f0b08564bffb4c5c844e7e005798a358","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [2 of 2]: Param: "k_decay", val=0.15...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"5a306d9a5e4d4f9184c7f5be81a4b9de","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.
Running model: {'model_name': 'stabilityai/stable-diffusion-2-base', 'model_kwargs': {'unet_attn_slice': False}}
Using prompt: digital painting of hanan pacha, the incan world above us where the sun and moon live, by filipe pagliuso and justin gerard, symmetric, fantasy, realistic, highly detailed, realistic, intricate, sharp focus, tarot card, portrait
Generation kwargs: {'height': 640, 'width': 512}
Using Guidance Transform: &lt;class 'cf_guidance.transforms.GuidanceTfm'&gt;
Running experiment [1 of 1]: Param: "max_val", val=7.5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"dc70fb537a544fbab844ab165f32a6a6","version_major":2,"version_minor":0}
</script>
</div>
</div>
</section>
</section>
<section id="results" class="level1">
<h1>Results</h1>
<p>Let’s make some helpers to grab all output images for a given Stable Diffusion model.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb39" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><span class="co" style="color: #5E5E5E;"># names of all the models we tried</span></span>
<span id="cb39-2">model_names <span class="op" style="color: #5E5E5E;">=</span> [</span>
<span id="cb39-3">    <span class="st" style="color: #20794D;">'CompVis/stable-diffusion-v1-4'</span>,</span>
<span id="cb39-4">    <span class="st" style="color: #20794D;">'runwayml/stable-diffusion-v1-5'</span>,</span>
<span id="cb39-5">    <span class="st" style="color: #20794D;">'prompthero/openjourney'</span>,</span>
<span id="cb39-6">    <span class="st" style="color: #20794D;">'stabilityai/stable-diffusion-2-base'</span>,</span>
<span id="cb39-7">]</span>
<span id="cb39-8"></span>
<span id="cb39-9"><span class="co" style="color: #5E5E5E;"># number of images to plot</span></span>
<span id="cb39-10">num_runs <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">2</span></span>
<span id="cb39-11">num_rows <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb39-12"></span>
<span id="cb39-13"><span class="co" style="color: #5E5E5E;"># plot dimensions</span></span>
<span id="cb39-14">plot_height, plot_width <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">640</span>, <span class="dv" style="color: #AD0000;">512</span></span>
<span id="cb39-15"></span>
<span id="cb39-16"><span class="kw" style="color: #003B4F;">def</span> get_results(model_name):</span>
<span id="cb39-17">    types <span class="op" style="color: #5E5E5E;">=</span> [<span class="st" style="color: #20794D;">'baseline'</span>, <span class="st" style="color: #20794D;">'baseNorm'</span>, <span class="st" style="color: #20794D;">'TNorm'</span>, <span class="st" style="color: #20794D;">'FullNorm'</span>]</span>
<span id="cb39-18">    <span class="cf" style="color: #003B4F;">return</span> [outputs[(model_name,t)] <span class="cf" style="color: #003B4F;">for</span> t <span class="kw" style="color: #003B4F;">in</span> types]</span>
<span id="cb39-19"></span>
<span id="cb39-20"><span class="kw" style="color: #003B4F;">def</span> plot_all_results(model_name):</span>
<span id="cb39-21">    mres <span class="op" style="color: #5E5E5E;">=</span> get_results(model_name)</span>
<span id="cb39-22">    <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(num_runs):</span>
<span id="cb39-23">        image_grid(</span>
<span id="cb39-24">            [mres[<span class="dv" style="color: #AD0000;">0</span>][<span class="st" style="color: #20794D;">'images'</span>][<span class="dv" style="color: #AD0000;">0</span>]] <span class="op" style="color: #5E5E5E;">+</span> [o[<span class="st" style="color: #20794D;">'images'</span>][i] <span class="cf" style="color: #003B4F;">for</span> o <span class="kw" style="color: #003B4F;">in</span> mres[<span class="dv" style="color: #AD0000;">1</span>:]], </span>
<span id="cb39-25">            title<span class="op" style="color: #5E5E5E;">=</span>[mres[<span class="dv" style="color: #AD0000;">0</span>][<span class="st" style="color: #20794D;">'titles'</span>][<span class="dv" style="color: #AD0000;">0</span>]] <span class="op" style="color: #5E5E5E;">+</span> [o[<span class="st" style="color: #20794D;">'titles'</span>][i] <span class="cf" style="color: #003B4F;">for</span> o <span class="kw" style="color: #003B4F;">in</span> mres[<span class="dv" style="color: #AD0000;">1</span>:]],</span>
<span id="cb39-26">            rows<span class="op" style="color: #5E5E5E;">=</span>num_rows, width<span class="op" style="color: #5E5E5E;">=</span>plot_width, height<span class="op" style="color: #5E5E5E;">=</span>plot_height</span>
<span id="cb39-27">        )</span>
<span id="cb39-28">        plt.suptitle(<span class="ss" style="color: #20794D;">f'Model: </span><span class="sc" style="color: #5E5E5E;">{</span>model_name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;"> | Output #</span><span class="sc" style="color: #5E5E5E;">{</span>i<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span></code></pre></div>
</div>
</section>
<section id="sd-1-4" class="level1">
<h1>SD 1-4</h1>
<div class="cell">
<div class="sourceCode cell-code" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1">plot_all_results(<span class="st" style="color: #20794D;">'CompVis/stable-diffusion-v1-4'</span>)</span></code></pre></div>
</div>
</section>
<section id="sd-1-5" class="level1">
<h1>SD 1-5</h1>
<div class="cell">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1">plot_all_results(<span class="st" style="color: #20794D;">'runwayml/stable-diffusion-v1-5'</span>)</span></code></pre></div>
</div>
</section>
<section id="openjourney" class="level1">
<h1>openjourney</h1>
<div class="cell">
<div class="sourceCode cell-code" id="cb42" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1">plot_all_results(<span class="st" style="color: #20794D;">'prompthero/openjourney'</span>)</span></code></pre></div>
</div>
</section>
<section id="sd-2-base" class="level1">
<h1>SD 2-base</h1>
<div class="cell">
<div class="sourceCode cell-code" id="cb43" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1">plot_all_results(<span class="st" style="color: #20794D;">'stabilityai/stable-diffusion-2-base'</span>)</span></code></pre></div>
</div>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>


</section>

 ]]></description>
  <category>diffusion</category>
  <category>classifier-free guidance</category>
  <category>deep learning</category>
  <guid>https://enzokro.dev/blog/posts/2022-11-26-guidance-expts-8/index.html</guid>
  <pubDate>Sat, 26 Nov 2022 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Classifier-free Guidance with Cosine Schedules Pt. 5</title>
  <dc:creator>enzokro</dc:creator>
  <link>https://enzokro.dev/blog/posts/2022-11-24-guidance-expts-6/index.html</link>
  <description><![CDATA[ 



<blockquote class="blockquote">
<p>Exploring a range of guidance values for T-Normalization.</p>
</blockquote>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>This notebook is Part 5 in a <a href="https://enzokro.dev/blog/posts/2022-11-15-guidance-expts-5">series</a> on dynamic Classifier-free Guidance. It explores smaller <img src="https://latex.codecogs.com/png.latex?G"> values for normalizations.</p>
<section id="recap-of-parts-1-4" class="level2">
<h2 class="anchored" data-anchor-id="recap-of-parts-1-4">Recap of Parts 1-4</h2>
<p>The first three parts explored how to turn Classifier-free Guidance into a dynamic process. We found an initial set of schedules and normalizers that seem to improve the quality of Diffusion images. We then dug in and refined a few of the most promising schedules.</p>
</section>
<section id="part-5-exploring-values-for-t-normalization" class="level2">
<h2 class="anchored" data-anchor-id="part-5-exploring-values-for-t-normalization">Part 5: Exploring values for <code>T-Normalization</code></h2>
<p>Part 5 answers the question: what should the value of <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bsmall%7D"> be for <code>T-Normalization</code> and <code>Full Normalization</code>?</p>
<p>Recall that these two normalizations scale the update vector <img src="https://latex.codecogs.com/png.latex?%5Cleft(t%20-%20u%20%5Cright)">. That places the update vector on a different scale than the unconditioned vector <img src="https://latex.codecogs.com/png.latex?u">. If we then scaled the update vector by a large scalar, say <img src="https://latex.codecogs.com/png.latex?G%20=%207.5">, the output collapses to noise. In fact it seems to collapse to the true mode of the latent image distribution: uniform, brown values.</p>
<p>These two normalizations are very promising: they improve the syntax and details of the image. However, we only explored a single value of <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bsmall%7D%20=%200.15">. This is very different from the default <img src="https://latex.codecogs.com/png.latex?G%20=%207.5"> that has been truly explored in regular Classifier-free Guidance.</p>
<p>This notebook tries to find a good starting point for <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bsmall%7D">, so we can try the normalizations with our best schedules so far.</p>
</section>
</section>
<section id="python-imports" class="level1">
<h1>Python imports</h1>
<p>We start with a few basic python imports.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> os</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> random</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">from</span> functools <span class="im" style="color: #00769E;">import</span> partial</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-6"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb1-7"><span class="im" style="color: #00769E;">import</span> matplotlib.colors <span class="im" style="color: #00769E;">as</span> mcolors</span></code></pre></div>
</div>
<section id="seed-for-reproducibility" class="level2">
<h2 class="anchored" data-anchor-id="seed-for-reproducibility">Seed for reproducibility</h2>
<p><code>seed_everything</code> makes sure that the results are reproducible across notebooks.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;"># set the seed and pseudo random number generator</span></span>
<span id="cb2-2">SEED <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1024</span></span>
<span id="cb2-3"><span class="kw" style="color: #003B4F;">def</span> seed_everything(seed):</span>
<span id="cb2-4">    random.seed(seed)</span>
<span id="cb2-5">    os.environ[<span class="st" style="color: #20794D;">'PYTHONHASHSEED'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">str</span>(seed)</span>
<span id="cb2-6">    np.random.seed(seed)</span>
<span id="cb2-7">    generator <span class="op" style="color: #5E5E5E;">=</span> torch.manual_seed(seed)</span>
<span id="cb2-8">    torch.backends.cudnn.deterministic <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">True</span></span>
<span id="cb2-9">    torch.backends.cudnn.benchmark <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">False</span></span>
<span id="cb2-10">    <span class="cf" style="color: #003B4F;">return</span> generator</span>
<span id="cb2-11"></span>
<span id="cb2-12"><span class="co" style="color: #5E5E5E;"># for sampling the initial, noisy latents</span></span>
<span id="cb2-13">generator <span class="op" style="color: #5E5E5E;">=</span> seed_everything(SEED)</span></code></pre></div>
</div>
</section>
</section>
<section id="constant-schedules-with-a-range-of-g_textsmall-values" class="level1">
<h1>Constant schedules with a range of <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bsmall%7D"> values</h1>
<p>We can try different <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bsmall%7D"> values using the <code>cf_guidance</code> library.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;"># helpers to create cosine schedules</span></span>
<span id="cb3-2"><span class="im" style="color: #00769E;">from</span> cf_guidance.schedules  <span class="im" style="color: #00769E;">import</span> get_cos_sched</span>
<span id="cb3-3"></span>
<span id="cb3-4"><span class="co" style="color: #5E5E5E;"># normalizations for classifier-free guidance</span></span>
<span id="cb3-5"><span class="im" style="color: #00769E;">from</span> cf_guidance.transforms <span class="im" style="color: #00769E;">import</span> TNormGuidance, FullNormGuidance</span></code></pre></div>
</div>
<p>For the other schedule parameters, we will use the <a href="https://enzokro.dev/blog/posts/2022-11-20-guidance-expts-2/#default-schedule-parameters">same values</a> from the running series on dynamic Classifier-free Guidance.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;"># Default schedule parameters from the blog post</span></span>
<span id="cb4-2"><span class="co" style="color: #5E5E5E;">######################################</span></span>
<span id="cb4-3">max_val           <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.15</span>  <span class="co" style="color: #5E5E5E;"># guidance scaling value</span></span>
<span id="cb4-4">min_val           <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.0</span>   <span class="co" style="color: #5E5E5E;"># minimum guidance scaling</span></span>
<span id="cb4-5">num_steps         <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">50</span>    <span class="co" style="color: #5E5E5E;"># number of diffusion steps</span></span>
<span id="cb4-6">num_warmup_steps  <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span>     <span class="co" style="color: #5E5E5E;"># number of warmup steps</span></span>
<span id="cb4-7">warmup_init_val   <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span>     <span class="co" style="color: #5E5E5E;"># the intial warmup value</span></span>
<span id="cb4-8">num_cycles        <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.5</span>   <span class="co" style="color: #5E5E5E;"># number of cosine cycles</span></span>
<span id="cb4-9">k_decay           <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span>     <span class="co" style="color: #5E5E5E;"># k-decay for cosine curve scaling </span></span>
<span id="cb4-10"><span class="co" style="color: #5E5E5E;">######################################</span></span>
<span id="cb4-11"></span>
<span id="cb4-12">DEFAULT_COS_PARAMS <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb4-13">    <span class="st" style="color: #20794D;">'max_val'</span>:           max_val,</span>
<span id="cb4-14">    <span class="st" style="color: #20794D;">'num_steps'</span>:         num_steps,</span>
<span id="cb4-15">    <span class="st" style="color: #20794D;">'min_val'</span>:           min_val,</span>
<span id="cb4-16">    <span class="st" style="color: #20794D;">'num_cycles'</span>:        num_cycles,</span>
<span id="cb4-17">    <span class="st" style="color: #20794D;">'k_decay'</span>:           k_decay,</span>
<span id="cb4-18">    <span class="st" style="color: #20794D;">'num_warmup_steps'</span>:  num_warmup_steps,</span>
<span id="cb4-19">    <span class="st" style="color: #20794D;">'warmup_init_val'</span>:   warmup_init_val,</span>
<span id="cb4-20">}</span>
<span id="cb4-21"></span>
<span id="cb4-22"><span class="kw" style="color: #003B4F;">def</span> cos_harness(new_params<span class="op" style="color: #5E5E5E;">=</span>{}, default_params<span class="op" style="color: #5E5E5E;">=</span>{}):</span>
<span id="cb4-23">    <span class="co" style="color: #5E5E5E;">'''Creates cosine schedules with updated parameters in `new_params`</span></span>
<span id="cb4-24"><span class="co" style="color: #5E5E5E;">    '''</span></span>
<span id="cb4-25">    <span class="co" style="color: #5E5E5E;"># start from the given baseline `cos_params`</span></span>
<span id="cb4-26">    cos_params <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">dict</span>(default_params)</span>
<span id="cb4-27">    <span class="co" style="color: #5E5E5E;"># update the schedule with any new parameters</span></span>
<span id="cb4-28">    cos_params.update(new_params)</span>
<span id="cb4-29">    </span>
<span id="cb4-30">    <span class="co" style="color: #5E5E5E;"># return the new cosine schedule</span></span>
<span id="cb4-31">    sched <span class="op" style="color: #5E5E5E;">=</span> get_cos_sched(<span class="op" style="color: #5E5E5E;">**</span>cos_params)</span>
<span id="cb4-32">    <span class="cf" style="color: #003B4F;">return</span> sched</span>
<span id="cb4-33"></span>
<span id="cb4-34"></span>
<span id="cb4-35"><span class="kw" style="color: #003B4F;">def</span> create_expts(params: <span class="bu" style="color: null;">dict</span>, schedule_func) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="bu" style="color: null;">list</span>:</span>
<span id="cb4-36">    <span class="co" style="color: #5E5E5E;">'''Creates a list of experiments.</span></span>
<span id="cb4-37"><span class="co" style="color: #5E5E5E;">    </span></span>
<span id="cb4-38"><span class="co" style="color: #5E5E5E;">    Each element is a dictionary with the name, value, and schedule for a given parameter.</span></span>
<span id="cb4-39"><span class="co" style="color: #5E5E5E;">    A `title` field is also added for easy plotting.</span></span>
<span id="cb4-40"><span class="co" style="color: #5E5E5E;">    '''</span></span>
<span id="cb4-41">    names <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">sorted</span>(params)</span>
<span id="cb4-42">    expts <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb4-43">    <span class="co" style="color: #5E5E5E;"># step through parameter names and their values</span></span>
<span id="cb4-44">    <span class="cf" style="color: #003B4F;">for</span> i,name <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(names):</span>
<span id="cb4-45">        <span class="cf" style="color: #003B4F;">for</span> j,val <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(params[name]):</span>
<span id="cb4-46">            <span class="co" style="color: #5E5E5E;"># create the experiment</span></span>
<span id="cb4-47">            expt <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'param_name'</span>: name,</span>
<span id="cb4-48">                    <span class="st" style="color: #20794D;">'val'</span>: val,</span>
<span id="cb4-49">                    <span class="st" style="color: #20794D;">'schedule'</span>: schedule_func(val)}</span>
<span id="cb4-50">                    <span class="co" style="color: #5E5E5E;"># 'schedule': schedule_func({name: val})}</span></span>
<span id="cb4-51">            <span class="co" style="color: #5E5E5E;"># name for plotting</span></span>
<span id="cb4-52">            expt[<span class="st" style="color: #20794D;">'title'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="ss" style="color: #20794D;">f'Param: "</span><span class="sc" style="color: #5E5E5E;">{</span>name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">", val=</span><span class="sc" style="color: #5E5E5E;">{</span>val<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb4-53">            <span class="co" style="color: #5E5E5E;"># add it to the experiment list</span></span>
<span id="cb4-54">            expts.append(expt)</span>
<span id="cb4-55">    <span class="cf" style="color: #003B4F;">return</span> expts</span>
<span id="cb4-56"></span>
<span id="cb4-57"></span>
<span id="cb4-58"><span class="co" style="color: #5E5E5E;"># create the constant G_small cosine experiments</span></span>
<span id="cb4-59">const_params <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'max_val'</span>: [<span class="fl" style="color: #AD0000;">0.01</span>, <span class="fl" style="color: #AD0000;">0.03</span>, <span class="fl" style="color: #AD0000;">0.05</span>, <span class="fl" style="color: #AD0000;">0.08</span>, <span class="fl" style="color: #AD0000;">0.1</span>, <span class="fl" style="color: #AD0000;">0.15</span>, <span class="fl" style="color: #AD0000;">0.2</span>, <span class="fl" style="color: #AD0000;">0.22</span>, <span class="fl" style="color: #AD0000;">0.25</span>, <span class="fl" style="color: #AD0000;">0.3</span>]}</span>
<span id="cb4-60">const_func <span class="op" style="color: #5E5E5E;">=</span> <span class="kw" style="color: #003B4F;">lambda</span> val: [val <span class="cf" style="color: #003B4F;">for</span> _ <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(num_steps)]</span>
<span id="cb4-61">const_expts <span class="op" style="color: #5E5E5E;">=</span> create_expts(const_params, const_func)</span></code></pre></div>
</div>
</section>
<section id="plotting-the-g_textsmall-values" class="level1">
<h1>Plotting the <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bsmall%7D"> values</h1>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-24-guidance-expts-6/index_files/figure-html/cell-6-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="loading-the-openjourney-model-from-prompt-hero" class="level1">
<h1>Loading the <code>openjourney</code> model from Prompt Hero</h1>
<p>The <code>min_diffusion</code> library loads a Stable Diffusion model from the HuggingFace hub.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="co" style="color: #5E5E5E;"># to load Stable Diffusion pipelines</span></span>
<span id="cb5-2"><span class="im" style="color: #00769E;">from</span> min_diffusion.core <span class="im" style="color: #00769E;">import</span> MinimalDiffusion</span>
<span id="cb5-3"></span>
<span id="cb5-4"><span class="co" style="color: #5E5E5E;"># to plot generated images</span></span>
<span id="cb5-5"><span class="im" style="color: #00769E;">from</span> min_diffusion.utils <span class="im" style="color: #00769E;">import</span> show_image, image_grid, plot_grid</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2022-11-24 20:59:11.535760: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0</code></pre>
</div>
</div>
<p>We use it to load the <code>openjourney</code> model on the GPU in <code>torch.float16</code> precision.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">model_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'prompthero/openjourney'</span></span>
<span id="cb7-2">device     <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'cuda'</span></span>
<span id="cb7-3">dtype      <span class="op" style="color: #5E5E5E;">=</span> torch.float16</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">pipeline <span class="op" style="color: #5E5E5E;">=</span> MinimalDiffusion(model_name, device, dtype, generator<span class="op" style="color: #5E5E5E;">=</span>generator)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">pipeline.load()<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Enabling default unet attention slicing.</code></pre>
</div>
</div>
</section>
<section id="text-prompt-for-image-generations" class="level1">
<h1>Text prompt for image generations</h1>
<p>We use the familiar, running prompt in our series to generate an image:</p>
<blockquote class="blockquote">
<p>“a photograph of an astronaut riding a horse”</p>
</blockquote>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>The <code>openjourney</code> model was fine-tuned to create images in the style of <a href="https://mezha.media/en/2022/11/11/midjourney-v4-is-an-incredible-new-version-of-the-ai-image-generator/">Midjourney v4</a>.</p>
<p>To enable this fine-tuned style, we need to add the keyword <code>"mdjrny-v4"</code> at the start of the prompt.</p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="co" style="color: #5E5E5E;"># text prompt for image generations</span></span>
<span id="cb11-2">prompt <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"mdjrny-v4 style a photograph of an astronaut riding a horse"</span></span></code></pre></div>
</div>
<section id="image-parameters" class="level2">
<h2 class="anchored" data-anchor-id="image-parameters">Image parameters</h2>
<p>Images will be generated over <img src="https://latex.codecogs.com/png.latex?50"> diffusion steps. They will have a height and width of <code>512 x 512</code> pixels.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;"># the number of diffusion steps</span></span>
<span id="cb12-2">num_steps <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">50</span></span>
<span id="cb12-3"></span>
<span id="cb12-4"><span class="co" style="color: #5E5E5E;"># generated image dimensions</span></span>
<span id="cb12-5">width, height <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">512</span>, <span class="dv" style="color: #AD0000;">512</span></span></code></pre></div>
</div>
</section>
</section>
<section id="running-the-experiments" class="level1">
<h1>Running the experiments</h1>
<p>The <code>run</code> function below generates images for the given <code>prompt</code>.</p>
<p>It also stores the output images with a matching title for plotting and visualizations.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="kw" style="color: #003B4F;">def</span> run(prompt, schedules, guide_tfm<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>, generator<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb13-2">        show_each<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>, test_run<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>):</span>
<span id="cb13-3">    <span class="co" style="color: #5E5E5E;">"""Runs a dynamic Classifier-free Guidance experiment. </span></span>
<span id="cb13-4"><span class="co" style="color: #5E5E5E;">    </span></span>
<span id="cb13-5"><span class="co" style="color: #5E5E5E;">    Generates an image for the text `prompt` given all the values in `schedules`.</span></span>
<span id="cb13-6"><span class="co" style="color: #5E5E5E;">    Uses a Guidance Transformation class from the `cf_guidance` library.  </span></span>
<span id="cb13-7"><span class="co" style="color: #5E5E5E;">    Stores the output images with a matching title for plotting. </span></span>
<span id="cb13-8"><span class="co" style="color: #5E5E5E;">    Optionally shows each image as its generated.</span></span>
<span id="cb13-9"><span class="co" style="color: #5E5E5E;">    If `test_run` is true, it runs a single schedule for testing. </span></span>
<span id="cb13-10"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb13-11">    <span class="co" style="color: #5E5E5E;"># store generated images and their title (the experiment name)</span></span>
<span id="cb13-12">    images, titles <span class="op" style="color: #5E5E5E;">=</span> [], []</span>
<span id="cb13-13">    </span>
<span id="cb13-14">    <span class="co" style="color: #5E5E5E;"># make sure we have a valid guidance transform</span></span>
<span id="cb13-15">    <span class="cf" style="color: #003B4F;">assert</span> guide_tfm</span>
<span id="cb13-16">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Using Guidance Transform: </span><span class="sc" style="color: #5E5E5E;">{</span>guide_tfm<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb13-17">    </span>
<span id="cb13-18">    <span class="co" style="color: #5E5E5E;"># optionally run a single test schedule</span></span>
<span id="cb13-19">    <span class="cf" style="color: #003B4F;">if</span> test_run:</span>
<span id="cb13-20">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Running a single schedule for testing.'</span>)</span>
<span id="cb13-21">        schedules <span class="op" style="color: #5E5E5E;">=</span> schedules[:<span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb13-22">        </span>
<span id="cb13-23">    <span class="co" style="color: #5E5E5E;"># run all schedule experiments</span></span>
<span id="cb13-24">    <span class="cf" style="color: #003B4F;">for</span> i,s <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(schedules):</span>
<span id="cb13-25">        </span>
<span id="cb13-26">        <span class="co" style="color: #5E5E5E;"># parse out the title for the current run</span></span>
<span id="cb13-27">        cur_title  <span class="op" style="color: #5E5E5E;">=</span> s[<span class="st" style="color: #20794D;">'title'</span>]</span>
<span id="cb13-28">        titles.append(cur_title)</span>
<span id="cb13-29">        </span>
<span id="cb13-30">        <span class="co" style="color: #5E5E5E;"># create the guidance transformation </span></span>
<span id="cb13-31">        cur_sched <span class="op" style="color: #5E5E5E;">=</span> s[<span class="st" style="color: #20794D;">'schedule'</span>]</span>
<span id="cb13-32">        gtfm <span class="op" style="color: #5E5E5E;">=</span> guide_tfm({<span class="st" style="color: #20794D;">'g'</span>: cur_sched})</span>
<span id="cb13-33">        </span>
<span id="cb13-34">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Running experiment [</span><span class="sc" style="color: #5E5E5E;">{</span>i<span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;"> of </span><span class="sc" style="color: #5E5E5E;">{</span><span class="bu" style="color: null;">len</span>(schedules)<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">]: </span><span class="sc" style="color: #5E5E5E;">{</span>cur_title<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">...'</span>)</span>
<span id="cb13-35">        img <span class="op" style="color: #5E5E5E;">=</span> pipeline.generate(prompt, gtfm, generator<span class="op" style="color: #5E5E5E;">=</span>generator)</span>
<span id="cb13-36">        images.append(img)</span>
<span id="cb13-37">        </span>
<span id="cb13-38">        <span class="co" style="color: #5E5E5E;"># optionally plot the image</span></span>
<span id="cb13-39">        <span class="cf" style="color: #003B4F;">if</span> show_each:</span>
<span id="cb13-40">            show_image(img, scale<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb13-41"></span>
<span id="cb13-42">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Done.'</span>)</span>
<span id="cb13-43">    <span class="cf" style="color: #003B4F;">return</span> {<span class="st" style="color: #20794D;">'images'</span>: images,</span>
<span id="cb13-44">            <span class="st" style="color: #20794D;">'titles'</span>: titles}</span></code></pre></div>
</div>
</section>
<section id="sweeping-the-g_textsmall-values" class="level1">
<h1>Sweeping the <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bsmall%7D"> values</h1>
<p>Now we generate images for the range of constant <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bsmall%7D"> values. Then we will check the outputs to see what a good, default value might be.</p>
<section id="t-normalization-with-g_textsmall-sweep" class="level2">
<h2 class="anchored" data-anchor-id="t-normalization-with-g_textsmall-sweep"><code>T-Normalization</code> with <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bsmall%7D"> sweep</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Running the k-Sweep experiments...'</span>)</span>
<span id="cb14-2">t_norm_res <span class="op" style="color: #5E5E5E;">=</span> run(prompt, const_expts, guide_tfm<span class="op" style="color: #5E5E5E;">=</span>TNormGuidance)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running the k-Sweep experiments...
Using Guidance Transform: &lt;class 'cf_guidance.transforms.TNormGuidance'&gt;
Running experiment [1 of 10]: Param: "max_val", val=0.01...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7aaa31a8ca3e4d74b68c85a5048930c7","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [2 of 10]: Param: "max_val", val=0.03...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"745cf26e52b241739b29f65854f6cf61","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [3 of 10]: Param: "max_val", val=0.05...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"733b2ed09b494b11a2eb0031575cd862","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [4 of 10]: Param: "max_val", val=0.08...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"826085513b7549aebbea3545cbbe3033","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [5 of 10]: Param: "max_val", val=0.1...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f2851f72a4154e26bf8fd51ad5cb9ffc","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [6 of 10]: Param: "max_val", val=0.15...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"cbbb7e05f0e94e4cbffe084e4173a630","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [7 of 10]: Param: "max_val", val=0.2...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e47d0a268b9c4b7aaa3c47ef115932ec","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [8 of 10]: Param: "max_val", val=0.22...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"45680c77af124e618981f9d966b90c24","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [9 of 10]: Param: "max_val", val=0.25...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"952b103193784896bad2ed90f8b1e1a0","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [10 of 10]: Param: "max_val", val=0.3...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ffa8575776a74eee8453ed2632f30a38","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.</code></pre>
</div>
</div>
</section>
<section id="full-normalization-with-g_textsmall-sweep" class="level2">
<h2 class="anchored" data-anchor-id="full-normalization-with-g_textsmall-sweep"><code>Full Normalization</code> with <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bsmall%7D"> sweep</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Running the k-Sweep experiments...'</span>)</span>
<span id="cb26-2">full_norm_res <span class="op" style="color: #5E5E5E;">=</span> run(prompt, const_expts, guide_tfm<span class="op" style="color: #5E5E5E;">=</span>FullNormGuidance)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running the k-Sweep experiments...
Using Guidance Transform: &lt;class 'cf_guidance.transforms.FullNormGuidance'&gt;
Running experiment [1 of 10]: Param: "max_val", val=0.01...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b2d07e82a84d42fdb43350bb2b2f6402","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [2 of 10]: Param: "max_val", val=0.03...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f5fd1f1af7bc4561ba8f2429a7ab255d","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [3 of 10]: Param: "max_val", val=0.05...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f2834901df14412ba1d95bcefb97c463","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [4 of 10]: Param: "max_val", val=0.08...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"2f7d1f54bf6145bd99a211e892eb6cfe","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [5 of 10]: Param: "max_val", val=0.1...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e3e9b13f8436413d9853c0990e0f6adb","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [6 of 10]: Param: "max_val", val=0.15...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f9d6d09d3abb467f970ae49af23d07cb","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [7 of 10]: Param: "max_val", val=0.2...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4259db4c31e54010be9b163dd6f315df","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [8 of 10]: Param: "max_val", val=0.22...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ccefd891bf69426982aaf7ae98941170","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [9 of 10]: Param: "max_val", val=0.25...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ba962f66fdc24503b64dc60f5b1681dd","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [10 of 10]: Param: "max_val", val=0.3...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"2f487df6ed8b46b8b6a9b5b6ef7c6af7","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.</code></pre>
</div>
</div>
</section>
</section>
<section id="results" class="level1">
<h1>Results</h1>
<section id="t-normalization-g_textsmall-results" class="level2">
<h2 class="anchored" data-anchor-id="t-normalization-g_textsmall-results"><code>T-Normalization</code> <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bsmall%7D"> results</h2>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-24-guidance-expts-6/index_files/figure-html/cell-16-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="full-normalization-g_textsmall-results" class="level2">
<h2 class="anchored" data-anchor-id="full-normalization-g_textsmall-results"><code>Full Normalization</code> <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bsmall%7D"> results</h2>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-24-guidance-expts-6/index_files/figure-html/cell-17-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="analysis" class="level1">
<h1>Analysis</h1>
<p>The sweet spot for <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bsmall%7D"> seems to be between 0.08 and 0.2. But, there are some massive changes between the values. Much more than was expected.</p>
<p>It seems that values below 0.08 are too small. The images never form or are too abstract. Likewise, values above 0.2 start to smear the image with weird colors. Both of these results could be ok for artistic generations, but in this case we are trying to improve the realism and quality of the images.</p>
<section id="phase-change-in-the-image" class="level2">
<h2 class="anchored" data-anchor-id="phase-change-in-the-image">Phase change in the image</h2>
<p>Most interesting, there is a “phase change” between the values of 0.08 and 0.1. The image completely changes style and pose from the previous results we’ve seen so far in the series. This phase change on its own deserves more exploration! What happens around these values of <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bsmall%7D">?</p>
<p>Let’s re-run experiments focused on this range. We will pick 10 points uniformly spread between 0.08 and 0.1 to see if we can catch where the phase changes.</p>
</section>
</section>
<section id="re-runs-to-find-the-phase-change" class="level1">
<h1>Re-runs to find the phase change</h1>
<div class="cell">
<div class="sourceCode cell-code" id="cb38" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1">low_bound <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.08</span></span>
<span id="cb38-2">hi_bound <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.102</span></span>
<span id="cb38-3">npoints <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">11</span></span>
<span id="cb38-4"></span>
<span id="cb38-5">points <span class="op" style="color: #5E5E5E;">=</span> np.linspace(low_bound, hi_bound, npoints<span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span>)<span class="op" style="color: #5E5E5E;">;</span> points</span></code></pre></div>
<div class="cell-output cell-output-display">
<pre><code>array([0.08 , 0.082, 0.084, 0.086, 0.088, 0.09 , 0.092, 0.094, 0.096,
       0.098, 0.1  , 0.102])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb40" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><span class="co" style="color: #5E5E5E;"># create the constant G_small cosine experiments</span></span>
<span id="cb40-2">phase_params <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'max_val'</span>: <span class="bu" style="color: null;">list</span>(points)}</span>
<span id="cb40-3">phase_func <span class="op" style="color: #5E5E5E;">=</span> <span class="kw" style="color: #003B4F;">lambda</span> val: [val <span class="cf" style="color: #003B4F;">for</span> _ <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(num_steps)]</span>
<span id="cb40-4">phase_expts <span class="op" style="color: #5E5E5E;">=</span> create_expts(phase_params, phase_func)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Running the phase change k-Sweep experiments...'</span>)</span>
<span id="cb41-2">phase_res <span class="op" style="color: #5E5E5E;">=</span> run(prompt, phase_expts, guide_tfm<span class="op" style="color: #5E5E5E;">=</span>TNormGuidance)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running the phase change k-Sweep experiments...
Using Guidance Transform: &lt;class 'cf_guidance.transforms.TNormGuidance'&gt;
Running experiment [1 of 12]: Param: "max_val", val=0.08...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4548f35e9803418b95a429525613d79f","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [2 of 12]: Param: "max_val", val=0.082...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"61f0a29ab9444da6b002781a95f57182","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [3 of 12]: Param: "max_val", val=0.084...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"89490647f2b44f4696f6a3e1b85f07e6","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [4 of 12]: Param: "max_val", val=0.086...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c10d19e8cde84ee2968d81768ed0759c","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [5 of 12]: Param: "max_val", val=0.088...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"fb06ed41d28247b091aff5eedeff6010","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [6 of 12]: Param: "max_val", val=0.09...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4835c391f40240b3b31577f458f6c83f","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [7 of 12]: Param: "max_val", val=0.092...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b2e6736de1714388bb394382a2e32005","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [8 of 12]: Param: "max_val", val=0.094...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b965e3f1e1d14d76b9545002a078d994","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [9 of 12]: Param: "max_val", val=0.096...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"8924e63e79184dee94db9310c84384ea","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [10 of 12]: Param: "max_val", val=0.09799999999999999...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"67907e6646b64c24a05cdae36f288c68","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [11 of 12]: Param: "max_val", val=0.09999999999999999...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"372d26ee09204e7bab94d51b31f8e445","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [12 of 12]: Param: "max_val", val=0.102...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"9bd3fcf2443747b8ad604c0ea0844a68","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.</code></pre>
</div>
</div>
<section id="t-normalization-with-g_textsmall-phase-change" class="level2">
<h2 class="anchored" data-anchor-id="t-normalization-with-g_textsmall-phase-change"><code>T-Normalization</code> with <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bsmall%7D"> phase change</h2>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-24-guidance-expts-6/index_files/figure-html/cell-21-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>It seems the phase change happens between 0.088 and 0.09. Let’s check if this is also true for <code>Full Normalization</code>.</p>
</section>
<section id="full-normalization-with-g_textsmall-phase-change" class="level2">
<h2 class="anchored" data-anchor-id="full-normalization-with-g_textsmall-phase-change"><code>Full Normalization</code> with <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bsmall%7D"> phase change</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb55" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Running the phase change k-Sweep experiments...'</span>)</span>
<span id="cb55-2">full_phase_res <span class="op" style="color: #5E5E5E;">=</span> run(prompt, phase_expts, guide_tfm<span class="op" style="color: #5E5E5E;">=</span>FullNormGuidance)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running the phase change k-Sweep experiments...
Using Guidance Transform: &lt;class 'cf_guidance.transforms.FullNormGuidance'&gt;
Running experiment [1 of 12]: Param: "max_val", val=0.08...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4f00af8030f0419182d3e06d3b18b9b8","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [2 of 12]: Param: "max_val", val=0.082...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4820bbcb582047799b59e36e80b81f97","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [3 of 12]: Param: "max_val", val=0.084...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4a9e7dafbaee423dbf83fd08077b7159","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [4 of 12]: Param: "max_val", val=0.086...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7d8937635c0d4181832fbf6d568d04fd","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [5 of 12]: Param: "max_val", val=0.088...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"627b82a266f441799e1817c8f0375a52","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [6 of 12]: Param: "max_val", val=0.09...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"2799bd3a76a04ff8a856b5c12da03c2b","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [7 of 12]: Param: "max_val", val=0.092...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"547080a551b84382934b6460714c1a58","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [8 of 12]: Param: "max_val", val=0.094...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4ab8a2a9413241d1a855d5d1077b602c","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [9 of 12]: Param: "max_val", val=0.096...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"9514a943917c40fb8b041e3fd40a79c4","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [10 of 12]: Param: "max_val", val=0.09799999999999999...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"33d0b1f1b4a64e78a2131e447276595d","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [11 of 12]: Param: "max_val", val=0.09999999999999999...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e6b85c5c3d2448baa3ff4a86c04d4f46","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [12 of 12]: Param: "max_val", val=0.102...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d7b09c18a1df430bb155caa63325d66c","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-24-guidance-expts-6/index_files/figure-html/cell-23-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>The phase change happens in the same place! In fact the change is more pronounced, there is definitely something strange with the horse’s head as we hit the phase transition around <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bsmall%7D%20=%200.09">.</p>
<p>However, it seems that the image grows darker and less clear as we move away from the phase change. The horse’s body is less illuminated and is even hard to see.</p>
<p>One last check, what if the images before the phase change are better? We already saw that 0.05 was a bit too low, but what about values between 0.06 and 0.08?</p>
</section>
</section>
<section id="re-runs-to-find-earlier-potentially-better-values" class="level1">
<h1>Re-runs to find earlier, potentially better values</h1>
<div class="cell">
<div class="sourceCode cell-code" id="cb69" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1">low_bound <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.06</span></span>
<span id="cb69-2">hi_bound <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.082</span></span>
<span id="cb69-3">npoints <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">11</span></span>
<span id="cb69-4"></span>
<span id="cb69-5">points <span class="op" style="color: #5E5E5E;">=</span> np.linspace(low_bound, hi_bound, npoints<span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span>)<span class="op" style="color: #5E5E5E;">;</span> points</span></code></pre></div>
<div class="cell-output cell-output-display">
<pre><code>array([0.06 , 0.062, 0.064, 0.066, 0.068, 0.07 , 0.072, 0.074, 0.076,
       0.078, 0.08 , 0.082])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb71" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><span class="co" style="color: #5E5E5E;"># create the constant G_small cosine experiments</span></span>
<span id="cb71-2">early_phase_params <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'max_val'</span>: <span class="bu" style="color: null;">list</span>(points)}</span>
<span id="cb71-3">early_phase_func <span class="op" style="color: #5E5E5E;">=</span> <span class="kw" style="color: #003B4F;">lambda</span> val: [val <span class="cf" style="color: #003B4F;">for</span> _ <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(num_steps)]</span>
<span id="cb71-4">early_phase_expts <span class="op" style="color: #5E5E5E;">=</span> create_expts(early_phase_params, early_phase_func)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb72" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Running the phase change k-Sweep experiments...'</span>)</span>
<span id="cb72-2">early_phase_res <span class="op" style="color: #5E5E5E;">=</span> run(prompt, early_phase_expts, guide_tfm<span class="op" style="color: #5E5E5E;">=</span>TNormGuidance)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running the phase change k-Sweep experiments...
Using Guidance Transform: &lt;class 'cf_guidance.transforms.TNormGuidance'&gt;
Running experiment [1 of 12]: Param: "max_val", val=0.06...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"fa5e8b637c884371811dddb54cd10299","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [2 of 12]: Param: "max_val", val=0.062...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"0ec09cac708b4aa98d17d62dff12f874","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [3 of 12]: Param: "max_val", val=0.064...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"6dc2f510c4a0469888dc96de1b047a62","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [4 of 12]: Param: "max_val", val=0.066...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"398e1a873cbc42a597f4d6b6d0cf97b0","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [5 of 12]: Param: "max_val", val=0.068...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"cf2c222a69a844faa9622b7999b3cdd3","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [6 of 12]: Param: "max_val", val=0.07...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e97e6c1afd97469f9a719a9f23b27d68","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [7 of 12]: Param: "max_val", val=0.07200000000000001...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"368cc726b846432b9438ba4f080527ec","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [8 of 12]: Param: "max_val", val=0.074...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"0177e23af524449bb20a44e7b74b5ca5","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [9 of 12]: Param: "max_val", val=0.076...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"70fd81a643614284bdc31788b31a8dda","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [10 of 12]: Param: "max_val", val=0.078...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"9c9d910bca2e4eaaa1aee6a514e11e6a","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [11 of 12]: Param: "max_val", val=0.08...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"8ac2be282d38437eaf378e604f0b5c75","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [12 of 12]: Param: "max_val", val=0.082...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"778ef491004943e696ae1cb95371ced0","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-24-guidance-expts-6/index_files/figure-html/cell-27-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>This is a mixed bag. The anatomy of the horse’s face is better at lower values, but the rest of the image gains some strange artifacts. For example the horse’s leg starts fraying, and the astronaut merges with horse’s body. It is safe to say we are in “too small” territory for <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bsmall%7D."></p>
</section>
<section id="the-final-check-g-from-0.1-to-0.2" class="level1">
<h1>The final check: <img src="https://latex.codecogs.com/png.latex?G%5C%20"> from <img src="https://latex.codecogs.com/png.latex?0.1"> to <img src="https://latex.codecogs.com/png.latex?0.2"></h1>
<p>There is a noticeable change in the image somewhere between 0.1 and 0.2. Let’s do a small sweep in this range to see what happens.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb86" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1">low_bound <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.1</span></span>
<span id="cb86-2">hi_bound <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.202</span></span>
<span id="cb86-3">npoints <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">11</span></span>
<span id="cb86-4"></span>
<span id="cb86-5">points <span class="op" style="color: #5E5E5E;">=</span> np.linspace(low_bound, hi_bound, npoints<span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span>)<span class="op" style="color: #5E5E5E;">;</span> points</span></code></pre></div>
<div class="cell-output cell-output-display">
<pre><code>array([0.1       , 0.10927273, 0.11854545, 0.12781818, 0.13709091,
       0.14636364, 0.15563636, 0.16490909, 0.17418182, 0.18345455,
       0.19272727, 0.202     ])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb88" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><span class="co" style="color: #5E5E5E;"># create the constant G_small cosine experiments</span></span>
<span id="cb88-2">late_phase_params <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'max_val'</span>: <span class="bu" style="color: null;">list</span>(points)}</span>
<span id="cb88-3">late_phase_func <span class="op" style="color: #5E5E5E;">=</span> <span class="kw" style="color: #003B4F;">lambda</span> val: [val <span class="cf" style="color: #003B4F;">for</span> _ <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(num_steps)]</span>
<span id="cb88-4">late_phase_expts <span class="op" style="color: #5E5E5E;">=</span> create_expts(late_phase_params, late_phase_func)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb89" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Running the phase change k-Sweep experiments...'</span>)</span>
<span id="cb89-2">late_phase_res <span class="op" style="color: #5E5E5E;">=</span> run(prompt, late_phase_expts, guide_tfm<span class="op" style="color: #5E5E5E;">=</span>TNormGuidance)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running the phase change k-Sweep experiments...
Using Guidance Transform: &lt;class 'cf_guidance.transforms.TNormGuidance'&gt;
Running experiment [1 of 12]: Param: "max_val", val=0.1...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"02cf60c7691a4b2d854c83354884ac5e","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [2 of 12]: Param: "max_val", val=0.10927272727272727...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"823754a07b6f48c2ab057f764e7820c1","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [3 of 12]: Param: "max_val", val=0.11854545454545455...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4093a9d3fb4b4222a0da26e679229494","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [4 of 12]: Param: "max_val", val=0.12781818181818183...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4e482b8aabb04d778ae8020ba1e04b4e","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [5 of 12]: Param: "max_val", val=0.1370909090909091...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"91a77b8506e54c8484b2003f88a15a4e","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [6 of 12]: Param: "max_val", val=0.14636363636363636...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"163a0471b5914ae1bb2afc45161e35d8","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [7 of 12]: Param: "max_val", val=0.15563636363636363...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"35bf8a60b71d47ac80f090a23d8112d9","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [8 of 12]: Param: "max_val", val=0.16490909090909092...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"252dcf1904fb4e39972eb434571c6998","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [9 of 12]: Param: "max_val", val=0.1741818181818182...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"3605133591214da784b953485520548e","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [10 of 12]: Param: "max_val", val=0.18345454545454545...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d5280609098f41b19b7f4b3c6eedfe48","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [11 of 12]: Param: "max_val", val=0.19272727272727275...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"0297bb58b4ac4c78a03362ba0d276f3e","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [12 of 12]: Param: "max_val", val=0.202...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"2da8d0080c3e4a92a201a50e327263ba","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-24-guidance-expts-6/index_files/figure-html/cell-31-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Another phase change! Almost exactly at twice the <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bsmall%7D"> from the previous phase change. And, after this second phase change, we re-gain some illumination on the horse’s body.</p>
<section id="checking-for-phase-change-multiples" class="level2">
<h2 class="anchored" data-anchor-id="checking-for-phase-change-multiples">Checking for phase change multiples</h2>
<p>Will we find another phase change around three times from the first one? Let’s find out.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb103" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1">low_bound <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.25</span></span>
<span id="cb103-2">hi_bound <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.29</span></span>
<span id="cb103-3">npoints <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">11</span></span>
<span id="cb103-4"></span>
<span id="cb103-5">points <span class="op" style="color: #5E5E5E;">=</span> np.linspace(low_bound, hi_bound, npoints<span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span>)<span class="op" style="color: #5E5E5E;">;</span> points</span></code></pre></div>
<div class="cell-output cell-output-display">
<pre><code>array([0.25      , 0.25363636, 0.25727273, 0.26090909, 0.26454545,
       0.26818182, 0.27181818, 0.27545455, 0.27909091, 0.28272727,
       0.28636364, 0.29      ])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb105" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb105-1"><span class="co" style="color: #5E5E5E;"># create the constant G_small cosine experiments</span></span>
<span id="cb105-2">later_phase_params <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'max_val'</span>: <span class="bu" style="color: null;">list</span>(points)}</span>
<span id="cb105-3">later_phase_func <span class="op" style="color: #5E5E5E;">=</span> <span class="kw" style="color: #003B4F;">lambda</span> val: [val <span class="cf" style="color: #003B4F;">for</span> _ <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(num_steps)]</span>
<span id="cb105-4">later_phase_expts <span class="op" style="color: #5E5E5E;">=</span> create_expts(later_phase_params, later_phase_func)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb106" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Running the phase change k-Sweep experiments...'</span>)</span>
<span id="cb106-2">later_phase_res <span class="op" style="color: #5E5E5E;">=</span> run(prompt, later_phase_expts, guide_tfm<span class="op" style="color: #5E5E5E;">=</span>TNormGuidance)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running the phase change k-Sweep experiments...
Using Guidance Transform: &lt;class 'cf_guidance.transforms.TNormGuidance'&gt;
Running experiment [1 of 12]: Param: "max_val", val=0.25...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a1cd4f973df44da98eb52aa801fc7a2a","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [2 of 12]: Param: "max_val", val=0.25363636363636366...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"43ca061400c0470882fd1a0248a3b922","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [3 of 12]: Param: "max_val", val=0.25727272727272726...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4cd0f63f6c964c2fa2c2d58d05a92302","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [4 of 12]: Param: "max_val", val=0.2609090909090909...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1a92681a4ba146f7aa85fe7932cdb9fc","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [5 of 12]: Param: "max_val", val=0.26454545454545453...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e815ba8a555b44f9bc70cbdce72ec242","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [6 of 12]: Param: "max_val", val=0.2681818181818182...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4f5b22ee75184e0b9aa8d94136a700f7","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [7 of 12]: Param: "max_val", val=0.2718181818181818...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ed54fd99ca5141b3957b5dff3b95d179","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [8 of 12]: Param: "max_val", val=0.27545454545454545...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"0aeecdcfcbcc4e48b3774cc5a5690d9f","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [9 of 12]: Param: "max_val", val=0.27909090909090906...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"395d15aefe3f4bd788d43c46a49b32bf","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [10 of 12]: Param: "max_val", val=0.2827272727272727...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f1485478a6bf446d83548120d0286b26","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [11 of 12]: Param: "max_val", val=0.2863636363636364...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"88f5332a7fbb48cba2cd5c3fa7c80fd5","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [12 of 12]: Param: "max_val", val=0.29...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"5de84e9844bd4480b6859ba7693805a1","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-24-guidance-expts-6/index_files/figure-html/cell-35-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>There is no clear phase change, but the image is starting to fall apart. It is safe to say we are in territory where <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bsmall%7D"> is too large.</p>
<p><img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bsmall%7D%20=%200.25"> is the last image where we have a fully correct, non-smeared astronaut.</p>
</section>
</section>
<section id="cosines-for-the-best-g_textsmall" class="level1">
<h1>Cosines for the best <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bsmall%7D"></h1>
<p>We saw that that <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bsmall%7D"> should be between 0.08 and 0.25. What happens if we try cosine schedules around these values?</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb120" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb120-1"><span class="kw" style="color: #003B4F;">def</span> create_cos_expts(params: <span class="bu" style="color: null;">dict</span>, schedule_func) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="bu" style="color: null;">list</span>:</span>
<span id="cb120-2">    <span class="co" style="color: #5E5E5E;">'''Creates a list of experiments.</span></span>
<span id="cb120-3"><span class="co" style="color: #5E5E5E;">    </span></span>
<span id="cb120-4"><span class="co" style="color: #5E5E5E;">    Each element is a dictionary with the name, value, and schedule for a given parameter.</span></span>
<span id="cb120-5"><span class="co" style="color: #5E5E5E;">    A `title` field is also added for easy plotting.</span></span>
<span id="cb120-6"><span class="co" style="color: #5E5E5E;">    '''</span></span>
<span id="cb120-7">    names <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">sorted</span>(params)</span>
<span id="cb120-8">    expts <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb120-9">    <span class="co" style="color: #5E5E5E;"># step through parameter names and their values</span></span>
<span id="cb120-10">    <span class="cf" style="color: #003B4F;">for</span> i,name <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(names):</span>
<span id="cb120-11">        <span class="cf" style="color: #003B4F;">for</span> j,val <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(params[name]):</span>
<span id="cb120-12">            <span class="co" style="color: #5E5E5E;"># create the experiment</span></span>
<span id="cb120-13">            expt <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'param_name'</span>: name,</span>
<span id="cb120-14">                    <span class="st" style="color: #20794D;">'val'</span>: val,</span>
<span id="cb120-15">                    <span class="st" style="color: #20794D;">'schedule'</span>: schedule_func({name: val})}</span>
<span id="cb120-16">                    <span class="co" style="color: #5E5E5E;"># 'schedule': schedule_func({name: val})}</span></span>
<span id="cb120-17">            <span class="co" style="color: #5E5E5E;"># name for plotting</span></span>
<span id="cb120-18">            expt[<span class="st" style="color: #20794D;">'title'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="ss" style="color: #20794D;">f'Param: "</span><span class="sc" style="color: #5E5E5E;">{</span>name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">", val=</span><span class="sc" style="color: #5E5E5E;">{</span>val<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb120-19">            <span class="co" style="color: #5E5E5E;"># add it to the experiment list</span></span>
<span id="cb120-20">            expts.append(expt)</span>
<span id="cb120-21">    <span class="cf" style="color: #003B4F;">return</span> expts</span></code></pre></div>
</div>
<p>Let’s sweep a few cosine schedules between the ideal <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bsmall%7D"> range.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb121" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb121-1">low_cos_bound <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.08</span></span>
<span id="cb121-2">hi_cos_bound <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.25</span></span>
<span id="cb121-3">npoints <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">11</span></span>
<span id="cb121-4">cos_points <span class="op" style="color: #5E5E5E;">=</span> np.linspace(low_cos_bound, hi_cos_bound, npoints<span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span>)<span class="op" style="color: #5E5E5E;">;</span> cos_points</span></code></pre></div>
<div class="cell-output cell-output-display">
<pre><code>array([0.08      , 0.09545455, 0.11090909, 0.12636364, 0.14181818,
       0.15727273, 0.17272727, 0.18818182, 0.20363636, 0.21909091,
       0.23454545, 0.25      ])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb123" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb123-1"><span class="co" style="color: #5E5E5E;"># create the constant G_small cosine experiments</span></span>
<span id="cb123-2">cos_params <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'max_val'</span>: <span class="bu" style="color: null;">list</span>(cos_points)}</span>
<span id="cb123-3">cos_func <span class="op" style="color: #5E5E5E;">=</span> partial(cos_harness, default_params<span class="op" style="color: #5E5E5E;">=</span>DEFAULT_COS_PARAMS)</span>
<span id="cb123-4">cos_expts <span class="op" style="color: #5E5E5E;">=</span> create_cos_expts(cos_params, cos_func)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb124" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb124-1"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Running the phase change k-Sweep experiments...'</span>)</span>
<span id="cb124-2">cos_res <span class="op" style="color: #5E5E5E;">=</span> run(prompt, cos_expts, guide_tfm<span class="op" style="color: #5E5E5E;">=</span>TNormGuidance)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running the phase change k-Sweep experiments...
Using Guidance Transform: &lt;class 'cf_guidance.transforms.TNormGuidance'&gt;
Running experiment [1 of 12]: Param: "max_val", val=0.08...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d8ed64a5413943f085be254c8dd23b29","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [2 of 12]: Param: "max_val", val=0.09545454545454546...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7261bd31f18a451fbc097f788df6b8f4","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [3 of 12]: Param: "max_val", val=0.1109090909090909...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"496422598ad94dcb8cf9e99ae5c27ec8","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [4 of 12]: Param: "max_val", val=0.12636363636363634...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"de2a811e88e744299495df557d18f7f1","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [5 of 12]: Param: "max_val", val=0.14181818181818182...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"23cac14673f2431c84722921eddb27eb","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [6 of 12]: Param: "max_val", val=0.1572727272727273...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c0c1208b3763483d96349c1c3b9dfeb4","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [7 of 12]: Param: "max_val", val=0.17272727272727273...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"59a4fdfd2ab5427ab15075052aa31d7d","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [8 of 12]: Param: "max_val", val=0.18818181818181817...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"10deef9af6ce4b36808f91bc94a9a9c3","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [9 of 12]: Param: "max_val", val=0.20363636363636362...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4f4d1962483f41d4bc55fa55b885adb4","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [10 of 12]: Param: "max_val", val=0.21909090909090906...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"042cc10e18ef4e0c91fde48c5717816f","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [11 of 12]: Param: "max_val", val=0.23454545454545456...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e649d6ca67e44c03b111480d5c1c8dfb","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [12 of 12]: Param: "max_val", val=0.25...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"32346b2fb55245f2b9bf85deba5e58ea","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-24-guidance-expts-6/index_files/figure-html/cell-40-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>For completion, let’s try the Cosine sweep on <code>Full Normalization</code></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb138" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb138-1"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Running the phase change k-Sweep experiments...'</span>)</span>
<span id="cb138-2">full_norm_cos_res <span class="op" style="color: #5E5E5E;">=</span> run(prompt, cos_expts, guide_tfm<span class="op" style="color: #5E5E5E;">=</span>FullNormGuidance)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running the phase change k-Sweep experiments...
Using Guidance Transform: &lt;class 'cf_guidance.transforms.FullNormGuidance'&gt;
Running experiment [1 of 12]: Param: "max_val", val=0.08...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1e07f0f9e60946f8a4c66061eb149588","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [2 of 12]: Param: "max_val", val=0.09545454545454546...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f7889191cafb4105875d078b570eeee2","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [3 of 12]: Param: "max_val", val=0.1109090909090909...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d2dcbf92232043e280e2c1e119cce071","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [4 of 12]: Param: "max_val", val=0.12636363636363634...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b5b96cbfc7fb4650a1ff8af3419514bc","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [5 of 12]: Param: "max_val", val=0.14181818181818182...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"3e70b224a2b641f7bd72be495fabd535","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [6 of 12]: Param: "max_val", val=0.1572727272727273...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"57f9753973624a5abd6a471a420dc2ed","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [7 of 12]: Param: "max_val", val=0.17272727272727273...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"99233bd974c54d3d900123355ac5f1c0","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [8 of 12]: Param: "max_val", val=0.18818181818181817...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d092dfbefb5446d18de5af52959b2acb","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [9 of 12]: Param: "max_val", val=0.20363636363636362...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e81de69f64f24663bd25e2ca08a288e6","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [10 of 12]: Param: "max_val", val=0.21909090909090906...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"3d0019d84f7b443388ae053f52373ded","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [11 of 12]: Param: "max_val", val=0.23454545454545456...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f0809fd0dac34f8ba1b911f76959f22d","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [12 of 12]: Param: "max_val", val=0.25...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"3125e087d5e84722a23e865ff4f2a51b","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-24-guidance-expts-6/index_files/figure-html/cell-42-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>This was Part 5 in our series on dynamic Classifier-free Guidance.</p>
<p>We found a good range of <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bsmall%7D"> for both <code>T</code> and <code>Full</code> Normalizations. We also tried some basic Cosine Schedules around this ideal range.</p>
<p>In Part 6, we will explore the best schedules for each type of normalization:<br>
- <code>Prediction Normalization</code><br>
- <code>T-Normalization</code><br>
- <code>Full Normalization</code></p>
<p>Specifically, we will plug in the best <code>kDecay</code> Cosine Schedules so far. At that point, we should be able to see a measure and consistent improvement from the original, constant Guidance.</p>


</section>

 ]]></description>
  <category>diffusion</category>
  <category>classifier-free guidance</category>
  <category>deep learning</category>
  <guid>https://enzokro.dev/blog/posts/2022-11-24-guidance-expts-6/index.html</guid>
  <pubDate>Fri, 25 Nov 2022 00:00:00 GMT</pubDate>
  <media:content url="https://enzokro.dev/blog/posts/2022-11-24-guidance-expts-6/better_horse_5.png" medium="image" type="image/png" height="145" width="144"/>
</item>
<item>
  <title>Classifier-free Guidance with Cosine Schedules Pt. 4</title>
  <dc:creator>enzokro</dc:creator>
  <link>https://enzokro.dev/blog/posts/2022-11-24-guidance-expts-5/index.html</link>
  <description><![CDATA[ 



<blockquote class="blockquote">
<p>Exploring the effect of k-decay on Cosine Schedules.</p>
</blockquote>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>This notebook is Part 4 in a <a href="https://enzokro.dev/blog/posts/2022-11-15-guidance-expts-4/">series</a> on dynamic Classifier-free Guidance. It explores more advanced schedules for the guidance parameter <img src="https://latex.codecogs.com/png.latex?G">.</p>
<section id="recap-of-parts-1-3" class="level2">
<h2 class="anchored" data-anchor-id="recap-of-parts-1-3">Recap of Parts 1-3</h2>
<p>The first three parts explored how to turn Classifier-free Guidance into a dynamic process. We found an initial set of schedules and normalizers that seem to improve the quality of Diffusion images.</p>
</section>
<section id="part-4-alternative-warmups-for-cosine-schedules" class="level2">
<h2 class="anchored" data-anchor-id="part-4-alternative-warmups-for-cosine-schedules">Part 4: Alternative warmups for cosine schedules</h2>
<p>Part 4 is an exploration of <a href="https://arxiv.org/pdf/2004.05909.pdf">kDecay</a> applied to Cosine Schedules.</p>
<p>The <code>kDecay</code> paper introduces a hyperparameter <img src="https://latex.codecogs.com/png.latex?k"> for scheduled learning rates. This parameter empirically improves the performance of models across many learning rate schedules.</p>
<p>Here we explore two aspects of <img src="https://latex.codecogs.com/png.latex?k"> for the guidance parameter <img src="https://latex.codecogs.com/png.latex?G">:</p>
<ol type="1">
<li>The effect of <img src="https://latex.codecogs.com/png.latex?(%5C%20k%5C%20%3C%5C%201%5C%20)"> and <img src="https://latex.codecogs.com/png.latex?(%5C%20k%5C%20%3E%5C%201%5C%20)"> on the guidance parameter.<br>
</li>
<li>How an inverse <code>kDecay</code> schedule can be used as a type of warm up.</li>
</ol>
</section>
</section>
<section id="python-imports" class="level1">
<h1>Python imports</h1>
<p>We start with a few basic python imports.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> os</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> random</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">from</span> functools <span class="im" style="color: #00769E;">import</span> partial</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-6"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb1-7"><span class="im" style="color: #00769E;">import</span> matplotlib.colors <span class="im" style="color: #00769E;">as</span> mcolors</span></code></pre></div>
</div>
<section id="seed-for-reproducibility" class="level2">
<h2 class="anchored" data-anchor-id="seed-for-reproducibility">Seed for reproducibility</h2>
<p><code>seed_everything</code> makes sure that the results are reproducible across notebooks.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;"># set the seed and pseudo random number generator</span></span>
<span id="cb2-2">SEED <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1024</span></span>
<span id="cb2-3"><span class="kw" style="color: #003B4F;">def</span> seed_everything(seed):</span>
<span id="cb2-4">    random.seed(seed)</span>
<span id="cb2-5">    os.environ[<span class="st" style="color: #20794D;">'PYTHONHASHSEED'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">str</span>(seed)</span>
<span id="cb2-6">    np.random.seed(seed)</span>
<span id="cb2-7">    generator <span class="op" style="color: #5E5E5E;">=</span> torch.manual_seed(seed)</span>
<span id="cb2-8">    torch.backends.cudnn.deterministic <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">True</span></span>
<span id="cb2-9">    torch.backends.cudnn.benchmark <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">False</span></span>
<span id="cb2-10">    <span class="cf" style="color: #003B4F;">return</span> generator</span>
<span id="cb2-11"></span>
<span id="cb2-12"><span class="co" style="color: #5E5E5E;"># for sampling the initial, noisy latents</span></span>
<span id="cb2-13">generator <span class="op" style="color: #5E5E5E;">=</span> seed_everything(SEED)</span></code></pre></div>
</div>
</section>
</section>
<section id="generating-cosines-with-k-decay" class="level1">
<h1>Generating cosines with k-decay</h1>
<p>We can easily create different <img src="https://latex.codecogs.com/png.latex?k"> values with the <code>cf_guidance</code> library.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;"># helpers to create cosine schedules</span></span>
<span id="cb3-2"><span class="im" style="color: #00769E;">from</span> cf_guidance.schedules  <span class="im" style="color: #00769E;">import</span> get_cos_sched</span>
<span id="cb3-3"></span>
<span id="cb3-4"><span class="co" style="color: #5E5E5E;"># normalizations for classifier-free guidance</span></span>
<span id="cb3-5"><span class="im" style="color: #00769E;">from</span> cf_guidance.transforms <span class="im" style="color: #00769E;">import</span> GuidanceTfm, BaseNormGuidance</span></code></pre></div>
</div>
<p>For the other schedule parameters, we will use the <a href="https://enzokro.dev/blog/posts/2022-11-20-guidance-expts-2/#default-schedule-parameters">same values</a> from the running series.</p>
<p>The rest of the functions below are also brought in from previous notebooks. They are used to create the different schedule values.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;"># Default schedule parameters from the blog post</span></span>
<span id="cb4-2"><span class="co" style="color: #5E5E5E;">######################################</span></span>
<span id="cb4-3">max_val           <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">7.5</span>   <span class="co" style="color: #5E5E5E;"># guidance scaling value</span></span>
<span id="cb4-4">min_val           <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">1.</span>    <span class="co" style="color: #5E5E5E;"># minimum guidance scaling</span></span>
<span id="cb4-5">num_steps         <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">50</span>    <span class="co" style="color: #5E5E5E;"># number of diffusion steps</span></span>
<span id="cb4-6">num_warmup_steps  <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span>     <span class="co" style="color: #5E5E5E;"># number of warmup steps</span></span>
<span id="cb4-7">warmup_init_val   <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span>     <span class="co" style="color: #5E5E5E;"># the intial warmup value</span></span>
<span id="cb4-8">num_cycles        <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.5</span>   <span class="co" style="color: #5E5E5E;"># number of cosine cycles</span></span>
<span id="cb4-9">k_decay           <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span>     <span class="co" style="color: #5E5E5E;"># k-decay for cosine curve scaling </span></span>
<span id="cb4-10"></span>
<span id="cb4-11"><span class="co" style="color: #5E5E5E;"># smaller values for T-Norm and FullNorm</span></span>
<span id="cb4-12">max_T <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.15</span></span>
<span id="cb4-13">min_T <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.05</span></span>
<span id="cb4-14"><span class="co" style="color: #5E5E5E;">######################################</span></span>
<span id="cb4-15"></span>
<span id="cb4-16">DEFAULT_COS_PARAMS <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb4-17">    <span class="st" style="color: #20794D;">'max_val'</span>:           max_val,</span>
<span id="cb4-18">    <span class="st" style="color: #20794D;">'num_steps'</span>:         num_steps,</span>
<span id="cb4-19">    <span class="st" style="color: #20794D;">'min_val'</span>:           min_val,</span>
<span id="cb4-20">    <span class="st" style="color: #20794D;">'num_cycles'</span>:        num_cycles,</span>
<span id="cb4-21">    <span class="st" style="color: #20794D;">'k_decay'</span>:           k_decay,</span>
<span id="cb4-22">    <span class="st" style="color: #20794D;">'num_warmup_steps'</span>:  num_warmup_steps,</span>
<span id="cb4-23">    <span class="st" style="color: #20794D;">'warmup_init_val'</span>:   warmup_init_val,</span>
<span id="cb4-24">}</span>
<span id="cb4-25"></span>
<span id="cb4-26"><span class="kw" style="color: #003B4F;">def</span> cos_harness(new_params<span class="op" style="color: #5E5E5E;">=</span>{}, default_params<span class="op" style="color: #5E5E5E;">=</span>{}):</span>
<span id="cb4-27">    <span class="co" style="color: #5E5E5E;">'''Creates cosine schedules with updated parameters in `new_params`</span></span>
<span id="cb4-28"><span class="co" style="color: #5E5E5E;">    '''</span></span>
<span id="cb4-29">    <span class="co" style="color: #5E5E5E;"># start from the given baseline `cos_params`</span></span>
<span id="cb4-30">    cos_params <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">dict</span>(default_params)</span>
<span id="cb4-31">    <span class="co" style="color: #5E5E5E;"># update the schedule with any new parameters</span></span>
<span id="cb4-32">    cos_params.update(new_params)</span>
<span id="cb4-33">    </span>
<span id="cb4-34">    <span class="co" style="color: #5E5E5E;"># return the new cosine schedule</span></span>
<span id="cb4-35">    sched <span class="op" style="color: #5E5E5E;">=</span> get_cos_sched(<span class="op" style="color: #5E5E5E;">**</span>cos_params)</span>
<span id="cb4-36">    <span class="cf" style="color: #003B4F;">return</span> sched</span>
<span id="cb4-37"></span>
<span id="cb4-38"></span>
<span id="cb4-39"><span class="kw" style="color: #003B4F;">def</span> create_expts(params: <span class="bu" style="color: null;">dict</span>, schedule_func) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="bu" style="color: null;">list</span>:</span>
<span id="cb4-40">    <span class="co" style="color: #5E5E5E;">'''Creates a list of experiments.</span></span>
<span id="cb4-41"><span class="co" style="color: #5E5E5E;">    </span></span>
<span id="cb4-42"><span class="co" style="color: #5E5E5E;">    Each element is a dictionary with the name, value, and schedule for a given parameter.</span></span>
<span id="cb4-43"><span class="co" style="color: #5E5E5E;">    A `title` field is also added for easy plotting.</span></span>
<span id="cb4-44"><span class="co" style="color: #5E5E5E;">    '''</span></span>
<span id="cb4-45">    names <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">sorted</span>(params)</span>
<span id="cb4-46">    expts <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb4-47">    <span class="co" style="color: #5E5E5E;"># step through parameter names and their values</span></span>
<span id="cb4-48">    <span class="cf" style="color: #003B4F;">for</span> i,name <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(names):</span>
<span id="cb4-49">        <span class="cf" style="color: #003B4F;">for</span> j,val <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(params[name]):</span>
<span id="cb4-50">            <span class="co" style="color: #5E5E5E;"># create the experiment</span></span>
<span id="cb4-51">            expt <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'param_name'</span>: name,</span>
<span id="cb4-52">                    <span class="st" style="color: #20794D;">'val'</span>: val,</span>
<span id="cb4-53">                    <span class="st" style="color: #20794D;">'schedule'</span>: schedule_func({name: val})}</span>
<span id="cb4-54">            <span class="co" style="color: #5E5E5E;"># name for plotting</span></span>
<span id="cb4-55">            expt[<span class="st" style="color: #20794D;">'title'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="ss" style="color: #20794D;">f'Param: "</span><span class="sc" style="color: #5E5E5E;">{</span>name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">", val=</span><span class="sc" style="color: #5E5E5E;">{</span>val<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb4-56">            <span class="co" style="color: #5E5E5E;"># add it to the experiment list</span></span>
<span id="cb4-57">            expts.append(expt)</span>
<span id="cb4-58">    <span class="cf" style="color: #003B4F;">return</span> expts</span></code></pre></div>
</div>
<p>Next we use the functions above to create the k-decay cosine values.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="co" style="color: #5E5E5E;"># create the k-decay cosine experiments</span></span>
<span id="cb5-2">cos_params <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'k_decay'</span>: [<span class="fl" style="color: #AD0000;">0.1</span>, <span class="fl" style="color: #AD0000;">0.2</span>, <span class="fl" style="color: #AD0000;">0.3</span>, <span class="fl" style="color: #AD0000;">0.5</span>, <span class="fl" style="color: #AD0000;">0.7</span>, <span class="fl" style="color: #AD0000;">1.</span>, <span class="fl" style="color: #AD0000;">1.5</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">3</span>, <span class="dv" style="color: #AD0000;">5</span>]}</span>
<span id="cb5-3">cos_func <span class="op" style="color: #5E5E5E;">=</span> partial(cos_harness, default_params<span class="op" style="color: #5E5E5E;">=</span>DEFAULT_COS_PARAMS)</span>
<span id="cb5-4">cos_expts <span class="op" style="color: #5E5E5E;">=</span> create_expts(cos_params, cos_func)</span></code></pre></div>
</div>
</section>
<section id="plotting-the-different-k-values" class="level1">
<h1>Plotting the different <img src="https://latex.codecogs.com/png.latex?k"> values</h1>
<p>Let’s plot the sweep of <img src="https://latex.codecogs.com/png.latex?k"> values to see how they change the cosine schedule. For reference, the value of <img src="https://latex.codecogs.com/png.latex?k%20=%201"> is the default.</p>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-24-guidance-expts-5/index_files/figure-html/cell-7-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>The curves to the left of the default <img src="https://latex.codecogs.com/png.latex?k%20=%201"> are “squished” by smaller <img src="https://latex.codecogs.com/png.latex?k"> values. While the curves to its right are expanded out.</p>
<p>We see that <img src="https://latex.codecogs.com/png.latex?k"> affects how quickly the guidance parameter decreases. What does this decrease mean for Diffusion images?</p>
<p>Consider that at the start of a diffusion process, the image is pure, random noise. It makes sense to strongly guide the image toward the given input prompt, else the model will freely hallucinate and ignore the prompt. This is the main idea behind Classifier-free Guidance.</p>
<p>What we are trying to find is a different, more gradual increase in <img src="https://latex.codecogs.com/png.latex?G"> that might improve the quality of generated images.</p>
</section>
<section id="inverting-the-kdecay-schedules" class="level1">
<h1>Inverting the <code>kDecay</code> schedules</h1>
<p>An interesting thing happens when we “invert” the <img src="https://latex.codecogs.com/png.latex?k"> schedules. Here, inverting means that we mirror the schedule along it’s y-axis midpoint.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="co" style="color: #5E5E5E;"># stores the inverted schedules</span></span>
<span id="cb6-2">inv_cos_expts <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb6-3"></span>
<span id="cb6-4"><span class="co" style="color: #5E5E5E;"># flip the schedules</span></span>
<span id="cb6-5"><span class="cf" style="color: #003B4F;">for</span> s <span class="kw" style="color: #003B4F;">in</span> cos_expts:</span>
<span id="cb6-6">    new_vals <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">dict</span>(s)</span>
<span id="cb6-7">    inv <span class="op" style="color: #5E5E5E;">=</span> [max_val <span class="op" style="color: #5E5E5E;">-</span> g <span class="op" style="color: #5E5E5E;">+</span> min_val <span class="cf" style="color: #003B4F;">for</span> g <span class="kw" style="color: #003B4F;">in</span> s[<span class="st" style="color: #20794D;">'schedule'</span>]]</span>
<span id="cb6-8">    new_vals[<span class="st" style="color: #20794D;">'schedule'</span>] <span class="op" style="color: #5E5E5E;">=</span> inv</span>
<span id="cb6-9">    inv_cos_expts.append(new_vals)</span></code></pre></div>
</div>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-24-guidance-expts-5/index_files/figure-html/cell-9-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Notice how, after inversion, the smallest <img src="https://latex.codecogs.com/png.latex?k"> values become steep warmups that quickly saturate toward the max. By contrast, the largest <img src="https://latex.codecogs.com/png.latex?k"> values now act like extremely slow warmups.</p>
<p>We expect that <img src="https://latex.codecogs.com/png.latex?k"> schedules that quickly reach a high guidance value will generate better images. Likewise, <img src="https://latex.codecogs.com/png.latex?k"> schedules that remain at higher guidance values for longer will do the same.</p>
<p>The open question is whether the smooth, inverse k-decay is a better warmup than a simple linear increase. This question is inspired by the slower, more gradual diffusion variance schedules in recent efforts.</p>
<p>With this full suite of <code>kDecay</code> schedules to explore, we are ready to generate some images.</p>
</section>
<section id="loading-the-openjourney-model-from-prompt-hero" class="level1">
<h1>Loading the <code>openjourney</code> model from Prompt Hero</h1>
<p>The <code>min_diffusion</code> library loads a Stable Diffusion model from the HuggingFace hub.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="co" style="color: #5E5E5E;"># to load Stable Diffusion pipelines</span></span>
<span id="cb7-2"><span class="im" style="color: #00769E;">from</span> min_diffusion.core <span class="im" style="color: #00769E;">import</span> MinimalDiffusion</span>
<span id="cb7-3"></span>
<span id="cb7-4"><span class="co" style="color: #5E5E5E;"># to plot generated images</span></span>
<span id="cb7-5"><span class="im" style="color: #00769E;">from</span> min_diffusion.utils <span class="im" style="color: #00769E;">import</span> show_image, image_grid, plot_grid</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2022-11-24 17:24:16.457198: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0</code></pre>
</div>
</div>
<p>The following code loads the <code>openjourney</code> model on the GPU, with <code>torch.float16</code> precision.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">model_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'prompthero/openjourney'</span></span>
<span id="cb9-2">device     <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'cuda'</span></span>
<span id="cb9-3">dtype      <span class="op" style="color: #5E5E5E;">=</span> torch.float16</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">pipeline <span class="op" style="color: #5E5E5E;">=</span> MinimalDiffusion(model_name, device, dtype, generator<span class="op" style="color: #5E5E5E;">=</span>generator)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">pipeline.load(unet_attn_slice<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>)<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
</div>
</section>
<section id="text-prompt-for-image-generations" class="level1">
<h1>Text prompt for image generations</h1>
<p>We use the familiar, running prompt in our series to generate an image:</p>
<blockquote class="blockquote">
<p>“a photograph of an astronaut riding a horse”</p>
</blockquote>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>The <code>openjourney</code> model was fine-tuned to create images in the style of <a href="https://mezha.media/en/2022/11/11/midjourney-v4-is-an-incredible-new-version-of-the-ai-image-generator/">Midjourney v4</a>.</p>
<p>To enable this fine-tuned style, we need to add the keyword <code>"mdjrny-v4"</code> at the start of the prompt.</p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;"># text prompt for image generations</span></span>
<span id="cb12-2">prompt <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"mdjrny-v4 style a photograph of an astronaut riding a horse"</span></span></code></pre></div>
</div>
<section id="image-parameters" class="level2">
<h2 class="anchored" data-anchor-id="image-parameters">Image parameters</h2>
<p>Images will be generated over <img src="https://latex.codecogs.com/png.latex?50"> diffusion steps. They will have a height and width of <code>512 x 512</code> pixels.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="co" style="color: #5E5E5E;"># the number of diffusion steps</span></span>
<span id="cb13-2">num_steps <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">50</span></span>
<span id="cb13-3"></span>
<span id="cb13-4"><span class="co" style="color: #5E5E5E;"># generated image dimensions</span></span>
<span id="cb13-5">width, height <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">512</span>, <span class="dv" style="color: #AD0000;">512</span></span></code></pre></div>
</div>
</section>
</section>
<section id="running-the-experiments" class="level1">
<h1>Running the experiments</h1>
<p>The <code>run</code> function below generates images for the given <code>prompt</code>.</p>
<p>It also stores the output images with a matching title for plotting and visualizations.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="kw" style="color: #003B4F;">def</span> run(prompt, schedules, guide_tfm<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>, generator<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb14-2">        show_each<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>, test_run<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>):</span>
<span id="cb14-3">    <span class="co" style="color: #5E5E5E;">"""Runs a dynamic Classifier-free Guidance experiment. </span></span>
<span id="cb14-4"><span class="co" style="color: #5E5E5E;">    </span></span>
<span id="cb14-5"><span class="co" style="color: #5E5E5E;">    Generates an image for the text `prompt` given all the values in `schedules`.</span></span>
<span id="cb14-6"><span class="co" style="color: #5E5E5E;">    Uses a Guidance Transformation class from the `cf_guidance` library.  </span></span>
<span id="cb14-7"><span class="co" style="color: #5E5E5E;">    Stores the output images with a matching title for plotting. </span></span>
<span id="cb14-8"><span class="co" style="color: #5E5E5E;">    Optionally shows each image as its generated.</span></span>
<span id="cb14-9"><span class="co" style="color: #5E5E5E;">    If `test_run` is true, it runs a single schedule for testing. </span></span>
<span id="cb14-10"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb14-11">    <span class="co" style="color: #5E5E5E;"># store generated images and their title (the experiment name)</span></span>
<span id="cb14-12">    images, titles <span class="op" style="color: #5E5E5E;">=</span> [], []</span>
<span id="cb14-13">    </span>
<span id="cb14-14">    <span class="co" style="color: #5E5E5E;"># make sure we have a valid guidance transform</span></span>
<span id="cb14-15">    <span class="cf" style="color: #003B4F;">assert</span> guide_tfm</span>
<span id="cb14-16">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Using Guidance Transform: </span><span class="sc" style="color: #5E5E5E;">{</span>guide_tfm<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb14-17">    </span>
<span id="cb14-18">    <span class="co" style="color: #5E5E5E;"># optionally run a single test schedule</span></span>
<span id="cb14-19">    <span class="cf" style="color: #003B4F;">if</span> test_run:</span>
<span id="cb14-20">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Running a single schedule for testing.'</span>)</span>
<span id="cb14-21">        schedules <span class="op" style="color: #5E5E5E;">=</span> schedules[:<span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb14-22">        </span>
<span id="cb14-23">    <span class="co" style="color: #5E5E5E;"># run all schedule experiments</span></span>
<span id="cb14-24">    <span class="cf" style="color: #003B4F;">for</span> i,s <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(schedules):</span>
<span id="cb14-25">        </span>
<span id="cb14-26">        <span class="co" style="color: #5E5E5E;"># parse out the title for the current run</span></span>
<span id="cb14-27">        cur_title  <span class="op" style="color: #5E5E5E;">=</span> s[<span class="st" style="color: #20794D;">'title'</span>]</span>
<span id="cb14-28">        titles.append(cur_title)</span>
<span id="cb14-29">        </span>
<span id="cb14-30">        <span class="co" style="color: #5E5E5E;"># create the guidance transformation </span></span>
<span id="cb14-31">        cur_sched <span class="op" style="color: #5E5E5E;">=</span> s[<span class="st" style="color: #20794D;">'schedule'</span>]</span>
<span id="cb14-32">        gtfm <span class="op" style="color: #5E5E5E;">=</span> guide_tfm({<span class="st" style="color: #20794D;">'g'</span>: cur_sched})</span>
<span id="cb14-33">        </span>
<span id="cb14-34">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Running experiment [</span><span class="sc" style="color: #5E5E5E;">{</span>i<span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;"> of </span><span class="sc" style="color: #5E5E5E;">{</span><span class="bu" style="color: null;">len</span>(schedules)<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">]: </span><span class="sc" style="color: #5E5E5E;">{</span>cur_title<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">...'</span>)</span>
<span id="cb14-35">        img <span class="op" style="color: #5E5E5E;">=</span> pipeline.generate(prompt, gtfm, generator<span class="op" style="color: #5E5E5E;">=</span>generator)</span>
<span id="cb14-36">        images.append(img)</span>
<span id="cb14-37">        </span>
<span id="cb14-38">        <span class="co" style="color: #5E5E5E;"># optionally plot the image</span></span>
<span id="cb14-39">        <span class="cf" style="color: #003B4F;">if</span> show_each:</span>
<span id="cb14-40">            show_image(img, scale<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb14-41"></span>
<span id="cb14-42">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Done.'</span>)</span>
<span id="cb14-43">    <span class="cf" style="color: #003B4F;">return</span> {<span class="st" style="color: #20794D;">'images'</span>: images,</span>
<span id="cb14-44">            <span class="st" style="color: #20794D;">'titles'</span>: titles}</span></code></pre></div>
</div>
<section id="setting-the-baseline-with-g-7.5" class="level2">
<h2 class="anchored" data-anchor-id="setting-the-baseline-with-g-7.5">Setting the baseline with <img src="https://latex.codecogs.com/png.latex?G%20=%207.5"></h2>
<p>First we create and display the baseline imagine using a constant Classifier-free Guidance with <img src="https://latex.codecogs.com/png.latex?G%20=%207.5">. Since this is a constant schedule, <img src="https://latex.codecogs.com/png.latex?k"> does not come into play.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="co" style="color: #5E5E5E;"># create the baseline schedule with the new function</span></span>
<span id="cb15-2">baseline_g <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">7.5</span></span>
<span id="cb15-3">baseline_params <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'max_val'</span>: [baseline_g]}</span>
<span id="cb15-4">baseline_func <span class="op" style="color: #5E5E5E;">=</span> <span class="kw" style="color: #003B4F;">lambda</span> params: [baseline_g <span class="cf" style="color: #003B4F;">for</span> _ <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(num_steps)]</span>
<span id="cb15-5">baseline_expts <span class="op" style="color: #5E5E5E;">=</span> create_expts(baseline_params, baseline_func)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">baseline_res <span class="op" style="color: #5E5E5E;">=</span> run(prompt, baseline_expts, guide_tfm<span class="op" style="color: #5E5E5E;">=</span>GuidanceTfm)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Using Guidance Transform: &lt;class 'cf_guidance.transforms.GuidanceTfm'&gt;
Running experiment [1 of 1]: Param: "max_val", val=7.5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"3803b3c695a045d7b3868edf7e61349c","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="co" style="color: #5E5E5E;"># view the baseline image</span></span>
<span id="cb19-2">baseline_res[<span class="st" style="color: #20794D;">'images'</span>][<span class="dv" style="color: #AD0000;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-24-guidance-expts-5/index_files/figure-html/cell-19-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="improving-the-baseline-with-k-schedules" class="level2">
<h2 class="anchored" data-anchor-id="improving-the-baseline-with-k-schedules">Improving the baseline with <img src="https://latex.codecogs.com/png.latex?k"> schedules</h2>
<p>Now we sweep the Cosine Schedules with different <img src="https://latex.codecogs.com/png.latex?k"> values. Then we will check the output images and compare them to the baseline.</p>
</section>
<section id="k-sweep-runs" class="level2">
<h2 class="anchored" data-anchor-id="k-sweep-runs"><code>k-Sweep</code> runs</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Running the k-Sweep experiments...'</span>)</span>
<span id="cb20-2">cos_res <span class="op" style="color: #5E5E5E;">=</span> run(prompt, cos_expts, guide_tfm<span class="op" style="color: #5E5E5E;">=</span>GuidanceTfm)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running the k-Sweep experiments...
Using Guidance Transform: &lt;class 'cf_guidance.transforms.GuidanceTfm'&gt;
Running experiment [1 of 10]: Param: "k_decay", val=0.1...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"daa7651f2b794bd59f7ed33239ea8462","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [2 of 10]: Param: "k_decay", val=0.2...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e483d9651c4645a0918bdb466bda607e","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [3 of 10]: Param: "k_decay", val=0.3...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1ea18eb9562e4848a584e0eabafb42e6","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [4 of 10]: Param: "k_decay", val=0.5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c6e6610389af43f0baf08a0e27032da7","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [5 of 10]: Param: "k_decay", val=0.7...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"108f224d774a42df9a2e9392e05e88cd","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [6 of 10]: Param: "k_decay", val=1.0...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"acf21f5072f5470f8ae32d82106dd255","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [7 of 10]: Param: "k_decay", val=1.5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e560488a869f47228bced9343fe0bced","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [8 of 10]: Param: "k_decay", val=2...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ac4712a1601643e18d81003f402fec69","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [9 of 10]: Param: "k_decay", val=3...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a24823ab0bda4d58a6c5b0dc420bf8d4","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [10 of 10]: Param: "k_decay", val=5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a8a76b03828a4c5780cf5d75e0097dd8","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.</code></pre>
</div>
</div>
</section>
<section id="inverse-k-sweep-runs" class="level2">
<h2 class="anchored" data-anchor-id="inverse-k-sweep-runs"><code>Inverse k-Sweep</code> runs</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb32" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Running the Inverse-k-Sweep experiments...'</span>)</span>
<span id="cb32-2">inv_cos_res <span class="op" style="color: #5E5E5E;">=</span> run(prompt, inv_cos_expts, guide_tfm<span class="op" style="color: #5E5E5E;">=</span>GuidanceTfm)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running the Inverse-k-Sweep experiments...
Using Guidance Transform: &lt;class 'cf_guidance.transforms.GuidanceTfm'&gt;
Running experiment [1 of 10]: Param: "k_decay", val=0.1...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"073278d9f1004805801a456e05a08ab1","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [2 of 10]: Param: "k_decay", val=0.2...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"32d1f4acafe946ee9e7c5e435563ef5e","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [3 of 10]: Param: "k_decay", val=0.3...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"84f8e5dc1b904ca1a2172bb943fe41c3","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [4 of 10]: Param: "k_decay", val=0.5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c73d220b4b3f413f9e525ec78b294119","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [5 of 10]: Param: "k_decay", val=0.7...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c228e74a414f4699a5043bcdb4d8d3a0","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [6 of 10]: Param: "k_decay", val=1.0...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"bac45c76d02c44d3bebb96b5aab93134","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [7 of 10]: Param: "k_decay", val=1.5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"49602f88896b48888911815a2dfbd52e","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [8 of 10]: Param: "k_decay", val=2...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d46a7de1aa90413cacc39360a4d82a5f","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [9 of 10]: Param: "k_decay", val=3...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"cb3977e0b0d84d9e8646eb418600e457","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [10 of 10]: Param: "k_decay", val=5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"2882f7a323ce4476b3bb99cd2029a855","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.</code></pre>
</div>
</div>
</section>
</section>
<section id="results" class="level1">
<h1>Results</h1>
<section id="k-sweep-results" class="level2">
<h2 class="anchored" data-anchor-id="k-sweep-results"><code>k-Sweep</code> results</h2>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-24-guidance-expts-5/index_files/figure-html/cell-22-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="inverse-k-sweep-results" class="level2">
<h2 class="anchored" data-anchor-id="inverse-k-sweep-results"><code>Inverse k-Sweep</code> results</h2>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-24-guidance-expts-5/index_files/figure-html/cell-23-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="analysis" class="level1">
<h1>Analysis</h1>
<p>A few patterns are clear.</p>
<p>The <img src="https://latex.codecogs.com/png.latex?k"> schedules that take too long to reach a high guidance value <img src="https://latex.codecogs.com/png.latex?G"> suffer. This makes sense: it means we allowed the model to hallucinate for too long before guiding it towards the intended prompt.</p>
<p>In the <code>k-Sweep</code> experiments we see a simiar effect with <img src="https://latex.codecogs.com/png.latex?k"> values below <img src="https://latex.codecogs.com/png.latex?1">. It seems that the guidance parameter falls off too quickly and the images became too abstract.</p>
<p>There seems to be a sweet spot where <img src="https://latex.codecogs.com/png.latex?k"> increases quickly and smoothly enough. Or, where it stays high for long enough before smoothly decreasing. The pattern is clear: guidance needs to be both high enough and early enough for good image generations.</p>
<p>Let’s compare the baseline to some of the best <img src="https://latex.codecogs.com/png.latex?k"> generations.</p>
<section id="k-sweep-comparison" class="level2">
<h2 class="anchored" data-anchor-id="k-sweep-comparison"><code>k-Sweep</code> comparison</h2>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-24-guidance-expts-5/index_files/figure-html/cell-24-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="inverse-k-sweep-comparison" class="level2">
<h2 class="anchored" data-anchor-id="inverse-k-sweep-comparison"><code>Inverse k-Sweep</code> comparison</h2>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-24-guidance-expts-5/index_files/figure-html/cell-25-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>In both cases, with a high and smooth value of <img src="https://latex.codecogs.com/png.latex?G">, the output image improved. We gained more details in the background, on the horse’s body, and on the astronaut’s gear.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>This post explored a range of <code>kDecay</code> schedules for dynamic Classifier-free Guidance. We empirically confirmed some of our intuitions about what makes for a good guidance.</p>
<p>Now, thanks to Parts 1-4 in this series, we have a solid understanding of how schedules and normalizations affect the quality of Diffusion images.</p>
<p>In Part 5, we will explore good good starting values for <img src="https://latex.codecogs.com/png.latex?G"> for our other kinds of normalizations. After that, we should have all the pieces of the puzzle to start putting together some powerful dynamic Classifier-free Guidances.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb44" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"></span>
<span id="cb44-2"><span class="co" style="color: #5E5E5E;"># #| echo: false</span></span>
<span id="cb44-3"><span class="co" style="color: #5E5E5E;"># #| include: false</span></span>
<span id="cb44-4"><span class="co" style="color: #5E5E5E;"># import torch</span></span>
<span id="cb44-5"><span class="co" style="color: #5E5E5E;"># import math</span></span>
<span id="cb44-6"><span class="co" style="color: #5E5E5E;"># import matplotlib.pyplot as plt</span></span>
<span id="cb44-7"><span class="co" style="color: #5E5E5E;"># num_steps = 50</span></span>
<span id="cb44-8"><span class="co" style="color: #5E5E5E;"># def log(t, eps = 1e-20):</span></span>
<span id="cb44-9"><span class="co" style="color: #5E5E5E;">#     return torch.log10(t.clamp(min = eps))</span></span>
<span id="cb44-10"><span class="co" style="color: #5E5E5E;"># t = torch.linspace(0, 1, num_steps)</span></span>
<span id="cb44-11"><span class="co" style="color: #5E5E5E;"># def alpha_cosine_log_snr(t, s = 0.008):</span></span>
<span id="cb44-12"><span class="co" style="color: #5E5E5E;">#     return -log((torch.cos((t + s) / (1 + s) * math.pi * 0.5) ** -2) - 1, eps = 1e-5)</span></span>
<span id="cb44-13"><span class="co" style="color: #5E5E5E;"># s = alpha_cosine_log_snr(t)</span></span>
<span id="cb44-14"><span class="co" style="color: #5E5E5E;"># plt.plot(s)</span></span></code></pre></div>
</div>


</section>

 ]]></description>
  <category>diffusion</category>
  <category>classifier-free guidance</category>
  <category>deep learning</category>
  <guid>https://enzokro.dev/blog/posts/2022-11-24-guidance-expts-5/index.html</guid>
  <pubDate>Thu, 24 Nov 2022 00:00:00 GMT</pubDate>
  <media:content url="https://enzokro.dev/blog/posts/2022-11-24-guidance-expts-5/log_cos_sweep.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>Classifier-free Guidance with Cosine Schedules Pt. 3</title>
  <dc:creator>enzokro</dc:creator>
  <link>https://enzokro.dev/blog/posts/2022-11-23-guidance-expts-4/index.html</link>
  <description><![CDATA[ 



<blockquote class="blockquote">
<p>Experiments with cosine schedules and normalizations for Classifier-free Guidance.</p>
</blockquote>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>This notebook is Part 3 in a <a href="https://enzokro.dev/blog/posts/2022-11-15-guidance-expts-3/">series</a> on dynamic Classifier-free Guidance. It combines normalizations and schedules for the guidance parameter <img src="https://latex.codecogs.com/png.latex?G">.</p>
<section id="quick-recap-of-parts-1-and-2" class="level2">
<h2 class="anchored" data-anchor-id="quick-recap-of-parts-1-and-2">Quick recap of Parts 1 and 2</h2>
<p>In Part 1, we generated a baseline image using a constant Classifier-free Guidance. Attempting to improve on the baseline, we swept the guidance parameter <img src="https://latex.codecogs.com/png.latex?G"> over a set of Cosine Schedules.</p>
<p>In Part 2, we introduced normalizations for Classifier-free Guidance. There was one kind of normalization, <code>Prediction Normalization</code>, that seems to improve the overall quality of generated images.</p>
</section>
<section id="part-3-combining-schedules-and-normalizations" class="level2">
<h2 class="anchored" data-anchor-id="part-3-combining-schedules-and-normalizations">Part 3: Combining schedules and normalizations</h2>
<p>In Part 3, we build on the previous results by now combining guidance normalizations <em>and</em> schedules.</p>
<p>The goal is to find a combo of normalized schedules that universally improve the outputs of Diffusion image models.</p>
</section>
<section id="leveraging-a-few-helper-libraries" class="level2">
<h2 class="anchored" data-anchor-id="leveraging-a-few-helper-libraries">Leveraging a few helper libraries</h2>
<p>We reuse our helper libraries to more efficiently run guidance experiments. The two libraries are:</p>
<ul>
<li><code>min_diffusion</code></li>
<li><code>cf_guidance</code></li>
</ul>
<p>They were introduced in <a href="https://enzokro.dev/blog/posts/2022-11-20-minimal-diffusion/">this separate post</a>.</p>
</section>
</section>
<section id="experiment-setup" class="level1">
<h1>Experiment Setup</h1>
<section id="python-imports" class="level2">
<h2 class="anchored" data-anchor-id="python-imports">Python Imports</h2>
<p>First we import the needed python modules.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> os</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> math</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">import</span> random</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> warnings</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">from</span> PIL <span class="im" style="color: #00769E;">import</span> Image</span>
<span id="cb1-6"><span class="im" style="color: #00769E;">from</span> typing <span class="im" style="color: #00769E;">import</span> List</span>
<span id="cb1-7"><span class="im" style="color: #00769E;">from</span> pathlib <span class="im" style="color: #00769E;">import</span> Path</span>
<span id="cb1-8"><span class="im" style="color: #00769E;">from</span> types <span class="im" style="color: #00769E;">import</span> SimpleNamespace</span>
<span id="cb1-9"><span class="im" style="color: #00769E;">from</span> fastcore.<span class="bu" style="color: null;">all</span> <span class="im" style="color: #00769E;">import</span> L</span>
<span id="cb1-10"><span class="im" style="color: #00769E;">from</span> functools <span class="im" style="color: #00769E;">import</span> partial</span>
<span id="cb1-11"></span>
<span id="cb1-12"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-13"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb1-14"></span>
<span id="cb1-15"><span class="co" style="color: #5E5E5E;"># imports for diffusion models</span></span>
<span id="cb1-16"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb1-17"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> logging</span>
<span id="cb1-18"><span class="co" style="color: #5E5E5E;"># for clean outputs</span></span>
<span id="cb1-19">warnings.filterwarnings(<span class="st" style="color: #20794D;">"ignore"</span>)</span>
<span id="cb1-20">logging.set_verbosity_error()</span>
<span id="cb1-21"></span>
<span id="cb1-22"><span class="co" style="color: #5E5E5E;"># set the hardware device</span></span>
<span id="cb1-23">device <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"cuda"</span> <span class="cf" style="color: #003B4F;">if</span> torch.cuda.is_available() <span class="cf" style="color: #003B4F;">else</span> <span class="st" style="color: #20794D;">"mps"</span> <span class="cf" style="color: #003B4F;">if</span> torch.has_mps <span class="cf" style="color: #003B4F;">else</span> <span class="st" style="color: #20794D;">"cpu"</span></span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2022-11-24 18:34:14.079096: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0</code></pre>
</div>
</div>
<section id="seed-for-reproducibility" class="level3">
<h3 class="anchored" data-anchor-id="seed-for-reproducibility">Seed for reproducibility</h3>
<p>We use the <code>seed_everything</code> function to make sure that the results are repeatable across notebooks.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;"># set the seed and pseudo random number generator</span></span>
<span id="cb3-2">SEED <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1024</span></span>
<span id="cb3-3"><span class="kw" style="color: #003B4F;">def</span> seed_everything(seed):</span>
<span id="cb3-4">    random.seed(seed)</span>
<span id="cb3-5">    os.environ[<span class="st" style="color: #20794D;">'PYTHONHASHSEED'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">str</span>(seed)</span>
<span id="cb3-6">    np.random.seed(seed)</span>
<span id="cb3-7">    generator <span class="op" style="color: #5E5E5E;">=</span> torch.manual_seed(seed)</span>
<span id="cb3-8">    torch.backends.cudnn.deterministic <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">True</span></span>
<span id="cb3-9">    torch.backends.cudnn.benchmark <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">False</span></span>
<span id="cb3-10">    <span class="cf" style="color: #003B4F;">return</span> generator</span>
<span id="cb3-11"><span class="co" style="color: #5E5E5E;"># for sampling the initial, noisy latents</span></span>
<span id="cb3-12">generator <span class="op" style="color: #5E5E5E;">=</span> seed_everything(SEED)</span></code></pre></div>
</div>
</section>
</section>
<section id="importing-the-helper-libraries" class="level2">
<h2 class="anchored" data-anchor-id="importing-the-helper-libraries">Importing the helper libraries</h2>
<p>The <code>cf_guidance</code> library has the guidance schedules and normalizations.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;"># helpers to create cosine schedules</span></span>
<span id="cb4-2"><span class="im" style="color: #00769E;">from</span> cf_guidance.schedules  <span class="im" style="color: #00769E;">import</span> get_cos_sched</span>
<span id="cb4-3"></span>
<span id="cb4-4"><span class="co" style="color: #5E5E5E;"># normalizations for classifier-free guidance</span></span>
<span id="cb4-5"><span class="im" style="color: #00769E;">from</span> cf_guidance.transforms <span class="im" style="color: #00769E;">import</span> GuidanceTfm, BaseNormGuidance, TNormGuidance, FullNormGuidance</span></code></pre></div>
</div>
<p>The <code>min_diffusion</code> library loads a Stable Diffusion model from the HuggingFace hub.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="co" style="color: #5E5E5E;"># to load Stable Diffusion pipelines</span></span>
<span id="cb5-2"><span class="im" style="color: #00769E;">from</span> min_diffusion.core <span class="im" style="color: #00769E;">import</span> MinimalDiffusion</span>
<span id="cb5-3"></span>
<span id="cb5-4"><span class="co" style="color: #5E5E5E;"># to plot generated images</span></span>
<span id="cb5-5"><span class="im" style="color: #00769E;">from</span> min_diffusion.utils <span class="im" style="color: #00769E;">import</span> show_image, image_grid, plot_grid</span></code></pre></div>
</div>
</section>
</section>
<section id="loading-the-new-openjourney-model-from-prompt-hero" class="level1">
<h1>Loading the new <code>openjourney</code> model from Prompt Hero</h1>
<p>The following code loads the <code>openjourney</code> Stable Diffusion model on the GPU, with <code>torch.float16</code> precision.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">model_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'prompthero/openjourney'</span></span>
<span id="cb6-2">device     <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'cuda'</span></span>
<span id="cb6-3">dtype      <span class="op" style="color: #5E5E5E;">=</span> torch.float16</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1">pipeline <span class="op" style="color: #5E5E5E;">=</span> MinimalDiffusion(model_name, device, dtype, generator<span class="op" style="color: #5E5E5E;">=</span>generator)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">pipeline.load()<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Enabling default unet attention slicing.</code></pre>
</div>
</div>
</section>
<section id="text-prompt-for-image-generations" class="level1">
<h1>Text prompt for image generations</h1>
<p>We use the familiar, running prompt in our series to generate an image:</p>
<blockquote class="blockquote">
<p>“a photograph of an astronaut riding a horse”</p>
</blockquote>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>The <code>openjourney</code> model was fine-tuned to create images in the style of <a href="https://mezha.media/en/2022/11/11/midjourney-v4-is-an-incredible-new-version-of-the-ai-image-generator/">Midjourney v4</a>.</p>
<p>To enable this fine-tuned style, we need to add the keyword <code>"mdjrny-v4"</code> at the start of the prompt.</p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;"># text prompt for image generations</span></span>
<span id="cb10-2">prompt <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"mdjrny-v4 style a photograph of an astronaut riding a horse"</span></span></code></pre></div>
</div>
<section id="image-parameters" class="level2">
<h2 class="anchored" data-anchor-id="image-parameters">Image parameters</h2>
<p>The images will be generated over <img src="https://latex.codecogs.com/png.latex?50"> diffusion steps. They will have a height and width of <code>512 x 512</code> pixels.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="co" style="color: #5E5E5E;"># the number of diffusion steps</span></span>
<span id="cb11-2">num_steps <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">50</span></span>
<span id="cb11-3"></span>
<span id="cb11-4"><span class="co" style="color: #5E5E5E;"># generated image dimensions</span></span>
<span id="cb11-5">width, height <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">512</span>, <span class="dv" style="color: #AD0000;">512</span></span></code></pre></div>
</div>
</section>
</section>
<section id="function-to-run-the-experiments" class="level1">
<h1>Function to run the experiments</h1>
<p>The <code>run</code> function below generates images for the text <code>prompt</code>.</p>
<p>The function sweeps a given set of <code>schedules</code> using the guidance normalization <code>guide_tfm</code>. It also stores the output images with a matching title for plotting and visualizations.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="kw" style="color: #003B4F;">def</span> run(prompt, schedules, guide_tfm<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>, generator<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb12-2">        show_each<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>, test_run<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>):</span>
<span id="cb12-3">    <span class="co" style="color: #5E5E5E;">"""Runs a dynamic Classifier-free Guidance experiment. </span></span>
<span id="cb12-4"><span class="co" style="color: #5E5E5E;">    </span></span>
<span id="cb12-5"><span class="co" style="color: #5E5E5E;">    Generates an image for the text `prompt` given all the values in `schedules`.</span></span>
<span id="cb12-6"><span class="co" style="color: #5E5E5E;">    Uses a Guidance Transformation class from the `cf_guidance` library.  </span></span>
<span id="cb12-7"><span class="co" style="color: #5E5E5E;">    Stores the output images with a matching title for plotting. </span></span>
<span id="cb12-8"><span class="co" style="color: #5E5E5E;">    Optionally shows each image as its generated.</span></span>
<span id="cb12-9"><span class="co" style="color: #5E5E5E;">    If `test_run` is true, it runs a single schedule for testing. </span></span>
<span id="cb12-10"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb12-11">    <span class="co" style="color: #5E5E5E;"># store generated images and their title (the experiment name)</span></span>
<span id="cb12-12">    images, titles <span class="op" style="color: #5E5E5E;">=</span> [], []</span>
<span id="cb12-13">    </span>
<span id="cb12-14">    <span class="co" style="color: #5E5E5E;"># make sure we have a valid guidance transform</span></span>
<span id="cb12-15">    <span class="cf" style="color: #003B4F;">assert</span> guide_tfm</span>
<span id="cb12-16">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Using Guidance Transform: </span><span class="sc" style="color: #5E5E5E;">{</span>guide_tfm<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb12-17">    </span>
<span id="cb12-18">    <span class="co" style="color: #5E5E5E;"># optionally run a single test schedule</span></span>
<span id="cb12-19">    <span class="cf" style="color: #003B4F;">if</span> test_run:</span>
<span id="cb12-20">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Running a single schedule for testing.'</span>)</span>
<span id="cb12-21">        schedules <span class="op" style="color: #5E5E5E;">=</span> schedules[:<span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb12-22">        </span>
<span id="cb12-23">    <span class="co" style="color: #5E5E5E;"># run all schedule experiments</span></span>
<span id="cb12-24">    <span class="cf" style="color: #003B4F;">for</span> i,s <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(schedules):</span>
<span id="cb12-25">        </span>
<span id="cb12-26">        <span class="co" style="color: #5E5E5E;"># parse out the title for the current run</span></span>
<span id="cb12-27">        cur_title  <span class="op" style="color: #5E5E5E;">=</span> s[<span class="st" style="color: #20794D;">'title'</span>]</span>
<span id="cb12-28">        titles.append(cur_title)</span>
<span id="cb12-29">        </span>
<span id="cb12-30">        <span class="co" style="color: #5E5E5E;"># create the guidance transformation </span></span>
<span id="cb12-31">        cur_sched <span class="op" style="color: #5E5E5E;">=</span> s[<span class="st" style="color: #20794D;">'schedule'</span>]</span>
<span id="cb12-32">        gtfm <span class="op" style="color: #5E5E5E;">=</span> guide_tfm({<span class="st" style="color: #20794D;">'g'</span>: cur_sched})</span>
<span id="cb12-33">        </span>
<span id="cb12-34">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Running experiment [</span><span class="sc" style="color: #5E5E5E;">{</span>i<span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;"> of </span><span class="sc" style="color: #5E5E5E;">{</span><span class="bu" style="color: null;">len</span>(schedules)<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">]: </span><span class="sc" style="color: #5E5E5E;">{</span>cur_title<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">...'</span>)</span>
<span id="cb12-35">        img <span class="op" style="color: #5E5E5E;">=</span> pipeline.generate(prompt, gtfm, generator<span class="op" style="color: #5E5E5E;">=</span>generator)</span>
<span id="cb12-36">        images.append(img)</span>
<span id="cb12-37">        </span>
<span id="cb12-38">        <span class="co" style="color: #5E5E5E;"># optionally plot the image</span></span>
<span id="cb12-39">        <span class="cf" style="color: #003B4F;">if</span> show_each:</span>
<span id="cb12-40">            show_image(img, scale<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb12-41"></span>
<span id="cb12-42">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Done.'</span>)</span>
<span id="cb12-43">    <span class="cf" style="color: #003B4F;">return</span> {<span class="st" style="color: #20794D;">'images'</span>: images,</span>
<span id="cb12-44">            <span class="st" style="color: #20794D;">'titles'</span>: titles,}</span></code></pre></div>
</div>
</section>
<section id="the-baseline-constant-guidance-with-g-7.5" class="level1">
<h1>The Baseline: Constant Guidance with <img src="https://latex.codecogs.com/png.latex?G%20=7.5"></h1>
<p>Here we create the baseline image. Then we check how the normalized, scheduled guidances change the output.</p>
<p>The baseline Classifier-free Guidance uses a constant update of <img src="https://latex.codecogs.com/png.latex?G%20=%207.5">.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="co" style="color: #5E5E5E;"># create the baseline Classifier-free Guidance</span></span>
<span id="cb13-2">baseline_params <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'max_val'</span>: [<span class="fl" style="color: #AD0000;">7.5</span>]}</span>
<span id="cb13-3"></span>
<span id="cb13-4"><span class="co" style="color: #5E5E5E;"># parameters we are sweeping</span></span>
<span id="cb13-5">baselines_names <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">sorted</span>(<span class="bu" style="color: null;">list</span>(baseline_params))</span>
<span id="cb13-6">baseline_scheds <span class="op" style="color: #5E5E5E;">=</span> L()</span>
<span id="cb13-7"></span>
<span id="cb13-8"><span class="co" style="color: #5E5E5E;"># step through each parameter</span></span>
<span id="cb13-9"><span class="cf" style="color: #003B4F;">for</span> idx,name <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(baselines_names):</span>
<span id="cb13-10">    <span class="co" style="color: #5E5E5E;"># step through each of its values</span></span>
<span id="cb13-11">    <span class="cf" style="color: #003B4F;">for</span> idj,val <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(baseline_params[name]):</span>
<span id="cb13-12"></span>
<span id="cb13-13">        <span class="co" style="color: #5E5E5E;"># create the baseline experimeent</span></span>
<span id="cb13-14">        expt <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb13-15">            <span class="st" style="color: #20794D;">'param_name'</span>: name,</span>
<span id="cb13-16">            <span class="st" style="color: #20794D;">'val'</span>: val,</span>
<span id="cb13-17">            <span class="st" style="color: #20794D;">'schedule'</span>: [val <span class="cf" style="color: #003B4F;">for</span> _ <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(num_steps)]</span>
<span id="cb13-18">        }</span>
<span id="cb13-19">        <span class="co" style="color: #5E5E5E;"># for plotting</span></span>
<span id="cb13-20">        expt[<span class="st" style="color: #20794D;">'title'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="ss" style="color: #20794D;">f'Param: "</span><span class="sc" style="color: #5E5E5E;">{</span>name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">", val=</span><span class="sc" style="color: #5E5E5E;">{</span>val<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb13-21">        </span>
<span id="cb13-22">        <span class="co" style="color: #5E5E5E;"># add to the running list of experiments</span></span>
<span id="cb13-23">        baseline_scheds.append(expt)</span></code></pre></div>
</div>
<p>We will be creating a lot of experiments, so let’s put this code in a function.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="kw" style="color: #003B4F;">def</span> create_expts(params: <span class="bu" style="color: null;">dict</span>, schedule_func) <span class="op" style="color: #5E5E5E;">-&gt;</span> <span class="bu" style="color: null;">list</span>:</span>
<span id="cb14-2">    names <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">sorted</span>(params)</span>
<span id="cb14-3">    expts <span class="op" style="color: #5E5E5E;">=</span> []</span>
<span id="cb14-4">    <span class="co" style="color: #5E5E5E;"># step through parameter names and their values</span></span>
<span id="cb14-5">    <span class="cf" style="color: #003B4F;">for</span> i,name <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(names):</span>
<span id="cb14-6">        <span class="cf" style="color: #003B4F;">for</span> j,val <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(params[name]):</span>
<span id="cb14-7">            <span class="co" style="color: #5E5E5E;"># create the experiment</span></span>
<span id="cb14-8">            expt <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'param_name'</span>: name,</span>
<span id="cb14-9">                    <span class="st" style="color: #20794D;">'val'</span>: val,</span>
<span id="cb14-10">                    <span class="st" style="color: #20794D;">'schedule'</span>: schedule_func({name: val}),}</span>
<span id="cb14-11">            <span class="co" style="color: #5E5E5E;"># name for plotting</span></span>
<span id="cb14-12">            expt[<span class="st" style="color: #20794D;">'title'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="ss" style="color: #20794D;">f'Param: "</span><span class="sc" style="color: #5E5E5E;">{</span>name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">", val=</span><span class="sc" style="color: #5E5E5E;">{</span>val<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb14-13">            <span class="co" style="color: #5E5E5E;"># add it to the experiment list</span></span>
<span id="cb14-14">            expts.append(expt)</span>
<span id="cb14-15">    <span class="cf" style="color: #003B4F;">return</span> expts</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="co" style="color: #5E5E5E;"># create the baseline schedule with the new function</span></span>
<span id="cb15-2">baseline_g <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">7.5</span></span>
<span id="cb15-3">baseline_params <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'max_val'</span>: [baseline_g]}</span>
<span id="cb15-4">baseline_func <span class="op" style="color: #5E5E5E;">=</span> <span class="kw" style="color: #003B4F;">lambda</span> params: [baseline_g <span class="cf" style="color: #003B4F;">for</span> _ <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(num_steps)]</span>
<span id="cb15-5">baseline_expts <span class="op" style="color: #5E5E5E;">=</span> create_expts(baseline_params, baseline_func)</span>
<span id="cb15-6">    </span></code></pre></div>
</div>
<p>Let’s create the baseline image. The hope is that our guidance changes will improve on it.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">baseline_res <span class="op" style="color: #5E5E5E;">=</span> run(prompt, baseline_expts, guide_tfm<span class="op" style="color: #5E5E5E;">=</span>GuidanceTfm)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Using Guidance Transform: &lt;class 'cf_guidance.transforms.GuidanceTfm'&gt;
Running experiment [1 of 1]: Param: "max_val", val=7.5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"3b67d254e88d49a0b83ab1534355df74","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="co" style="color: #5E5E5E;"># view the baseline image</span></span>
<span id="cb19-2">baseline_res[<span class="st" style="color: #20794D;">'images'</span>][<span class="dv" style="color: #AD0000;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-23-guidance-expts-4/index_files/figure-html/cell-16-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="improving-the-baseline-with-schedules-and-normalizations" class="level1">
<h1>Improving the baseline with schedules and normalizations</h1>
<p>This part is similar to its matching sections in <a href="https://enzokro.dev/blog/posts/2022-11-20-guidance-expts-2/#trying-to-improve-the-baseline">Part 1</a> and <a href="https://enzokro.dev/blog/posts/2022-11-21-guidance-expts-3/#improving-the-baseline-with-normalizations">Part 2</a>.</p>
<p>Here we create the sweep of Cosine Schedules and the normalizations.</p>
<section id="setting-the-schedule-parameters" class="level2">
<h2 class="anchored" data-anchor-id="setting-the-schedule-parameters">Setting the schedule parameters</h2>
<p>Recall that there are three kinds of schedules:</p>
<ol type="1">
<li>A static schedule with a constant <img src="https://latex.codecogs.com/png.latex?G">.<br>
</li>
<li>A decreasing Cosine schedule.<br>
</li>
<li>A Cosine schedule with some initial warm up steps.</li>
</ol>
<p>We already created the static schedule <code>1.</code> in the baseline above. This section creates variations of schedules <code>2.</code> and <code>3.</code>.</p>
<p>:::: {.callout-note}.<br>
We need smaller guidance values for <code>T-Normalization</code> and <code>Full Normalization</code>.</p>
<p>These normalizations get their own, smaller value of <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bsmall%7D%20=%200.15">. This smaller value keeps the guidance update vector <img src="https://latex.codecogs.com/png.latex?%5Cleft(%20t%20-%20u%20%5Cright)"> from exploding in scale.<br>
::::</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="co" style="color: #5E5E5E;"># Default schedule parameters from the blog post</span></span>
<span id="cb20-2"><span class="co" style="color: #5E5E5E;">######################################</span></span>
<span id="cb20-3">max_val           <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">7.5</span>   <span class="co" style="color: #5E5E5E;"># guidance scaling value</span></span>
<span id="cb20-4">min_val           <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span>     <span class="co" style="color: #5E5E5E;"># minimum guidance scaling</span></span>
<span id="cb20-5">num_steps         <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">50</span>    <span class="co" style="color: #5E5E5E;"># number of diffusion steps</span></span>
<span id="cb20-6">num_warmup_steps  <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span>     <span class="co" style="color: #5E5E5E;"># number of warmup steps</span></span>
<span id="cb20-7">warmup_init_val   <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span>     <span class="co" style="color: #5E5E5E;"># the intial warmup value</span></span>
<span id="cb20-8">num_cycles        <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.5</span>   <span class="co" style="color: #5E5E5E;"># number of cosine cycles</span></span>
<span id="cb20-9">k_decay           <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span>     <span class="co" style="color: #5E5E5E;"># k-decay for cosine curve scaling </span></span>
<span id="cb20-10"></span>
<span id="cb20-11"><span class="co" style="color: #5E5E5E;"># smaller values for T-Norm and FullNorm</span></span>
<span id="cb20-12">max_T <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.15</span></span>
<span id="cb20-13">min_T <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.05</span></span>
<span id="cb20-14"><span class="co" style="color: #5E5E5E;">######################################</span></span></code></pre></div>
</div>
<p>To make sure our changes always reference this shared starting point, we can wrap these parameters in a dictionary.</p>
<p>We also create a matching dictionary for the <code>T-Norm</code> params.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">DEFAULT_COS_PARAMS <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb21-2">    <span class="st" style="color: #20794D;">'max_val'</span>:           max_val,</span>
<span id="cb21-3">    <span class="st" style="color: #20794D;">'num_steps'</span>:         num_steps,</span>
<span id="cb21-4">    <span class="st" style="color: #20794D;">'min_val'</span>:           min_val,</span>
<span id="cb21-5">    <span class="st" style="color: #20794D;">'num_cycles'</span>:        num_cycles,</span>
<span id="cb21-6">    <span class="st" style="color: #20794D;">'k_decay'</span>:           k_decay,</span>
<span id="cb21-7">    <span class="st" style="color: #20794D;">'num_warmup_steps'</span>:  num_warmup_steps,</span>
<span id="cb21-8">    <span class="st" style="color: #20794D;">'warmup_init_val'</span>:   warmup_init_val,</span>
<span id="cb21-9">}</span>
<span id="cb21-10"></span>
<span id="cb21-11">DEFAULT_T_PARAMS <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb21-12">    <span class="st" style="color: #20794D;">'max_val'</span>:           max_T, <span class="co" style="color: #5E5E5E;"># max G_small value</span></span>
<span id="cb21-13">    <span class="st" style="color: #20794D;">'num_steps'</span>:         num_steps,</span>
<span id="cb21-14">    <span class="st" style="color: #20794D;">'min_val'</span>:           min_T, <span class="co" style="color: #5E5E5E;"># min G_small value</span></span>
<span id="cb21-15">    <span class="st" style="color: #20794D;">'num_cycles'</span>:        num_cycles,</span>
<span id="cb21-16">    <span class="st" style="color: #20794D;">'k_decay'</span>:           k_decay,</span>
<span id="cb21-17">    <span class="st" style="color: #20794D;">'num_warmup_steps'</span>:  num_warmup_steps,</span>
<span id="cb21-18">    <span class="st" style="color: #20794D;">'warmup_init_val'</span>:   warmup_init_val,</span>
<span id="cb21-19">}</span></code></pre></div>
</div>
<p>Every new, incremental schedule will start from these shared dictionaries. Then, a single parameter is changed at a time.</p>
<p>The <code>cos_harness</code> below gives us an easy way of making these minimum-pair changes.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="kw" style="color: #003B4F;">def</span> cos_harness(new_params<span class="op" style="color: #5E5E5E;">=</span>{}, default_params<span class="op" style="color: #5E5E5E;">=</span>{}):</span>
<span id="cb22-2">    <span class="co" style="color: #5E5E5E;">'''Creates cosine schedules with updated parameters in `new_params`</span></span>
<span id="cb22-3"><span class="co" style="color: #5E5E5E;">    '''</span></span>
<span id="cb22-4">    <span class="co" style="color: #5E5E5E;"># start from the given baseline `cos_params`</span></span>
<span id="cb22-5">    cos_params <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">dict</span>(default_params)</span>
<span id="cb22-6">    <span class="co" style="color: #5E5E5E;"># update the schedule with any new parameters</span></span>
<span id="cb22-7">    cos_params.update(new_params)</span>
<span id="cb22-8">    </span>
<span id="cb22-9">    <span class="co" style="color: #5E5E5E;"># return the new cosine schedule</span></span>
<span id="cb22-10">    sched <span class="op" style="color: #5E5E5E;">=</span> get_cos_sched(<span class="op" style="color: #5E5E5E;">**</span>cos_params)</span>
<span id="cb22-11">    <span class="cf" style="color: #003B4F;">return</span> sched</span></code></pre></div>
</div>
</section>
<section id="plotting-the-cosine-schedules" class="level2">
<h2 class="anchored" data-anchor-id="plotting-the-cosine-schedules">Plotting the Cosine Schedules</h2>
<p>Now we create the different Cosine schedules that will be swept.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">cos_params <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb23-2">    <span class="st" style="color: #20794D;">'num_warmup_steps'</span>: [<span class="dv" style="color: #AD0000;">5</span>, <span class="dv" style="color: #AD0000;">10</span>],</span>
<span id="cb23-3">    <span class="st" style="color: #20794D;">'num_cycles'</span>:       [<span class="dv" style="color: #AD0000;">1</span>, <span class="fl" style="color: #AD0000;">1.5</span>, <span class="dv" style="color: #AD0000;">2</span>],</span>
<span id="cb23-4">    <span class="st" style="color: #20794D;">'k_decay'</span>:          [<span class="fl" style="color: #AD0000;">0.7</span>, <span class="dv" style="color: #AD0000;">2</span>],</span>
<span id="cb23-5">    <span class="st" style="color: #20794D;">'max_val'</span>:          [<span class="dv" style="color: #AD0000;">8</span>, <span class="dv" style="color: #AD0000;">10</span>, <span class="dv" style="color: #AD0000;">12</span>],</span>
<span id="cb23-6">    <span class="st" style="color: #20794D;">'min_val'</span>:          [<span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">3</span>],</span>
<span id="cb23-7">}</span>
<span id="cb23-8"></span>
<span id="cb23-9"><span class="co" style="color: #5E5E5E;"># create the cosine experiments</span></span>
<span id="cb23-10">cos_func  <span class="op" style="color: #5E5E5E;">=</span> partial(cos_harness, default_params<span class="op" style="color: #5E5E5E;">=</span>DEFAULT_COS_PARAMS)</span>
<span id="cb23-11">cos_expts <span class="op" style="color: #5E5E5E;">=</span> create_expts(cos_params, cos_func)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">plot_grid([o[<span class="st" style="color: #20794D;">'schedule'</span>] <span class="cf" style="color: #003B4F;">for</span> o <span class="kw" style="color: #003B4F;">in</span> cos_expts], rows<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4</span>, titles<span class="op" style="color: #5E5E5E;">=</span>[o[<span class="st" style="color: #20794D;">'title'</span>] <span class="cf" style="color: #003B4F;">for</span> o <span class="kw" style="color: #003B4F;">in</span> cos_expts])</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-23-guidance-expts-4/index_files/figure-html/cell-21-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>We repeat the steps above to create the <code>T-Norm</code> experiments</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1">T_params <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb25-2">    <span class="st" style="color: #20794D;">'num_warmup_steps'</span>: [<span class="dv" style="color: #AD0000;">5</span>, <span class="dv" style="color: #AD0000;">10</span>],</span>
<span id="cb25-3">    <span class="st" style="color: #20794D;">'num_cycles'</span>:       [<span class="dv" style="color: #AD0000;">1</span>, <span class="fl" style="color: #AD0000;">1.5</span>, <span class="dv" style="color: #AD0000;">2</span>],</span>
<span id="cb25-4">    <span class="st" style="color: #20794D;">'k_decay'</span>:          [<span class="fl" style="color: #AD0000;">0.7</span>, <span class="dv" style="color: #AD0000;">2</span>],</span>
<span id="cb25-5">    <span class="st" style="color: #20794D;">'max_val'</span>:          [<span class="fl" style="color: #AD0000;">0.1</span>, <span class="fl" style="color: #AD0000;">0.2</span>, <span class="fl" style="color: #AD0000;">0.3</span>],</span>
<span id="cb25-6">    <span class="st" style="color: #20794D;">'min_val'</span>:          [<span class="fl" style="color: #AD0000;">0.01</span>, <span class="fl" style="color: #AD0000;">0.1</span>],</span>
<span id="cb25-7">}</span>
<span id="cb25-8"></span>
<span id="cb25-9"><span class="co" style="color: #5E5E5E;"># create the T-norm cosine experiments</span></span>
<span id="cb25-10">T_func  <span class="op" style="color: #5E5E5E;">=</span> partial(cos_harness, default_params<span class="op" style="color: #5E5E5E;">=</span>DEFAULT_T_PARAMS)</span>
<span id="cb25-11">T_expts <span class="op" style="color: #5E5E5E;">=</span> create_expts(T_params, T_func)</span></code></pre></div>
</div>
<p>We also plot the <code>T-Norm</code> schedules below. Note that we are trying a few max and min values.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1">plot_grid([o[<span class="st" style="color: #20794D;">'schedule'</span>] <span class="cf" style="color: #003B4F;">for</span> o <span class="kw" style="color: #003B4F;">in</span> T_expts], rows<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4</span>, titles<span class="op" style="color: #5E5E5E;">=</span>[o[<span class="st" style="color: #20794D;">'title'</span>] <span class="cf" style="color: #003B4F;">for</span> o <span class="kw" style="color: #003B4F;">in</span> T_expts])</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-23-guidance-expts-4/index_files/figure-html/cell-23-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="running-the-normalized-cosine-experiments" class="level2">
<h2 class="anchored" data-anchor-id="running-the-normalized-cosine-experiments">Running the normalized cosine experiments</h2>
<p>Next we sweep the schedules for each type of normalization.</p>
</section>
<section id="basenorm-runs" class="level2">
<h2 class="anchored" data-anchor-id="basenorm-runs"><code>BaseNorm</code> runs</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Running the BaseNorm experiments...'</span>)</span>
<span id="cb27-2">base_norm_cos_res <span class="op" style="color: #5E5E5E;">=</span> run(prompt, cos_expts, guide_tfm<span class="op" style="color: #5E5E5E;">=</span>BaseNormGuidance)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running the BaseNorm experiments...
Using Guidance Transform: &lt;class 'cf_guidance.transforms.BaseNormGuidance'&gt;
Running experiment [1 of 12]: Param: "k_decay", val=0.7...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"e5b3574a1f264f4cb9595c36ad383854","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [2 of 12]: Param: "k_decay", val=2...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"956746bc0a0c468fabf274312a5894dc","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [3 of 12]: Param: "max_val", val=8...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"42277f32eab24b918cd34cc61933f6c2","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [4 of 12]: Param: "max_val", val=10...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"c9e861dbdefc4c5fa405eda1b166963b","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [5 of 12]: Param: "max_val", val=12...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"95e161f75f4f4df68da1ed20cb2b926a","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [6 of 12]: Param: "min_val", val=2...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1faa203cdef44bf3b9b71af608bbfa31","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [7 of 12]: Param: "min_val", val=3...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"57da638442ac4058b385df0346a6d24e","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [8 of 12]: Param: "num_cycles", val=1...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"964dc915a8c44e6cac1498b2b9e7efb7","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [9 of 12]: Param: "num_cycles", val=1.5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"73399e43795a49cd90ccb6b83e6c95f4","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [10 of 12]: Param: "num_cycles", val=2...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1aabd0febae744f187bfd499606885d0","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [11 of 12]: Param: "num_warmup_steps", val=5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7d236ff24a534f83b4ac441a9b8328ad","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [12 of 12]: Param: "num_warmup_steps", val=10...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"6b80772c26464e088bc8d166912fd5eb","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.</code></pre>
</div>
</div>
</section>
<section id="t-norm-runs" class="level2">
<h2 class="anchored" data-anchor-id="t-norm-runs"><code>T-Norm</code> runs</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb41" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Running the T-Norm experiments...'</span>)</span>
<span id="cb41-2">t_norm_cos_res <span class="op" style="color: #5E5E5E;">=</span> run(prompt, T_expts, guide_tfm<span class="op" style="color: #5E5E5E;">=</span>TNormGuidance)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running the T-Norm experiments...
Using Guidance Transform: &lt;class 'cf_guidance.transforms.TNormGuidance'&gt;
Running experiment [1 of 12]: Param: "k_decay", val=0.7...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"22757c8077f44bc8bd017fb754c9c793","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [2 of 12]: Param: "k_decay", val=2...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1da00e586f4542499f37fbcb896690c7","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [3 of 12]: Param: "max_val", val=0.1...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"5367c8d637794b5e9224dc9d55d6f18d","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [4 of 12]: Param: "max_val", val=0.2...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"3e170f3b919b4e85a49c3a7320ee9335","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [5 of 12]: Param: "max_val", val=0.3...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"28ce448298ab4db8b149d73de4396b3c","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [6 of 12]: Param: "min_val", val=0.01...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ac622a8974244d1eade9bc0c931aa287","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [7 of 12]: Param: "min_val", val=0.1...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1c4715488d7a42cba581b99e488e1f82","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [8 of 12]: Param: "num_cycles", val=1...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"2c732500aeff4326b13d2bfa640f1e9b","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [9 of 12]: Param: "num_cycles", val=1.5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"96a20bf76b3a46c79adcbfdf93c5009a","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [10 of 12]: Param: "num_cycles", val=2...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4d8789ae9f14442a8022d4391848b52b","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [11 of 12]: Param: "num_warmup_steps", val=5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"20927024afb543099f50afccee32843a","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [12 of 12]: Param: "num_warmup_steps", val=10...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7551fb8f96474bdbbdda57640fd5e31c","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.</code></pre>
</div>
</div>
</section>
<section id="fullnorm-runs" class="level2">
<h2 class="anchored" data-anchor-id="fullnorm-runs"><code>FullNorm</code> runs</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb55" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Running the FullNorm experiments...'</span>)</span>
<span id="cb55-2">full_norm_cos_res <span class="op" style="color: #5E5E5E;">=</span> run(prompt, T_expts, guide_tfm<span class="op" style="color: #5E5E5E;">=</span>FullNormGuidance)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running the FullNorm experiments...
Using Guidance Transform: &lt;class 'cf_guidance.transforms.FullNormGuidance'&gt;
Running experiment [1 of 12]: Param: "k_decay", val=0.7...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"787a15c0da154d45baff48e544fdb084","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [2 of 12]: Param: "k_decay", val=2...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"a5381a8e7ec541649d9c7863de42b5be","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [3 of 12]: Param: "max_val", val=0.1...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"24e74b3f2f0340d393f65a041c30aeb4","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [4 of 12]: Param: "max_val", val=0.2...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"d95cebf681db4fa48950edc15d285cc0","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [5 of 12]: Param: "max_val", val=0.3...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7cdec17deb634f7283eaaf2d80dc9d35","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [6 of 12]: Param: "min_val", val=0.01...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"660d7a0a36834ffe97b0bafa7ee1b47c","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [7 of 12]: Param: "min_val", val=0.1...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"20f0888e4d2a42f1a5dec0f3dc9d6d7a","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [8 of 12]: Param: "num_cycles", val=1...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"42351bec358c458ea1109056bf418d47","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [9 of 12]: Param: "num_cycles", val=1.5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"467b9798d4ed4d45b4d13779737ce5d7","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [10 of 12]: Param: "num_cycles", val=2...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b7367534fcd640fdbed65bf87a70f866","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [11 of 12]: Param: "num_warmup_steps", val=5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b0dd33f489c44e04a54100245deff079","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [12 of 12]: Param: "num_warmup_steps", val=10...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f971e8685b934128b60d630dc184d338","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.</code></pre>
</div>
</div>
</section>
</section>
<section id="results" class="level1">
<h1>Results</h1>
<section id="basenorm-results" class="level2">
<h2 class="anchored" data-anchor-id="basenorm-results"><code>BaseNorm</code> results</h2>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-23-guidance-expts-4/index_files/figure-html/cell-27-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="t-norm-results" class="level2">
<h2 class="anchored" data-anchor-id="t-norm-results"><code>T-Norm</code> results</h2>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-23-guidance-expts-4/index_files/figure-html/cell-28-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="fullnorm-results" class="level2">
<h2 class="anchored" data-anchor-id="fullnorm-results"><code>FullNorm</code> results</h2>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-23-guidance-expts-4/index_files/figure-html/cell-29-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="analysis" class="level2">
<h2 class="anchored" data-anchor-id="analysis">Analysis</h2>
<p>There are many images and parameter changes going on.</p>
<p>Broadly speaking, across normalizations, the following schedules show the most promise:</p>
<ul>
<li>Changing <code>k-decay</code>.<br>
</li>
<li>Allowing for some warmup steps.<br>
</li>
<li>Increasing the maximum value of <img src="https://latex.codecogs.com/png.latex?G">.<br>
</li>
<li>Allow the cosine to go through more cycles.</li>
</ul>
<p>The other changes either have negligible gains or actively corrupted the image.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>This notebook was Part 3 in a series on dynamic Classifier-free Guidance.</p>
<p>It combined guidance normalizations and schedules to see if we could make even better images.</p>
<p>We found a promising set of changes that seem to improve on the static, constant baseline.</p>
<p>In Part 4, we will dig into some of the promising schedules to find more answers.</p>


</section>

 ]]></description>
  <category>diffusion</category>
  <category>classifier-free guidance</category>
  <category>deep learning</category>
  <guid>https://enzokro.dev/blog/posts/2022-11-23-guidance-expts-4/index.html</guid>
  <pubDate>Wed, 23 Nov 2022 00:00:00 GMT</pubDate>
  <media:content url="https://enzokro.dev/blog/posts/2022-11-23-guidance-expts-4/better_horse_4.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Dynamic Classifier-free Guidance Pt. 2</title>
  <dc:creator>enzokro</dc:creator>
  <link>https://enzokro.dev/blog/posts/2022-11-21-guidance-expts-3/index.html</link>
  <description><![CDATA[ 



<blockquote class="blockquote">
<p>Experiments with normalizations for Classifier-free Guidance.</p>
</blockquote>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>This notebook is Part 2 in a <a href="https://enzokro.dev/blog/posts/2022-11-15-guidance-expts-2/">series</a> on dynamic Classifier-free Guidance.</p>
<section id="quick-recap-of-part-1" class="level2">
<h2 class="anchored" data-anchor-id="quick-recap-of-part-1">Quick recap of Part 1</h2>
<p>In Part 1, we generated a baseline image using the default, static Classifier-free Guidance. To see if we could improve on the baseline, we swept a range of Cosine Schedules on the guidance parameter <img src="https://latex.codecogs.com/png.latex?G">.</p>
<p>To recap the results of the sweep, there are a few promising guidance schedules to explore:</p>
<ul>
<li>Setting a higher guidance value.<br>
</li>
<li>Allowing the Cosine schedule to go through multiple cycles.<br>
</li>
<li>Warming up the guidance for a few steps.</li>
</ul>
</section>
<section id="part-2-bringing-in-normalizations" class="level2">
<h2 class="anchored" data-anchor-id="part-2-bringing-in-normalizations">Part 2: Bringing in Normalizations</h2>
<p>In Part 2, we bring in normalizations as another kind of dynamic guidance.</p>
<p>The idea is that normalizing the guidance might improve the updates in the Diffusion model’s latent image space. To test this we explore three kinds of guidance normalizations:</p>
<ol type="1">
<li>Normalizing the prediction by its overall norm.<br>
</li>
<li>Normalizing the guidance update vector, <img src="https://latex.codecogs.com/png.latex?%5Cleft(t%20-%20u%5Cright)">, by its norm.<br>
</li>
<li>Combining the Normalizations in <code>1.</code> and <code>2.</code></li>
</ol>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>More details about the normalizations can be found in <a href="https://enzokro.dev/blog/posts/2022-11-15-guidance-expts-1/#normalizing-the-guidance">this section</a> of the original post.</p>
</div>
</div>
<p>After these runs, we should have a good idea of both the schedules and normalizations that can improve Diffusion images. We will then combine the two approaches and explore other, more advanced schedules.</p>
</section>
<section id="leveraging-a-few-helper-libraries" class="level2">
<h2 class="anchored" data-anchor-id="leveraging-a-few-helper-libraries">Leveraging a few helper libraries</h2>
<p>We use two new libraries that make it easier to run dynamic Classifier-free Guidances.<br>
These two libraries are:</p>
<ul>
<li><code>min_diffusion</code></li>
<li><code>cf_guidance</code></li>
</ul>
<p>The helper libraries remove a lot of overhead and boilerplate code. They allow us to jump straight to the important parts: running the guidance experiments.</p>
<p>For more details, the libraries were introduced in <a href="https://enzokro.dev/blog/posts/2022-11-20-minimal-diffusion/">this earlier post</a>.</p>
</section>
</section>
<section id="experiment-setup" class="level1">
<h1>Experiment Setup</h1>
<section id="python-imports" class="level2">
<h2 class="anchored" data-anchor-id="python-imports">Python Imports</h2>
<p>To start we import the needed python modules.</p>
<p>We also handle random seeding to make sure that our results are reproducible across the series.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> os</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> math</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">import</span> random</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> warnings</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">from</span> PIL <span class="im" style="color: #00769E;">import</span> Image</span>
<span id="cb1-6"><span class="im" style="color: #00769E;">from</span> typing <span class="im" style="color: #00769E;">import</span> List</span>
<span id="cb1-7"><span class="im" style="color: #00769E;">from</span> pathlib <span class="im" style="color: #00769E;">import</span> Path</span>
<span id="cb1-8"><span class="im" style="color: #00769E;">from</span> types <span class="im" style="color: #00769E;">import</span> SimpleNamespace</span>
<span id="cb1-9"><span class="im" style="color: #00769E;">from</span> fastcore.<span class="bu" style="color: null;">all</span> <span class="im" style="color: #00769E;">import</span> L</span>
<span id="cb1-10"></span>
<span id="cb1-11"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-12"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb1-13"></span>
<span id="cb1-14"><span class="co" style="color: #5E5E5E;"># imports for diffusion models</span></span>
<span id="cb1-15"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb1-16"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> logging</span>
<span id="cb1-17"><span class="co" style="color: #5E5E5E;"># for clean outputs</span></span>
<span id="cb1-18">warnings.filterwarnings(<span class="st" style="color: #20794D;">"ignore"</span>)</span>
<span id="cb1-19">logging.set_verbosity_error()</span>
<span id="cb1-20"></span>
<span id="cb1-21"><span class="co" style="color: #5E5E5E;"># seed for reproducibility</span></span>
<span id="cb1-22">SEED <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1024</span></span>
<span id="cb1-23"><span class="kw" style="color: #003B4F;">def</span> seed_everything(seed: <span class="bu" style="color: null;">int</span>):</span>
<span id="cb1-24">    random.seed(seed)</span>
<span id="cb1-25">    os.environ[<span class="st" style="color: #20794D;">'PYTHONHASHSEED'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">str</span>(seed)</span>
<span id="cb1-26">    np.random.seed(seed)</span>
<span id="cb1-27">    generator <span class="op" style="color: #5E5E5E;">=</span> torch.manual_seed(seed)</span>
<span id="cb1-28">    torch.backends.cudnn.deterministic <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">True</span></span>
<span id="cb1-29">    torch.backends.cudnn.benchmark <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">False</span></span>
<span id="cb1-30">    <span class="cf" style="color: #003B4F;">return</span> generator</span>
<span id="cb1-31"><span class="co" style="color: #5E5E5E;"># for sampling the initial, noisy latents</span></span>
<span id="cb1-32">generator <span class="op" style="color: #5E5E5E;">=</span> seed_everything(SEED)</span>
<span id="cb1-33"></span>
<span id="cb1-34"><span class="co" style="color: #5E5E5E;"># set the hardware device</span></span>
<span id="cb1-35">device <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"cuda"</span> <span class="cf" style="color: #003B4F;">if</span> torch.cuda.is_available() <span class="cf" style="color: #003B4F;">else</span> <span class="st" style="color: #20794D;">"mps"</span> <span class="cf" style="color: #003B4F;">if</span> torch.has_mps <span class="cf" style="color: #003B4F;">else</span> <span class="st" style="color: #20794D;">"cpu"</span></span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2022-11-23 14:58:50.779076: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0</code></pre>
</div>
</div>
</section>
<section id="the-min_diffusion-library" class="level2">
<h2 class="anchored" data-anchor-id="the-min_diffusion-library">The <code>min_diffusion</code> library</h2>
<p>We use the <code>min_diffusion</code> library to load a Stable Diffusion model from the HuggingFace hub.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;"># to load Stable Diffusion pipelines</span></span>
<span id="cb3-2"><span class="im" style="color: #00769E;">from</span> min_diffusion.core <span class="im" style="color: #00769E;">import</span> MinimalDiffusion</span>
<span id="cb3-3"></span>
<span id="cb3-4"><span class="co" style="color: #5E5E5E;"># helpers to plot the generated images</span></span>
<span id="cb3-5"><span class="im" style="color: #00769E;">from</span> min_diffusion.utils <span class="im" style="color: #00769E;">import</span> show_image, image_grid</span></code></pre></div>
</div>
<section id="loading-the-openjourney-model-from-prompt-hero" class="level3">
<h3 class="anchored" data-anchor-id="loading-the-openjourney-model-from-prompt-hero">Loading the <code>openjourney</code> model from Prompt Hero</h3>
<p>The following code loads the <code>openjourney</code> model in <code>torch.float16</code> precision and puts it on the GPU.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">model_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'prompthero/openjourney'</span></span>
<span id="cb4-2">device     <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'cuda'</span></span>
<span id="cb4-3">dtype      <span class="op" style="color: #5E5E5E;">=</span> torch.float16</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">pipeline <span class="op" style="color: #5E5E5E;">=</span> MinimalDiffusion(model_name, device, dtype)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">pipeline.load()<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Enabling default unet attention slicing.</code></pre>
</div>
</div>
</section>
</section>
<section id="text-prompt-for-generations" class="level2">
<h2 class="anchored" data-anchor-id="text-prompt-for-generations">Text prompt for generations</h2>
<p>We use the familiar, running prompt in our series to generate an image:</p>
<blockquote class="blockquote">
<p>“a photograph of an astronaut riding a horse”</p>
</blockquote>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>The <code>openjourney</code> model was fine-tuned to create images in the style of <a href="https://mezha.media/en/2022/11/11/midjourney-v4-is-an-incredible-new-version-of-the-ai-image-generator/">Midjourney v4</a>.</p>
<p>To enable this fine-tuned style, we need to add the keyword <code>"mdjrny-v4"</code> at the start of the prompt.</p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;"># text prompt for image generations</span></span>
<span id="cb8-2">prompt <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"mdjrny-v4 style a photograph of an astronaut riding a horse"</span></span></code></pre></div>
</div>
</section>
<section id="image-parameters" class="level2">
<h2 class="anchored" data-anchor-id="image-parameters">Image parameters</h2>
<p>The images will be generated over <img src="https://latex.codecogs.com/png.latex?50"> diffusion steps. They will have a height and width of <code>512 x 512</code> pixels.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="co" style="color: #5E5E5E;"># the number of diffusion steps</span></span>
<span id="cb9-2">num_steps <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">50</span></span>
<span id="cb9-3"></span>
<span id="cb9-4"><span class="co" style="color: #5E5E5E;"># generated image dimensions</span></span>
<span id="cb9-5">width, height <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">512</span>, <span class="dv" style="color: #AD0000;">512</span></span></code></pre></div>
</div>
</section>
</section>
<section id="the-baseline-guidance-with-a-constant-g-7.5" class="level1">
<h1>The Baseline: Guidance with a constant <img src="https://latex.codecogs.com/png.latex?G%20=7.5"></h1>
<p>First we create the baseline. Then we will check how a normalized, dynamic guidance changes the output.</p>
<p>The baseline Classifier-free Guidance uses a static, constant update of <img src="https://latex.codecogs.com/png.latex?G%20=%207.5">.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="im" style="color: #00769E;">from</span> cf_guidance.transforms <span class="im" style="color: #00769E;">import</span> GuidanceTfm, BaseNormGuidance, TNormGuidance, FullNormGuidance</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="co" style="color: #5E5E5E;"># create the baseline Classifier-free Guidance</span></span>
<span id="cb11-2">baseline_run <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'max_val'</span>: [<span class="fl" style="color: #AD0000;">7.5</span>]}</span>
<span id="cb11-3"></span>
<span id="cb11-4"><span class="co" style="color: #5E5E5E;"># parameters we are sweeping</span></span>
<span id="cb11-5">baselines_names <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">sorted</span>(<span class="bu" style="color: null;">list</span>(baseline_run))</span>
<span id="cb11-6">baseline_scheds <span class="op" style="color: #5E5E5E;">=</span> L()</span>
<span id="cb11-7"></span>
<span id="cb11-8"><span class="co" style="color: #5E5E5E;"># step through each parameter</span></span>
<span id="cb11-9"><span class="cf" style="color: #003B4F;">for</span> idx,name <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(baselines_names):</span>
<span id="cb11-10">    <span class="co" style="color: #5E5E5E;"># step through each of its values</span></span>
<span id="cb11-11">    <span class="cf" style="color: #003B4F;">for</span> idj,val <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(baseline_run[name]):</span>
<span id="cb11-12"></span>
<span id="cb11-13">        <span class="co" style="color: #5E5E5E;"># create the baseline experimeent</span></span>
<span id="cb11-14">        expt <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb11-15">            <span class="st" style="color: #20794D;">'param_name'</span>: name,</span>
<span id="cb11-16">            <span class="st" style="color: #20794D;">'val'</span>: val,</span>
<span id="cb11-17">            <span class="st" style="color: #20794D;">'schedule'</span>: [val <span class="cf" style="color: #003B4F;">for</span> _ <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(num_steps)]</span>
<span id="cb11-18">        }</span>
<span id="cb11-19">        <span class="co" style="color: #5E5E5E;"># for plotting</span></span>
<span id="cb11-20">        expt[<span class="st" style="color: #20794D;">'title'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="ss" style="color: #20794D;">f'Param: "</span><span class="sc" style="color: #5E5E5E;">{</span>name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">", val=</span><span class="sc" style="color: #5E5E5E;">{</span>val<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb11-21">        </span>
<span id="cb11-22">        <span class="co" style="color: #5E5E5E;"># add to the running list of experiments</span></span>
<span id="cb11-23">        baseline_scheds.append(expt)</span></code></pre></div>
</div>
<section id="wrapper-to-run-the-experiments" class="level2">
<h2 class="anchored" data-anchor-id="wrapper-to-run-the-experiments">Wrapper to run the experiments</h2>
<p>The <code>run</code> function below generates images from a given prompt.</p>
<p>It also takes an argument <code>guide_tfm</code> for the specific Guidance Transformation class that will guide the outputs. The <code>schedules</code> argument has the parameter values of <img src="https://latex.codecogs.com/png.latex?G"> at each diffusion timestep.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="kw" style="color: #003B4F;">def</span> run(prompt, schedules, guide_tfm<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>, generator<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>,</span>
<span id="cb12-2">        show_each<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>, test_run<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>):</span>
<span id="cb12-3">    <span class="co" style="color: #5E5E5E;">"""Runs a dynamic Classifier-free Guidance experiment. </span></span>
<span id="cb12-4"><span class="co" style="color: #5E5E5E;">    </span></span>
<span id="cb12-5"><span class="co" style="color: #5E5E5E;">    Generates an image for the text `prompt` given all the values in `schedules`.</span></span>
<span id="cb12-6"><span class="co" style="color: #5E5E5E;">    Uses a Guidance Transformation class from the `cf_guidance` library.  </span></span>
<span id="cb12-7"><span class="co" style="color: #5E5E5E;">    Stores the output images with a matching title for plotting. </span></span>
<span id="cb12-8"><span class="co" style="color: #5E5E5E;">    Optionally shows each image as its generated.</span></span>
<span id="cb12-9"><span class="co" style="color: #5E5E5E;">    If `test_run` is true, it runs a single schedule for testing. </span></span>
<span id="cb12-10"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb12-11">    <span class="co" style="color: #5E5E5E;"># store generated images and their title (the experiment name)</span></span>
<span id="cb12-12">    images, titles <span class="op" style="color: #5E5E5E;">=</span> [], []</span>
<span id="cb12-13">    </span>
<span id="cb12-14">    <span class="co" style="color: #5E5E5E;"># make sure we have a valid guidance transform</span></span>
<span id="cb12-15">    <span class="cf" style="color: #003B4F;">assert</span> guide_tfm</span>
<span id="cb12-16">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Using Guidance Transform: </span><span class="sc" style="color: #5E5E5E;">{</span>guide_tfm<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb12-17">    </span>
<span id="cb12-18">    <span class="co" style="color: #5E5E5E;"># optionally run a single test schedule</span></span>
<span id="cb12-19">    <span class="cf" style="color: #003B4F;">if</span> test_run:</span>
<span id="cb12-20">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Running a single schedule for testing.'</span>)</span>
<span id="cb12-21">        schedules <span class="op" style="color: #5E5E5E;">=</span> schedules[:<span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb12-22">        </span>
<span id="cb12-23"></span>
<span id="cb12-24">    <span class="co" style="color: #5E5E5E;"># run all schedule experiments</span></span>
<span id="cb12-25">    <span class="cf" style="color: #003B4F;">for</span> i,s <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(schedules):</span>
<span id="cb12-26">        </span>
<span id="cb12-27">        <span class="co" style="color: #5E5E5E;"># parse out the title for the current run</span></span>
<span id="cb12-28">        cur_title  <span class="op" style="color: #5E5E5E;">=</span> s[<span class="st" style="color: #20794D;">'title'</span>]</span>
<span id="cb12-29">        titles.append(cur_title)</span>
<span id="cb12-30">        </span>
<span id="cb12-31">        <span class="co" style="color: #5E5E5E;"># create the guidance transformation </span></span>
<span id="cb12-32">        cur_sched <span class="op" style="color: #5E5E5E;">=</span> s[<span class="st" style="color: #20794D;">'schedule'</span>]</span>
<span id="cb12-33">        gtfm <span class="op" style="color: #5E5E5E;">=</span> guide_tfm({<span class="st" style="color: #20794D;">'g'</span>: cur_sched})</span>
<span id="cb12-34">        </span>
<span id="cb12-35">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Running experiment [</span><span class="sc" style="color: #5E5E5E;">{</span>i<span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;"> of </span><span class="sc" style="color: #5E5E5E;">{</span><span class="bu" style="color: null;">len</span>(schedules)<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">]: </span><span class="sc" style="color: #5E5E5E;">{</span>cur_title<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">...'</span>)</span>
<span id="cb12-36">        img <span class="op" style="color: #5E5E5E;">=</span> pipeline.generate(prompt, gtfm, generator<span class="op" style="color: #5E5E5E;">=</span>generator)</span>
<span id="cb12-37">        images.append(img)</span>
<span id="cb12-38">        </span>
<span id="cb12-39">        <span class="co" style="color: #5E5E5E;"># optionally plot the image</span></span>
<span id="cb12-40">        <span class="cf" style="color: #003B4F;">if</span> show_each:</span>
<span id="cb12-41">            show_image(img, scale<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb12-42"></span>
<span id="cb12-43">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Done.'</span>)</span>
<span id="cb12-44">    <span class="cf" style="color: #003B4F;">return</span> {<span class="st" style="color: #20794D;">'images'</span>: images,</span>
<span id="cb12-45">            <span class="st" style="color: #20794D;">'titles'</span>: titles,}</span></code></pre></div>
</div>
<p>Let’s create the baseline image. The hope is that our guidance changes will then improve on it.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1">baseline_res <span class="op" style="color: #5E5E5E;">=</span> run(prompt, baseline_scheds, guide_tfm<span class="op" style="color: #5E5E5E;">=</span>GuidanceTfm, generator<span class="op" style="color: #5E5E5E;">=</span>generator)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Using Guidance Transform: &lt;class 'cf_guidance.transforms.GuidanceTfm'&gt;
Running experiment [1 of 1]: Param: "max_val", val=7.5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7aa68e80fb914df4b934fc9f14547902","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="co" style="color: #5E5E5E;"># view the baseline image</span></span>
<span id="cb16-2">baseline_res[<span class="st" style="color: #20794D;">'images'</span>][<span class="dv" style="color: #AD0000;">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-21-guidance-expts-3/index_files/figure-html/cell-15-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Not a bad starting point. Let’s see if we can do better.</p>
</section>
</section>
<section id="improving-the-baseline-with-normalizations" class="level1">
<h1>Improving the baseline with normalizations</h1>
<p>It seems that normalizations can improve both the syntax and details of Diffusion images.</p>
<p>We explore three kinds of normalizations:</p>
<ol type="1">
<li><code>Prediction Normalization</code><br>
</li>
<li><code>T-Normalization</code></li>
<li><code>Full Normalization</code></li>
</ol>
<section id="details-on-normalized-guidance-values" class="level2">
<h2 class="anchored" data-anchor-id="details-on-normalized-guidance-values">Details on normalized Guidance values</h2>
<p>For <code>Prediction Normalization</code> we can use the same static <img src="https://latex.codecogs.com/png.latex?G%20=%207.5"> from the baseline.</p>
<p>For both <code>T-Normalization</code> and <code>Full Normalization</code>, however, we need a much smaller guidance value. The reason is that these normalizations scale the update vector <img src="https://latex.codecogs.com/png.latex?%5Cleft(%20t%20-%20u%20%5Cright)"> itself. That means that a large value like <img src="https://latex.codecogs.com/png.latex?G%20=%207.5"> would de-scale the vectors even more! That is the exact situation we are trying to avoid with normalization in the first place.</p>
<p>To prevent this, we create a special <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bsmall%7D"> schedule for T and Full Normalizations with a smaller value of <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bsmall%7D%20=%200.15"></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="co" style="color: #5E5E5E;"># create the baseline Classifier-free Guidance</span></span>
<span id="cb17-2">T_run <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'max_val'</span>: [<span class="fl" style="color: #AD0000;">0.15</span>]}</span>
<span id="cb17-3"></span>
<span id="cb17-4"><span class="co" style="color: #5E5E5E;"># parameters we are sweeping</span></span>
<span id="cb17-5">T_scheds <span class="op" style="color: #5E5E5E;">=</span> L()</span>
<span id="cb17-6"></span>
<span id="cb17-7"><span class="co" style="color: #5E5E5E;"># step through each parameter</span></span>
<span id="cb17-8"><span class="cf" style="color: #003B4F;">for</span> idx,name <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(baselines_names):</span>
<span id="cb17-9">    <span class="co" style="color: #5E5E5E;"># step through each of its values</span></span>
<span id="cb17-10">    <span class="cf" style="color: #003B4F;">for</span> idj,val <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(T_run[name]):</span>
<span id="cb17-11"></span>
<span id="cb17-12">        <span class="co" style="color: #5E5E5E;"># create the baseline experimeent</span></span>
<span id="cb17-13">        expt <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb17-14">            <span class="st" style="color: #20794D;">'param_name'</span>: name,</span>
<span id="cb17-15">            <span class="st" style="color: #20794D;">'val'</span>: val,</span>
<span id="cb17-16">            <span class="st" style="color: #20794D;">'schedule'</span>: [val <span class="cf" style="color: #003B4F;">for</span> _ <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(num_steps)]</span>
<span id="cb17-17">        }</span>
<span id="cb17-18">        <span class="co" style="color: #5E5E5E;"># for plotting</span></span>
<span id="cb17-19">        expt[<span class="st" style="color: #20794D;">'title'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="ss" style="color: #20794D;">f'Param: "</span><span class="sc" style="color: #5E5E5E;">{</span>name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">", val=</span><span class="sc" style="color: #5E5E5E;">{</span>val<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb17-20">        </span>
<span id="cb17-21">        <span class="co" style="color: #5E5E5E;"># add to the running list of experiments</span></span>
<span id="cb17-22">        T_scheds.append(expt)</span></code></pre></div>
</div>
</section>
<section id="prediction-norm-runs" class="level2">
<h2 class="anchored" data-anchor-id="prediction-norm-runs"><code>Prediction Norm</code> runs</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Running the BaseNorm experiments...'</span>)</span>
<span id="cb18-2">base_norm_res <span class="op" style="color: #5E5E5E;">=</span> run(prompt, baseline_scheds, guide_tfm<span class="op" style="color: #5E5E5E;">=</span>BaseNormGuidance, generator<span class="op" style="color: #5E5E5E;">=</span>generator)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running the BaseNorm experiments...
Using Guidance Transform: &lt;class 'cf_guidance.transforms.BaseNormGuidance'&gt;
Running experiment [1 of 1]: Param: "max_val", val=7.5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"00ea0b8029ea424cba0aef86cc74bd45","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.</code></pre>
</div>
</div>
</section>
<section id="t-norm-runs" class="level2">
<h2 class="anchored" data-anchor-id="t-norm-runs"><code>T-Norm</code> runs</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Running the T-Norm experiments...'</span>)</span>
<span id="cb21-2">t_norm_res <span class="op" style="color: #5E5E5E;">=</span> run(prompt, T_scheds, guide_tfm<span class="op" style="color: #5E5E5E;">=</span>TNormGuidance, generator<span class="op" style="color: #5E5E5E;">=</span>generator)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running the T-Norm experiments...
Using Guidance Transform: &lt;class 'cf_guidance.transforms.TNormGuidance'&gt;
Running experiment [1 of 1]: Param: "max_val", val=0.15...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"49d8b9791466436897e08e23fe7b4c41","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.</code></pre>
</div>
</div>
</section>
<section id="full-norm-runs" class="level2">
<h2 class="anchored" data-anchor-id="full-norm-runs"><code>Full Norm</code> runs</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Running the FullNorm experiments...'</span>)</span>
<span id="cb24-2">full_norm_res <span class="op" style="color: #5E5E5E;">=</span> run(prompt, T_scheds, guide_tfm<span class="op" style="color: #5E5E5E;">=</span>FullNormGuidance, generator<span class="op" style="color: #5E5E5E;">=</span>generator)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running the FullNorm experiments...
Using Guidance Transform: &lt;class 'cf_guidance.transforms.FullNormGuidance'&gt;
Running experiment [1 of 1]: Param: "max_val", val=0.15...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b69d1346091f4f7cb362e38b7d001f91","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.</code></pre>
</div>
</div>
</section>
</section>
<section id="results" class="level1">
<h1>Results</h1>
<p>Let’s compare each result to the baseline.</p>
<p>The baseline image is on the left, and the normalized version is on the right.</p>
<section id="prediction-norm-results" class="level2">
<h2 class="anchored" data-anchor-id="prediction-norm-results"><code>Prediction Norm</code> results</h2>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-21-guidance-expts-3/index_files/figure-html/cell-20-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Comparing left to right, <code>Prediction Normalization</code> improves the overall image.</p>
<p>The horse’s body and hair are more defined. The clouds in the background have more texture. The lowest orb in the sky is much better defined. The shadows on the ground also have better coverage and a more natural transition. The ground itself has more details and texture, and is better separated from the background sky.</p>
<p>Even the reflection on the astronaut’s helmet has more depth and looks smoother.</p>
<p>Overall, it seems that <code>Prediction Normalization</code> is a global improvement on the baseline.</p>
</section>
<section id="t-norm-results" class="level2">
<h2 class="anchored" data-anchor-id="t-norm-results"><code>T-Norm</code> results</h2>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-21-guidance-expts-3/index_files/figure-html/cell-21-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>This one is much more interesting. <code>T-Normalization</code> completely changed the image! Even though they started from the exact same noisy latents.</p>
<p>Here the horse’s anatomy, especially its head, look more correct. Even though we lost overall illumination on the horse’s body.</p>
<p>The patches and details on the astronaut’s gear are also better defined. And maybe it’s subjective, but this one <em>feels</em> more like a photograph (thanks to helmet’s glare) while the baseline looks more like digital art.</p>
</section>
<section id="full-norm-results" class="level2">
<h2 class="anchored" data-anchor-id="full-norm-results"><code>Full Norm</code> results</h2>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-21-guidance-expts-3/index_files/figure-html/cell-22-output-1.png" class="img-fluid"></p>
</div>
</div>
<p><code>Full Normalization</code> feels like a mix of the best from both worlds.</p>
<p>The horse’s anatomy and astronaut details are better, following the results from <code>T-Normalization</code>. And we regained some background vs.&nbsp;foreground separation from <code>Prediction Normalization</code>.</p>
<p>It seems this dual benefit came at the cost of some symmetry for the orbs in the sky, and a loss of resolution on the horse’s tail.</p>
</section>
<section id="analysis" class="level2">
<h2 class="anchored" data-anchor-id="analysis">Analysis</h2>
<p>Overall, at least for this example, it is fair to say that normalizations can improve Diffusion images.</p>
<p>Either the baseline image was improved overall (<code>Prediction Normalization</code>), or we gained better image syntax and details (<code>T-Normalization</code> and <code>Full Normalization</code>).</p>
<p>Given that <code>T-Normalization</code> and <code>Full Normalization</code> completely changed the style of the baseline image, there is a lot to explore here. To start, there is likely a much better set of <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bsmall%7D"> values. Consider the baseline’s value of <img src="https://latex.codecogs.com/png.latex?G%20=%207.5">. This value is the standard across many Diffusion models and empirically produces good results. Meanwhile, our <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bsmall%7D%20=%200.15"> is only a starting point that has not been thoroughly tested.</p>
<p>In summary, it seems that <code>Prediction Normalization</code> could be an easy way to improve all Diffusion images. As for the others, they definitely have potential that should be explored further.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>This notebook was Part 2 in a series on dynamic Classifier-free Guidance.</p>
<p>We showed that normalizing the guidance has a big impact on the generated images. We found that <code>Prediction Normalization</code> has the potential to improve any Diffusion image.</p>
<p>Now, after Parts 1 and 2, we have a good idea of the guidance schedules and normalizations that might improve generated images.</p>
<p>In Part 3, we will combine schedules with normalizations to see if their gains compound.</p>


</section>

 ]]></description>
  <category>diffusion</category>
  <category>classifier-free guidance</category>
  <category>deep learning</category>
  <guid>https://enzokro.dev/blog/posts/2022-11-21-guidance-expts-3/index.html</guid>
  <pubDate>Tue, 22 Nov 2022 00:00:00 GMT</pubDate>
  <media:content url="https://enzokro.dev/blog/posts/2022-11-21-guidance-expts-3/better_horse_3.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>Libraries for dynamic Classifier-free Guidance</title>
  <dc:creator>enzokro</dc:creator>
  <link>https://enzokro.dev/blog/posts/2022-11-20-minimal-diffusion/index.html</link>
  <description><![CDATA[ 



<blockquote class="blockquote">
<p>Introducing two helper libraries to run dynamic Classifier-free Guidance.</p>
</blockquote>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>This post is a quick overview of two libraries:</p>
<ul>
<li><code>cf_guidance</code></li>
<li><code>min_diffusion</code></li>
</ul>
<p>These libraries were developed as part of a <a href="https://enzokro.dev/blog/posts/2022-11-21-guidance-expts-2/">series</a> on dynamic Classifier-free Guidance (CFG).</p>
<p>Dynamic CFG means that the guidance parameters change during the diffusion process. Specifically:</p>
<ul>
<li>The predictions are normalized by their vector norms.<br>
</li>
<li>The guidance scalar <img src="https://latex.codecogs.com/png.latex?G">, also called <img src="https://latex.codecogs.com/png.latex?%5Cgamma">, follows a schedule.</li>
</ul>
<section id="motivation" class="level2">
<h2 class="anchored" data-anchor-id="motivation">Motivation</h2>
<p>The initial experiments had a lot of boilerplate and repeated code.</p>
<p>For example, the same code was used in multiple notebooks to load Stable Diffusion models. The code for guidance schedules and normalizations was also repeated across notebooks.</p>
<p>That meant that each notebook needed a lot of overhead before it got to the actual experiments.</p>
<p>To make life a bit easier, and because we hope that these ideas are broadly usable, this repeated code was moved to two libraries:</p>
<ul>
<li><code>min_diffusion</code></li>
<li><code>cf_guidance</code></li>
</ul>
<p>Now we can import these libraries and jump straight to the important part: running the guidance experiments.</p>
</section>
</section>
<section id="using-the-libraries" class="level1">
<h1>Using the libraries</h1>
<p>First we import a few setup libraries to plot the examples.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span></code></pre></div>
</div>
<p>Next we show how to use the two new helper libraries.</p>
<section id="the-min_diffusion-library" class="level2">
<h2 class="anchored" data-anchor-id="the-min_diffusion-library">The <code>min_diffusion</code> library</h2>
<p>In this section we generate an image using <code>min_diffsion</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;">from</span> min_diffusion.core <span class="im" style="color: #00769E;">import</span> MinimalDiffusion</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2022-11-22 15:42:08.507717: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0</code></pre>
</div>
</div>
<section id="loading-the-openjourney-model-from-prompt-hero" class="level3">
<h3 class="anchored" data-anchor-id="loading-the-openjourney-model-from-prompt-hero">Loading the <code>openjourney</code> model from Prompt Hero</h3>
<p>The following code load the <code>openjourney</code> Stable Diffusion model on the GPU, in <code>torch.float16</code> precision.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">model_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'prompthero/openjourney'</span></span>
<span id="cb4-2">device     <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'cuda'</span></span>
<span id="cb4-3">dtype      <span class="op" style="color: #5E5E5E;">=</span> torch.float16</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">pipeline <span class="op" style="color: #5E5E5E;">=</span> MinimalDiffusion(model_name, device, dtype)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">pipeline.load()<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Enabling default unet attention slicing.</code></pre>
</div>
</div>
</section>
<section id="generating-an-image" class="level3">
<h3 class="anchored" data-anchor-id="generating-an-image">Generating an image</h3>
<p>Next we use the familiar prompt to generate an image:</p>
<blockquote class="blockquote">
<p>“a photograph of an astronaut riding a horse”</p>
</blockquote>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The <code>openjourney</code> model was fine-tuned to create images in the style of <a href="https://mezha.media/en/2022/11/11/midjourney-v4-is-an-incredible-new-version-of-the-ai-image-generator/">Midjourney v4</a>.</p>
<p>To enable this fine-tuned style, we have to add the keyword <code>"mdjrny-v4"</code> at the start of the prompt.</p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;"># text prompt for image generations</span></span>
<span id="cb8-2">prompt <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"mdjrny-v4 style a photograph of an astronaut riding a horse"</span></span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="co" style="color: #5E5E5E;"># set the seed for reproducibility</span></span>
<span id="cb9-2">torch.manual_seed(<span class="dv" style="color: #AD0000;">2147483647</span>)<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;"># generate the image</span></span>
<span id="cb10-2">img <span class="op" style="color: #5E5E5E;">=</span> pipeline.generate(prompt)<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Using the default Classifier-free Guidance.</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ff57196b6ecc4964b96df4196a2becf8","version_major":2,"version_minor":0}
</script>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;"># display the generated image</span></span>
<span id="cb12-2">img</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-20-minimal-diffusion/index_files/figure-html/cell-11-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>That’s the entire process!</p>
<p>The main difference between <code>MinimalDiffusion</code> and the HuggingFace API is that now we can easily customize the image generation loop. This allows us to explore a wide range of dynamic Classifier-free Guidances.</p>
</section>
</section>
<section id="the-cf_guidance-library" class="level2">
<h2 class="anchored" data-anchor-id="the-cf_guidance-library">The <code>cf_guidance</code> library</h2>
<p>The sections below are based on the <a href="https://enzokro.github.io/guidance_transforms/"><code>cf_guidance</code> documentation</a>.</p>
<p>We create a few Cosine schedules and plug them into different Classifier-free Guidances.</p>
<p>The schedule parameter come from the <a href="https://enzokro.dev/blog/posts/2022-11-15-guidance-expts-1/">initial post</a> on dynamic Classifier-free Guidance.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="im" style="color: #00769E;">from</span> cf_guidance.schedules <span class="im" style="color: #00769E;">import</span> get_cos_sched</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="co" style="color: #5E5E5E;"># Parameters from the blog post</span></span>
<span id="cb14-2"><span class="co" style="color: #5E5E5E;"># https://enzokro.dev/blog/posts/2022-11-15-guidance-expts-1/</span></span>
<span id="cb14-3">max_val <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">7.5</span></span>
<span id="cb14-4">min_val <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.15</span></span>
<span id="cb14-5">num_steps <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">50</span></span>
<span id="cb14-6">num_warmup_steps <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">5</span></span>
<span id="cb14-7"></span>
<span id="cb14-8"><span class="co" style="color: #5E5E5E;"># 1) Baseline cosine schedule</span></span>
<span id="cb14-9">cos_params <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb14-10">    <span class="st" style="color: #20794D;">'max_val'</span>:           max_val,</span>
<span id="cb14-11">    <span class="st" style="color: #20794D;">'num_steps'</span>:         num_steps,</span>
<span id="cb14-12">    <span class="st" style="color: #20794D;">'min_val'</span>:           min_val,</span>
<span id="cb14-13">    <span class="st" style="color: #20794D;">'num_warmup_steps'</span>:  <span class="dv" style="color: #AD0000;">0</span>,</span>
<span id="cb14-14">}</span>
<span id="cb14-15"></span>
<span id="cb14-16"><span class="co" style="color: #5E5E5E;"># 2) Cosine schedule with warmup </span></span>
<span id="cb14-17">warmup_cos_params <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb14-18">    <span class="st" style="color: #20794D;">'max_val'</span>:           max_val,</span>
<span id="cb14-19">    <span class="st" style="color: #20794D;">'num_steps'</span>:         num_steps,</span>
<span id="cb14-20">    <span class="st" style="color: #20794D;">'min_val'</span>:           min_val,</span>
<span id="cb14-21">    <span class="st" style="color: #20794D;">'warmup_init_val'</span>:   min_val <span class="op" style="color: #5E5E5E;">+</span> <span class="fl" style="color: #AD0000;">1.</span>, <span class="co" style="color: #5E5E5E;"># to show we can offset the warmup relative to min</span></span>
<span id="cb14-22">    <span class="st" style="color: #20794D;">'num_warmup_steps'</span>:  num_warmup_steps,</span>
<span id="cb14-23">}</span>
<span id="cb14-24"></span>
<span id="cb14-25"><span class="co" style="color: #5E5E5E;"># create the schedules</span></span>
<span id="cb14-26">cos_g <span class="op" style="color: #5E5E5E;">=</span> get_cos_sched(<span class="op" style="color: #5E5E5E;">**</span>cos_params)</span>
<span id="cb14-27">warmup_g <span class="op" style="color: #5E5E5E;">=</span> get_cos_sched(<span class="op" style="color: #5E5E5E;">**</span>warmup_cos_params)</span></code></pre></div>
</div>
<p>Let’s plot these cosine schedules to see what they look like.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="co" style="color: #5E5E5E;"># plot the schedules</span></span>
<span id="cb15-2">plt.plot(cos_g)</span>
<span id="cb15-3">plt.xlabel(<span class="st" style="color: #20794D;">'Diffusion Timesteps'</span>)</span>
<span id="cb15-4">plt.ylabel(<span class="st" style="color: #20794D;">'$G$ Guidance Parameter'</span>)</span>
<span id="cb15-5">plt.title(<span class="st" style="color: #20794D;">'Cosine Schedule'</span>)<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-20-minimal-diffusion/index_files/figure-html/cell-14-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">plt.plot(warmup_g)</span>
<span id="cb16-2">plt.xlabel(<span class="st" style="color: #20794D;">'Diffusion Timesteps'</span>)</span>
<span id="cb16-3">plt.ylabel(<span class="st" style="color: #20794D;">'$G$ Guidance Parameter'</span>)</span>
<span id="cb16-4">plt.title(<span class="st" style="color: #20794D;">'Warmup Cosine Schedule'</span>)<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-20-minimal-diffusion/index_files/figure-html/cell-15-output-1.png" class="img-fluid"></p>
</div>
</div>
<section id="creating-guidance-normalizers" class="level3">
<h3 class="anchored" data-anchor-id="creating-guidance-normalizers">Creating Guidance Normalizers</h3>
<p>Now we can use these schedules during Classifier-free Guidance. The Guidance Transform class, <code>GuidanceTfm</code>, makes this possible.</p>
<p>Guidance transforms take one initialization parameter: <code>schedules</code>. This is a map from parameter names to an array-like, indexable sequence of values.<br>
For a given parameter <code>name</code> at diffusion timestep <code>idx</code>, the value of <code>schedules[name][idx]</code> should be the parameter’s scheduled value at the given timestep.</p>
<p>In this case we call the guidance parameter <img src="https://latex.codecogs.com/png.latex?G"> as a lowercase <img src="https://latex.codecogs.com/png.latex?g">.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="im" style="color: #00769E;">from</span> cf_guidance.transforms <span class="im" style="color: #00769E;">import</span> GuidanceTfm, BaseNormGuidance</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="co" style="color: #5E5E5E;"># create the `schedules` parameter</span></span>
<span id="cb18-2">example_schedules <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'g'</span>: cos_g}</span>
<span id="cb18-3"></span>
<span id="cb18-4"><span class="co" style="color: #5E5E5E;"># Create a Guidance with cosine schedule.</span></span>
<span id="cb18-5">guidance <span class="op" style="color: #5E5E5E;">=</span> GuidanceTfm(example_schedules)</span>
<span id="cb18-6"></span>
<span id="cb18-7"><span class="co" style="color: #5E5E5E;"># Normalized Guidance with a cosine schedule.</span></span>
<span id="cb18-8">norm_guidance <span class="op" style="color: #5E5E5E;">=</span> BaseNormGuidance(example_schedules)</span></code></pre></div>
</div>
</section>
<section id="using-the-transforms-in-a-diffusion-pipeline" class="level3">
<h3 class="anchored" data-anchor-id="using-the-transforms-in-a-diffusion-pipeline">Using the transforms in a Diffusion pipeline</h3>
<p>The following snippet shows where and how the Guidance Transforms are used in a diffusion loop.</p>
<p>We use the <code>norm_guidance</code> example class created above. Specifically, we call <code>norm_guidance</code> with the following arguments:</p>
<ul>
<li>The unconditioned noise predictions.<br>
</li>
<li>The conditional noise predictions.<br>
</li>
<li>The index of the current timestep.</li>
</ul>
<p>The code is borrowed from HuggingFace’s <a href="https://github.com/nateraw/stable-diffusion-videos/blob/main/stable_diffusion_videos/stable_diffusion_pipeline.py#L448">official <code>StableDiffusionPipeline</code></a> to show where <code>norm_guidance</code> should go.<br>
This seems like a good starting point, since many scripts and functions are based on this HuggingFace setup.</p>
<div class="sourceCode" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">    <span class="co" style="color: #5E5E5E;"># inside of `StableDiffusionPipeline`</span></span>
<span id="cb19-2">    </span>
<span id="cb19-3">    <span class="cf" style="color: #003B4F;">for</span> i, t <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(<span class="va" style="color: #111111;">self</span>.progress_bar(timesteps_tensor)):</span>
<span id="cb19-4">        <span class="co" style="color: #5E5E5E;"># expand the latents if we are doing classifier free guidance</span></span>
<span id="cb19-5">        latent_model_input <span class="op" style="color: #5E5E5E;">=</span> torch.cat([latents] <span class="op" style="color: #5E5E5E;">*</span> <span class="dv" style="color: #AD0000;">2</span>) <span class="cf" style="color: #003B4F;">if</span> do_classifier_free_guidance <span class="cf" style="color: #003B4F;">else</span> latents</span>
<span id="cb19-6">        latent_model_input <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.scheduler.scale_model_input(latent_model_input, t)</span>
<span id="cb19-7"></span>
<span id="cb19-8">        <span class="co" style="color: #5E5E5E;"># predict the noise residual</span></span>
<span id="cb19-9">        noise_pred <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.unet(latent_model_input, t, encoder_hidden_states<span class="op" style="color: #5E5E5E;">=</span>text_embeddings).sample</span>
<span id="cb19-10"></span>
<span id="cb19-11">        <span class="co" style="color: #5E5E5E;"># </span><span class="al" style="color: #AD0000;">NOTE</span><span class="co" style="color: #5E5E5E;">: our transforms go here:</span></span>
<span id="cb19-12">        <span class="co" style="color: #5E5E5E;">###############################</span></span>
<span id="cb19-13">        <span class="cf" style="color: #003B4F;">if</span> do_classifier_free_guidance:</span>
<span id="cb19-14">            noise_pred_uncond, noise_pred_text <span class="op" style="color: #5E5E5E;">=</span> noise_pred.chunk(<span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb19-15"></span>
<span id="cb19-16">            <span class="co" style="color: #5E5E5E;">## OLD UPADTE</span></span>
<span id="cb19-17">            <span class="co" style="color: #5E5E5E;">#noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)</span></span>
<span id="cb19-18"></span>
<span id="cb19-19">            <span class="co" style="color: #5E5E5E;"># NEW cf_guidance UPDATE</span></span>
<span id="cb19-20">            noise_pred <span class="op" style="color: #5E5E5E;">=</span> norm_guidance(noise_pred_uncond, noise_pred_text, i)</span></code></pre></div>
</section>
<section id="creating-more-complex-schedules" class="level3">
<h3 class="anchored" data-anchor-id="creating-more-complex-schedules">Creating more complex schedules</h3>
<p>Our cosine scheduler is based on a combination of the schedulers in <a href="https://github.com/rwightman/pytorch-image-models/blob/main/timm/scheduler/cosine_lr.py">timm</a> and <a href="https://github.com/huggingface/transformers/blob/v4.24.0/src/transformers/optimization.py#L104">HuggingFace</a>.</p>
<p>It has a variety of parameters to support many schedule combinations as shown below.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="co" style="color: #5E5E5E;"># cosine schedule with a full cycle</span></span>
<span id="cb20-2">full_cycle <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb20-3">    <span class="st" style="color: #20794D;">'max_val'</span>:           max_val,</span>
<span id="cb20-4">    <span class="st" style="color: #20794D;">'num_steps'</span>:         num_steps,</span>
<span id="cb20-5">    <span class="st" style="color: #20794D;">'min_val'</span>:           min_val,</span>
<span id="cb20-6">    <span class="st" style="color: #20794D;">'num_cycles'</span>:        <span class="dv" style="color: #AD0000;">1</span>,</span>
<span id="cb20-7">    <span class="st" style="color: #20794D;">'num_warmup_steps'</span>:  <span class="dv" style="color: #AD0000;">0</span>,</span>
<span id="cb20-8">}</span>
<span id="cb20-9"></span>
<span id="cb20-10"><span class="co" style="color: #5E5E5E;"># cosine schedule with k-decay</span></span>
<span id="cb20-11">k_decay_cos <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb20-12">    <span class="st" style="color: #20794D;">'max_val'</span>:           max_val,</span>
<span id="cb20-13">    <span class="st" style="color: #20794D;">'num_steps'</span>:         num_steps,</span>
<span id="cb20-14">    <span class="st" style="color: #20794D;">'min_val'</span>:           min_val,</span>
<span id="cb20-15">    <span class="st" style="color: #20794D;">'num_cycles'</span>:        <span class="fl" style="color: #AD0000;">1.5</span>,</span>
<span id="cb20-16">    <span class="st" style="color: #20794D;">'k_decay'</span>:           <span class="fl" style="color: #AD0000;">0.7</span>,</span>
<span id="cb20-17">    <span class="st" style="color: #20794D;">'warmup_init_val'</span>:   min_val <span class="op" style="color: #5E5E5E;">+</span> <span class="fl" style="color: #AD0000;">1.</span>, <span class="co" style="color: #5E5E5E;"># to show we can offset the warmup value</span></span>
<span id="cb20-18">    <span class="st" style="color: #20794D;">'num_warmup_steps'</span>:  num_warmup_steps,</span>
<span id="cb20-19">}</span>
<span id="cb20-20"></span>
<span id="cb20-21"><span class="co" style="color: #5E5E5E;"># create the schedules</span></span>
<span id="cb20-22">full_cycle_sched <span class="op" style="color: #5E5E5E;">=</span> get_cos_sched(<span class="op" style="color: #5E5E5E;">**</span>full_cycle)</span>
<span id="cb20-23">k_decay_sched <span class="op" style="color: #5E5E5E;">=</span> get_cos_sched(<span class="op" style="color: #5E5E5E;">**</span>k_decay_cos)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1">plt.plot(full_cycle_sched)</span>
<span id="cb21-2">plt.xlabel(<span class="st" style="color: #20794D;">'Diffusion Timesteps'</span>)</span>
<span id="cb21-3">plt.ylabel(<span class="st" style="color: #20794D;">'$G$ Guidance Parameter'</span>)</span>
<span id="cb21-4">plt.title(<span class="st" style="color: #20794D;">'Cosine With a Full Cycle'</span>)<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-20-minimal-diffusion/index_files/figure-html/cell-19-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">plt.plot(k_decay_sched)</span>
<span id="cb22-2">plt.xlabel(<span class="st" style="color: #20794D;">'Diffusion Timesteps'</span>)</span>
<span id="cb22-3">plt.ylabel(<span class="st" style="color: #20794D;">'$G$ Guidance Parameter'</span>)</span>
<span id="cb22-4">plt.title(<span class="st" style="color: #20794D;">'Cosine with Offset-Warmup, 1.5 Cycles, and K-decay'</span>)<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-20-minimal-diffusion/index_files/figure-html/cell-20-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>This notebook was a quick introduction to two libraries:</p>
<ul>
<li><code>min_diffusion</code><br>
</li>
<li><code>cf_guidance</code></li>
</ul>
<p><code>min_diffusion</code> makes it easier to load Stable Diffusion models.<br>
<code>cf_guidance</code> makes it easier to create schedules and normalizations for dynamic Classifier-free Guidance.</p>
<p>The next post in this series will use the libraries to keep exploring the effects of dynamically changing the Classifier-free Guidance.</p>


</section>

 ]]></description>
  <category>diffusion</category>
  <category>deep learning</category>
  <guid>https://enzokro.dev/blog/posts/2022-11-20-minimal-diffusion/index.html</guid>
  <pubDate>Mon, 21 Nov 2022 00:00:00 GMT</pubDate>
  <media:content url="https://enzokro.dev/blog/posts/2022-11-20-minimal-diffusion/dynam_cfg.png" medium="image" type="image/png" height="160" width="144"/>
</item>
<item>
  <title>Dynamic Classifier-free Guidance Pt. 1</title>
  <dc:creator>enzokro</dc:creator>
  <link>https://enzokro.dev/blog/posts/2022-11-20-guidance-expts-2/index.html</link>
  <description><![CDATA[ 



<blockquote class="blockquote">
<p>Experiments with cosine schedules for Classifier-free Guidance.</p>
</blockquote>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>This notebook continues <a href="https://enzokro.dev/blog/posts/2022-11-15-guidance-expts-1/">previous experiments</a> on dynamically changing the Classifier-free Guidance parameter.</p>
<p>To recap the earlier results: changing the guidance parameter <img src="https://latex.codecogs.com/png.latex?G"> improved the quality of generated images. More specifically:</p>
<ul>
<li><strong>Normalizing</strong> the guidance helped the image’s syntax.<br>
</li>
<li><strong>Scheduling</strong> the guidance improved the image details.</li>
</ul>
<p>The combination of the two often makes for even better generations.</p>
<p>However, there is an open question about which dynamic changes are the best. The goal of this series is to, ideally, find changes that universally improve the quality of Diffusion images.</p>
</section>
<section id="the-cf_guidance-library" class="level1">
<h1>The <code>cf_guidance</code> library</h1>
<p>Guidance schedules and normalizers are now available in the <a href="https://pypi.org/project/cf-guidance/">cf_guidance</a> library!</p>
<p>We will use this library to generate images for a sweep of cosine schedules.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="co" style="color: #5E5E5E;"># helpers to create cosine schedules</span></span>
<span id="cb1-2"><span class="im" style="color: #00769E;">from</span> cf_guidance.schedules  <span class="im" style="color: #00769E;">import</span> get_cos_sched</span>
<span id="cb1-3"></span>
<span id="cb1-4"><span class="co" style="color: #5E5E5E;"># normalizations for classifier-free guidance</span></span>
<span id="cb1-5"><span class="im" style="color: #00769E;">from</span> cf_guidance.transforms <span class="im" style="color: #00769E;">import</span> GuidanceTfm, BaseNormGuidance, TNormGuidance</span></code></pre></div>
</div>
</section>
<section id="experiment-setup" class="level1">
<h1>Experiment Setup</h1>
<p>The following section setups up the imports and helpers we need for the runs.</p>
<p>First we import the needed python modules.</p>
<section id="imports" class="level2">
<h2 class="anchored" data-anchor-id="imports">Imports</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;">import</span> os</span>
<span id="cb2-2"><span class="im" style="color: #00769E;">import</span> math</span>
<span id="cb2-3"><span class="im" style="color: #00769E;">import</span> random</span>
<span id="cb2-4"><span class="im" style="color: #00769E;">import</span> warnings</span>
<span id="cb2-5"><span class="im" style="color: #00769E;">from</span> PIL <span class="im" style="color: #00769E;">import</span> Image</span>
<span id="cb2-6"><span class="im" style="color: #00769E;">from</span> typing <span class="im" style="color: #00769E;">import</span> List</span>
<span id="cb2-7"><span class="im" style="color: #00769E;">from</span> pathlib <span class="im" style="color: #00769E;">import</span> Path</span>
<span id="cb2-8"><span class="im" style="color: #00769E;">from</span> types <span class="im" style="color: #00769E;">import</span> SimpleNamespace</span>
<span id="cb2-9"><span class="im" style="color: #00769E;">from</span> fastcore.<span class="bu" style="color: null;">all</span> <span class="im" style="color: #00769E;">import</span> L</span>
<span id="cb2-10"></span>
<span id="cb2-11"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb2-12"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb2-13"><span class="im" style="color: #00769E;">from</span> textwrap <span class="im" style="color: #00769E;">import</span> wrap</span>
<span id="cb2-14"><span class="im" style="color: #00769E;">from</span> tqdm.auto <span class="im" style="color: #00769E;">import</span> tqdm </span>
<span id="cb2-15"></span>
<span id="cb2-16"><span class="co" style="color: #5E5E5E;"># imports for diffusion models</span></span>
<span id="cb2-17"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb2-18"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> logging</span>
<span id="cb2-19"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> CLIPTextModel, CLIPTokenizer</span>
<span id="cb2-20"><span class="im" style="color: #00769E;">from</span> huggingface_hub <span class="im" style="color: #00769E;">import</span> notebook_login</span>
<span id="cb2-21"><span class="im" style="color: #00769E;">from</span> diffusers <span class="im" style="color: #00769E;">import</span> StableDiffusionPipeline</span>
<span id="cb2-22"><span class="im" style="color: #00769E;">from</span> diffusers <span class="im" style="color: #00769E;">import</span> AutoencoderKL, UNet2DConditionModel</span>
<span id="cb2-23"><span class="im" style="color: #00769E;">from</span> diffusers <span class="im" style="color: #00769E;">import</span> LMSDiscreteScheduler</span>
<span id="cb2-24"></span>
<span id="cb2-25"><span class="co" style="color: #5E5E5E;"># for clean outputs</span></span>
<span id="cb2-26">warnings.filterwarnings(<span class="st" style="color: #20794D;">"ignore"</span>)</span>
<span id="cb2-27">logging.set_verbosity_error()</span>
<span id="cb2-28"></span>
<span id="cb2-29"><span class="co" style="color: #5E5E5E;"># set the hardware device</span></span>
<span id="cb2-30">device <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"cuda"</span> <span class="cf" style="color: #003B4F;">if</span> torch.cuda.is_available() <span class="cf" style="color: #003B4F;">else</span> <span class="st" style="color: #20794D;">"mps"</span> <span class="cf" style="color: #003B4F;">if</span> torch.has_mps <span class="cf" style="color: #003B4F;">else</span> <span class="st" style="color: #20794D;">"cpu"</span></span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2022-11-21 19:06:22.967865: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0</code></pre>
</div>
</div>
</section>
<section id="helper-functions" class="level2">
<h2 class="anchored" data-anchor-id="helper-functions">Helper functions</h2>
<p>The functions below help with:</p>
<ol type="1">
<li>Generating text embeddings from a given prompt.<br>
</li>
<li>Converting Diffusion latents to a PIL image.<br>
</li>
<li>Plotting the images to visualize results.</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="kw" style="color: #003B4F;">def</span> text_embeddings(prompts, maxlen<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb4-2">    <span class="co" style="color: #5E5E5E;">"Extracts text embeddings from the given `prompts`."</span></span>
<span id="cb4-3">    maxlen <span class="op" style="color: #5E5E5E;">=</span> maxlen <span class="kw" style="color: #003B4F;">or</span> tokenizer.model_max_length</span>
<span id="cb4-4">    inp <span class="op" style="color: #5E5E5E;">=</span> tokenizer(prompts, padding<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"max_length"</span>, max_length<span class="op" style="color: #5E5E5E;">=</span>maxlen, truncation<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, return_tensors<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"pt"</span>)</span>
<span id="cb4-5">    <span class="cf" style="color: #003B4F;">return</span> text_encoder(inp.input_ids.to(device))[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb4-6"></span>
<span id="cb4-7"></span>
<span id="cb4-8"><span class="kw" style="color: #003B4F;">def</span> image_from_latents(latents):</span>
<span id="cb4-9">    <span class="co" style="color: #5E5E5E;">"Scales diffusion `latents` and turns them into a PIL Image."</span></span>
<span id="cb4-10">    </span>
<span id="cb4-11">    <span class="co" style="color: #5E5E5E;"># scale and decode the latents</span></span>
<span id="cb4-12">    latents <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span> <span class="op" style="color: #5E5E5E;">/</span> <span class="fl" style="color: #AD0000;">0.18215</span> <span class="op" style="color: #5E5E5E;">*</span> latents</span>
<span id="cb4-13">    <span class="cf" style="color: #003B4F;">with</span> torch.no_grad():</span>
<span id="cb4-14">        data <span class="op" style="color: #5E5E5E;">=</span> vae.decode(latents).sample[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb4-15"></span>
<span id="cb4-16">    <span class="co" style="color: #5E5E5E;"># Create PIL image</span></span>
<span id="cb4-17">    data <span class="op" style="color: #5E5E5E;">=</span> (data <span class="op" style="color: #5E5E5E;">/</span> <span class="dv" style="color: #AD0000;">2</span> <span class="op" style="color: #5E5E5E;">+</span> <span class="fl" style="color: #AD0000;">0.5</span>).clamp(<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb4-18">    data <span class="op" style="color: #5E5E5E;">=</span> data.cpu().permute(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">0</span>).<span class="bu" style="color: null;">float</span>().numpy()</span>
<span id="cb4-19">    data <span class="op" style="color: #5E5E5E;">=</span> (data <span class="op" style="color: #5E5E5E;">*</span> <span class="dv" style="color: #AD0000;">255</span>).<span class="bu" style="color: null;">round</span>().astype(<span class="st" style="color: #20794D;">"uint8"</span>)</span>
<span id="cb4-20">    image <span class="op" style="color: #5E5E5E;">=</span> Image.fromarray(data)</span>
<span id="cb4-21">    <span class="cf" style="color: #003B4F;">return</span> image</span>
<span id="cb4-22">    </span>
<span id="cb4-23">    </span>
<span id="cb4-24"><span class="kw" style="color: #003B4F;">def</span> show_image(image, scale<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.5</span>):</span>
<span id="cb4-25">    <span class="co" style="color: #5E5E5E;">"Displays the given `image` resized based on `scale`."</span></span>
<span id="cb4-26">    img <span class="op" style="color: #5E5E5E;">=</span> image.resize(((<span class="bu" style="color: null;">int</span>)(image.width <span class="op" style="color: #5E5E5E;">*</span> scale), (<span class="bu" style="color: null;">int</span>)(image.height <span class="op" style="color: #5E5E5E;">*</span> scale)))</span>
<span id="cb4-27">    display(img)</span>
<span id="cb4-28">    <span class="cf" style="color: #003B4F;">return</span> img</span>
<span id="cb4-29"></span>
<span id="cb4-30"></span>
<span id="cb4-31"><span class="kw" style="color: #003B4F;">def</span> image_grid(images, rows <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span>, width<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">256</span>, height<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">256</span>, title<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb4-32">    <span class="co" style="color: #5E5E5E;">"Display an array of images in a grid with the given number of `rows`"</span></span>
<span id="cb4-33">    count <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">len</span>(images)</span>
<span id="cb4-34">    cols <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">int</span>(count <span class="op" style="color: #5E5E5E;">/</span> rows)</span>
<span id="cb4-35">    <span class="cf" style="color: #003B4F;">if</span> cols <span class="op" style="color: #5E5E5E;">*</span> rows <span class="op" style="color: #5E5E5E;">&lt;</span> count:</span>
<span id="cb4-36">        rows <span class="op" style="color: #5E5E5E;">+=</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb4-37">    <span class="co" style="color: #5E5E5E;"># Calculate fig size based on individual image sizes    </span></span>
<span id="cb4-38">    px <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">/</span>plt.rcParams[<span class="st" style="color: #20794D;">'figure.dpi'</span>]</span>
<span id="cb4-39">    w <span class="op" style="color: #5E5E5E;">=</span> cols <span class="op" style="color: #5E5E5E;">*</span> width <span class="op" style="color: #5E5E5E;">*</span> px</span>
<span id="cb4-40">    <span class="co" style="color: #5E5E5E;"># Add some extra space for the caption/title since that can wrap</span></span>
<span id="cb4-41">    h <span class="op" style="color: #5E5E5E;">=</span> (rows <span class="op" style="color: #5E5E5E;">*</span> height <span class="op" style="color: #5E5E5E;">*</span> px) <span class="op" style="color: #5E5E5E;">+</span> (rows <span class="op" style="color: #5E5E5E;">*</span> <span class="dv" style="color: #AD0000;">30</span> <span class="op" style="color: #5E5E5E;">*</span> px)</span>
<span id="cb4-42">    fig, axes <span class="op" style="color: #5E5E5E;">=</span> plt.subplots(rows, cols, figsize<span class="op" style="color: #5E5E5E;">=</span>(w, h))</span>
<span id="cb4-43">    <span class="cf" style="color: #003B4F;">for</span> y <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(rows):</span>
<span id="cb4-44">        <span class="cf" style="color: #003B4F;">for</span> x <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(cols):</span>
<span id="cb4-45">            index <span class="op" style="color: #5E5E5E;">=</span> y<span class="op" style="color: #5E5E5E;">*</span>cols <span class="op" style="color: #5E5E5E;">+</span> x</span>
<span id="cb4-46">            ref <span class="op" style="color: #5E5E5E;">=</span> axes[x] <span class="cf" style="color: #003B4F;">if</span> rows <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">1</span> <span class="cf" style="color: #003B4F;">else</span> axes[y] <span class="cf" style="color: #003B4F;">if</span> cols <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">1</span> <span class="cf" style="color: #003B4F;">else</span> axes[y, x]</span>
<span id="cb4-47">            ref.axis(<span class="st" style="color: #20794D;">'off'</span>)</span>
<span id="cb4-48">            <span class="cf" style="color: #003B4F;">if</span> index <span class="op" style="color: #5E5E5E;">&gt;</span> count <span class="op" style="color: #5E5E5E;">-</span> <span class="dv" style="color: #AD0000;">1</span>:</span>
<span id="cb4-49">                <span class="cf" style="color: #003B4F;">continue</span></span>
<span id="cb4-50">            img <span class="op" style="color: #5E5E5E;">=</span> images[index]</span>
<span id="cb4-51">            txt <span class="op" style="color: #5E5E5E;">=</span> <span class="ss" style="color: #20794D;">f'Frame: </span><span class="sc" style="color: #5E5E5E;">{</span>index<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb4-52">            <span class="cf" style="color: #003B4F;">if</span> title <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb4-53">                <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">isinstance</span>(title, <span class="bu" style="color: null;">str</span>):</span>
<span id="cb4-54">                    txt <span class="op" style="color: #5E5E5E;">=</span> <span class="ss" style="color: #20794D;">f'</span><span class="sc" style="color: #5E5E5E;">{</span>title<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">: </span><span class="sc" style="color: #5E5E5E;">{</span>index<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb4-55">                <span class="cf" style="color: #003B4F;">elif</span> <span class="bu" style="color: null;">isinstance</span>(title, List):</span>
<span id="cb4-56">                    txt <span class="op" style="color: #5E5E5E;">=</span> title[index]</span>
<span id="cb4-57">            <span class="co" style="color: #5E5E5E;"># small change for bigger, more visible titles</span></span>
<span id="cb4-58">            txt <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">'</span>.join(wrap(txt, width<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">70</span>))</span>
<span id="cb4-59">            ref.set_title(txt, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'x-large'</span>)</span>
<span id="cb4-60">            ref.imshow(img)</span>
<span id="cb4-61">            ref.axis(<span class="st" style="color: #20794D;">'off'</span>)</span>
<span id="cb4-62">            </span></code></pre></div>
</div>
</section>
<section id="loading-a-diffusion-pipeline" class="level2">
<h2 class="anchored" data-anchor-id="loading-a-diffusion-pipeline">Loading a Diffusion pipeline</h2>
<p>We need to dynamically change the diffusion guidance parameter <img src="https://latex.codecogs.com/png.latex?G">.</p>
<p>That means we need more control than what is available in the high-level HuggingFace APIs. To achieve this control, we load each piece of a Diffusion pipeline separately. Then, we can write our own image generation loop with full control over <img src="https://latex.codecogs.com/png.latex?G">.</p>
<p>The <code>get_sd_pieces</code> function loads and returns the separate components of a Stable Diffusion pipeline.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="kw" style="color: #003B4F;">def</span> get_sd_pieces(model_name, dtype<span class="op" style="color: #5E5E5E;">=</span>torch.float32, better_vae<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'ema'</span>):</span>
<span id="cb5-2">    <span class="co" style="color: #5E5E5E;">"Loads and returns the individual pieces in a Diffusion pipeline."</span></span>
<span id="cb5-3">    </span>
<span id="cb5-4">    <span class="co" style="color: #5E5E5E;"># create the tokenizer and text encoder</span></span>
<span id="cb5-5">    tokenizer <span class="op" style="color: #5E5E5E;">=</span> CLIPTokenizer.from_pretrained(</span>
<span id="cb5-6">        model_name,</span>
<span id="cb5-7">        subfolder<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"tokenizer"</span>,</span>
<span id="cb5-8">        torch_dtype<span class="op" style="color: #5E5E5E;">=</span>dtype)</span>
<span id="cb5-9">    text_encoder <span class="op" style="color: #5E5E5E;">=</span> CLIPTextModel.from_pretrained(</span>
<span id="cb5-10">        model_name,</span>
<span id="cb5-11">        subfolder<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"text_encoder"</span>,</span>
<span id="cb5-12">        torch_dtype<span class="op" style="color: #5E5E5E;">=</span>dtype).to(device)</span>
<span id="cb5-13"></span>
<span id="cb5-14">    <span class="co" style="color: #5E5E5E;"># we are using a VAE from stability that was trained for longer than the baseline </span></span>
<span id="cb5-15">    <span class="cf" style="color: #003B4F;">if</span> better_vae:</span>
<span id="cb5-16">        <span class="cf" style="color: #003B4F;">assert</span> better_vae <span class="kw" style="color: #003B4F;">in</span> (<span class="st" style="color: #20794D;">'ema'</span>, <span class="st" style="color: #20794D;">'mse'</span>)</span>
<span id="cb5-17">        vae <span class="op" style="color: #5E5E5E;">=</span> AutoencoderKL.from_pretrained(<span class="ss" style="color: #20794D;">f"stabilityai/sd-vae-ft-</span><span class="sc" style="color: #5E5E5E;">{</span>better_vae<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, torch_dtype<span class="op" style="color: #5E5E5E;">=</span>dtype).to(device)</span>
<span id="cb5-18">    <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb5-19">        vae <span class="op" style="color: #5E5E5E;">=</span> AutoencoderKL.from_pretrained(model_name, subfolder<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'vae'</span>, torch_dtype<span class="op" style="color: #5E5E5E;">=</span>dtype).to(device)</span>
<span id="cb5-20">    </span>
<span id="cb5-21">    <span class="co" style="color: #5E5E5E;"># build the unet</span></span>
<span id="cb5-22">    unet <span class="op" style="color: #5E5E5E;">=</span> UNet2DConditionModel.from_pretrained(</span>
<span id="cb5-23">        model_name,</span>
<span id="cb5-24">        subfolder<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"unet"</span>,</span>
<span id="cb5-25">        torch_dtype<span class="op" style="color: #5E5E5E;">=</span>dtype).to(device)</span>
<span id="cb5-26">    </span>
<span id="cb5-27">    <span class="co" style="color: #5E5E5E;"># enable unet attention slicing</span></span>
<span id="cb5-28">    slice_size <span class="op" style="color: #5E5E5E;">=</span> unet.config.attention_head_dim <span class="op" style="color: #5E5E5E;">//</span> <span class="dv" style="color: #AD0000;">2</span></span>
<span id="cb5-29">    unet.set_attention_slice(slice_size)</span>
<span id="cb5-30">        </span>
<span id="cb5-31">    <span class="co" style="color: #5E5E5E;"># build the scheduler</span></span>
<span id="cb5-32">    scheduler <span class="op" style="color: #5E5E5E;">=</span> LMSDiscreteScheduler.from_config(model_name, subfolder<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"scheduler"</span>)</span>
<span id="cb5-33">    </span>
<span id="cb5-34">    <span class="cf" style="color: #003B4F;">return</span> (</span>
<span id="cb5-35">        tokenizer,</span>
<span id="cb5-36">        text_encoder,</span>
<span id="cb5-37">        vae,</span>
<span id="cb5-38">        unet,</span>
<span id="cb5-39">        scheduler,</span>
<span id="cb5-40">    )</span></code></pre></div>
</div>
<section id="picking-a-model" class="level3">
<h3 class="anchored" data-anchor-id="picking-a-model">Picking a model</h3>
<p>These runs use the <code>openjourney</code> model from <a href="https://huggingface.co/prompthero/openjourney">Prompt Hero</a>.</p>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p><code>openjourney</code> was fine-tuned to create images in the style of <a href="https://mezha.media/en/2022/11/11/midjourney-v4-is-an-incredible-new-version-of-the-ai-image-generator/">Midjourney v4</a>.</p>
<p>To trigger this style, we need to add the special keyword <code>"mdjrny-v4"</code> at the front of an input text prompt.</p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="co" style="color: #5E5E5E;"># set the diffusion model</span></span>
<span id="cb6-2">model_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"prompthero/openjourney"</span></span>
<span id="cb6-3"></span>
<span id="cb6-4"><span class="co" style="color: #5E5E5E;"># other possible models</span></span>
<span id="cb6-5"><span class="co" style="color: #5E5E5E;"># model_name = "CompVis/stable-diffusion-v1-4"</span></span>
<span id="cb6-6"><span class="co" style="color: #5E5E5E;"># model_name = "runwayml/stable-diffusion-v1-5"</span></span></code></pre></div>
</div>
<p>Next we use the function <code>get_sd_pieces</code> to load this model. The pieces are loaded in <code>float16</code> precision.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="co" style="color: #5E5E5E;"># set the data type for the pipeline</span></span>
<span id="cb7-2">dtype <span class="op" style="color: #5E5E5E;">=</span> torch.float16</span>
<span id="cb7-3"></span>
<span id="cb7-4"><span class="co" style="color: #5E5E5E;"># load the individual diffusion pieces</span></span>
<span id="cb7-5">pieces <span class="op" style="color: #5E5E5E;">=</span> get_sd_pieces(model_name, dtype<span class="op" style="color: #5E5E5E;">=</span>dtype)</span>
<span id="cb7-6">(tokenizer, text_encoder, vae, unet, scheduler) <span class="op" style="color: #5E5E5E;">=</span> pieces</span></code></pre></div>
</div>
</section>
</section>
<section id="text-prompt-for-generations" class="level2">
<h2 class="anchored" data-anchor-id="text-prompt-for-generations">Text prompt for generations</h2>
<p>We use the same input text prompt from the previous notebook:</p>
<blockquote class="blockquote">
<p>“<em>a photograph of an astronaut riding a horse</em>”</p>
</blockquote>
<p>But, we add the special prefix keyword <code>"mdjrny-v4"</code> to create Midjourney-style images.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;"># input text prompt for diffusion models</span></span>
<span id="cb8-2">prompt <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"mdjrny-v4 style a photograph of an astronaut riding a horse"</span></span></code></pre></div>
</div>
</section>
<section id="generating-images" class="level2">
<h2 class="anchored" data-anchor-id="generating-images">Generating images</h2>
<p>The images will be generated over <img src="https://latex.codecogs.com/png.latex?50"> diffusion steps. They will have a height and width size of <code>512 x 512</code> pixels.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="co" style="color: #5E5E5E;"># the number of diffusion steps</span></span>
<span id="cb9-2">num_steps <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">50</span></span>
<span id="cb9-3"></span>
<span id="cb9-4"><span class="co" style="color: #5E5E5E;"># generated image dimensions</span></span>
<span id="cb9-5">width, height <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">512</span>, <span class="dv" style="color: #AD0000;">512</span></span></code></pre></div>
</div>
<section id="creating-a-fixed-starting-point-for-diffusion" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-fixed-starting-point-for-diffusion">Creating a fixed starting point for diffusion</h3>
<p>The code below creates an initial set of latent noise.</p>
<p>The idea is for every generation to start from this shared, fixed noise. That way we can be sure that only our guidance changes are having an effect on the output image.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;"># create the shared, initial latents</span></span>
<span id="cb10-2">seed <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1024</span></span>
<span id="cb10-3">torch.manual_seed(seed)</span>
<span id="cb10-4">init_latents <span class="op" style="color: #5E5E5E;">=</span> torch.randn((<span class="dv" style="color: #AD0000;">1</span>, unet.in_channels, height<span class="op" style="color: #5E5E5E;">//</span><span class="dv" style="color: #AD0000;">8</span>, width<span class="op" style="color: #5E5E5E;">//</span><span class="dv" style="color: #AD0000;">8</span>), dtype<span class="op" style="color: #5E5E5E;">=</span>unet.dtype, device<span class="op" style="color: #5E5E5E;">=</span>device)</span></code></pre></div>
</div>
</section>
<section id="image-generation-function" class="level3">
<h3 class="anchored" data-anchor-id="image-generation-function">Image generation function</h3>
<p>Below is the main image generation function: <code>generate</code>. It uses the Stable Diffusion components we loaded earlier.</p>
<p>Note that this function is almost identical to the <code>StableDiffusionPipeline</code> from HuggingFace. The main difference is plugging in our Guidance Transform instead of doing the default Classifier-free Guidance update.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="kw" style="color: #003B4F;">def</span> generate(prompt, guide_tfm<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>, width<span class="op" style="color: #5E5E5E;">=</span>width, height<span class="op" style="color: #5E5E5E;">=</span>height, steps<span class="op" style="color: #5E5E5E;">=</span>num_steps, <span class="op" style="color: #5E5E5E;">**</span>kwargs):</span>
<span id="cb11-2">    <span class="co" style="color: #5E5E5E;"># make sure we have a guidance transformation</span></span>
<span id="cb11-3">    <span class="cf" style="color: #003B4F;">assert</span> guide_tfm</span>
<span id="cb11-4">    </span>
<span id="cb11-5">    <span class="co" style="color: #5E5E5E;"># prepare the text embeddings</span></span>
<span id="cb11-6">    text <span class="op" style="color: #5E5E5E;">=</span> text_embeddings(prompt)</span>
<span id="cb11-7">    uncond <span class="op" style="color: #5E5E5E;">=</span> text_embeddings(<span class="st" style="color: #20794D;">''</span>)</span>
<span id="cb11-8">    emb <span class="op" style="color: #5E5E5E;">=</span> torch.cat([uncond, text]).<span class="bu" style="color: null;">type</span>(unet.dtype)</span>
<span id="cb11-9">    </span>
<span id="cb11-10">    <span class="co" style="color: #5E5E5E;"># start from the shared, initial latents</span></span>
<span id="cb11-11">    latents <span class="op" style="color: #5E5E5E;">=</span> torch.clone(init_latents)</span>
<span id="cb11-12">    scheduler.set_timesteps(steps)</span>
<span id="cb11-13">    latents <span class="op" style="color: #5E5E5E;">=</span> latents <span class="op" style="color: #5E5E5E;">*</span> scheduler.init_noise_sigma</span>
<span id="cb11-14">    </span>
<span id="cb11-15">    <span class="co" style="color: #5E5E5E;"># run the diffusion process</span></span>
<span id="cb11-16">    <span class="cf" style="color: #003B4F;">for</span> i,ts <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(tqdm(scheduler.timesteps)):</span>
<span id="cb11-17">        inp <span class="op" style="color: #5E5E5E;">=</span> scheduler.scale_model_input(torch.cat([latents] <span class="op" style="color: #5E5E5E;">*</span> <span class="dv" style="color: #AD0000;">2</span>), ts)</span>
<span id="cb11-18">        <span class="cf" style="color: #003B4F;">with</span> torch.no_grad(): </span>
<span id="cb11-19">            tf <span class="op" style="color: #5E5E5E;">=</span> ts</span>
<span id="cb11-20">            <span class="cf" style="color: #003B4F;">if</span> torch.has_mps:</span>
<span id="cb11-21">                tf <span class="op" style="color: #5E5E5E;">=</span> ts.<span class="bu" style="color: null;">type</span>(torch.float32)</span>
<span id="cb11-22">            u,t <span class="op" style="color: #5E5E5E;">=</span> unet(inp, tf, encoder_hidden_states<span class="op" style="color: #5E5E5E;">=</span>emb).sample.chunk(<span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb11-23">        </span>
<span id="cb11-24">        <span class="co" style="color: #5E5E5E;"># call the guidance transform</span></span>
<span id="cb11-25">        pred <span class="op" style="color: #5E5E5E;">=</span> guide_tfm(u, t, idx<span class="op" style="color: #5E5E5E;">=</span>i)</span>
<span id="cb11-26">        </span>
<span id="cb11-27">        <span class="co" style="color: #5E5E5E;"># update the latents</span></span>
<span id="cb11-28">        latents <span class="op" style="color: #5E5E5E;">=</span> scheduler.step(pred, ts, latents).prev_sample</span>
<span id="cb11-29">        </span>
<span id="cb11-30">    <span class="co" style="color: #5E5E5E;"># decode and return the final latents</span></span>
<span id="cb11-31">    image <span class="op" style="color: #5E5E5E;">=</span> image_from_latents(latents)</span>
<span id="cb11-32">    <span class="cf" style="color: #003B4F;">return</span> image    </span></code></pre></div>
</div>
</section>
</section>
</section>
<section id="function-to-run-the-experiments" class="level1">
<h1>Function to run the experiments</h1>
<p>The <code>run</code> function below generates images for a given prompt.</p>
<p>It takes an argument <code>guide_tfm</code> for the specific <code>GuidanceTfm</code> class that will guide the outputs.<br>
The <code>schedules</code> argument has the set of schedules to sweep for <img src="https://latex.codecogs.com/png.latex?G">.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="kw" style="color: #003B4F;">def</span> run(prompt, schedules, guide_tfm<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>, show_each<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, test_run<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>):</span>
<span id="cb12-2">    <span class="co" style="color: #5E5E5E;"># store generated images and their title (the experiment name)</span></span>
<span id="cb12-3">    images, titles <span class="op" style="color: #5E5E5E;">=</span> [], []</span>
<span id="cb12-4">    </span>
<span id="cb12-5">    <span class="cf" style="color: #003B4F;">assert</span> guide_tfm</span>
<span id="cb12-6">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Using Guidance Transform: </span><span class="sc" style="color: #5E5E5E;">{</span>guide_tfm<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb12-7">    </span>
<span id="cb12-8">    <span class="cf" style="color: #003B4F;">if</span> test_run:</span>
<span id="cb12-9">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Running a single schedule for testing.'</span>)</span>
<span id="cb12-10">        schedules <span class="op" style="color: #5E5E5E;">=</span> schedules[:<span class="dv" style="color: #AD0000;">1</span>]</span>
<span id="cb12-11">        </span>
<span id="cb12-12">    ns <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">len</span>(schedules)</span>
<span id="cb12-13">    <span class="co" style="color: #5E5E5E;"># run all schedule experiments</span></span>
<span id="cb12-14">    <span class="cf" style="color: #003B4F;">for</span> i,s <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(schedules):</span>
<span id="cb12-15">        </span>
<span id="cb12-16">        <span class="co" style="color: #5E5E5E;"># parse out the title for the current run</span></span>
<span id="cb12-17">        cur_title  <span class="op" style="color: #5E5E5E;">=</span> s[<span class="st" style="color: #20794D;">'title'</span>]</span>
<span id="cb12-18">        titles.append(cur_title)</span>
<span id="cb12-19">        </span>
<span id="cb12-20">        <span class="co" style="color: #5E5E5E;"># create the guidance transformation </span></span>
<span id="cb12-21">        cur_sched <span class="op" style="color: #5E5E5E;">=</span> s[<span class="st" style="color: #20794D;">'schedule'</span>]</span>
<span id="cb12-22">        gtfm <span class="op" style="color: #5E5E5E;">=</span> guide_tfm({<span class="st" style="color: #20794D;">'g'</span>: cur_sched})</span>
<span id="cb12-23">        </span>
<span id="cb12-24">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Running experiment [</span><span class="sc" style="color: #5E5E5E;">{</span>i<span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span><span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;"> of </span><span class="sc" style="color: #5E5E5E;">{</span>ns<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">]: </span><span class="sc" style="color: #5E5E5E;">{</span>cur_title<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">...'</span>)</span>
<span id="cb12-25">        img <span class="op" style="color: #5E5E5E;">=</span> generate(prompt, gtfm)</span>
<span id="cb12-26">        images.append(img)</span>
<span id="cb12-27">        </span>
<span id="cb12-28">        <span class="co" style="color: #5E5E5E;"># optionally plot the image</span></span>
<span id="cb12-29">        <span class="cf" style="color: #003B4F;">if</span> show_each:</span>
<span id="cb12-30">            show_image(img, scale<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb12-31"></span>
<span id="cb12-32">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Done.'</span>)</span>
<span id="cb12-33">    <span class="cf" style="color: #003B4F;">return</span> {</span>
<span id="cb12-34">        <span class="st" style="color: #20794D;">'images'</span>: images,</span>
<span id="cb12-35">        <span class="st" style="color: #20794D;">'titles'</span>: titles,</span>
<span id="cb12-36">    }</span></code></pre></div>
</div>
</section>
<section id="the-baseline-guidance-with-a-constant-g-7.5" class="level1">
<h1>The Baseline: Guidance with a constant <img src="https://latex.codecogs.com/png.latex?G%20=7.5"></h1>
<p>We need a good baseline to find out exactly how dynamic guidances affect the output images.</p>
<p>Below we create the baseline Classifier-free Guidance with a static, constant update of <img src="https://latex.codecogs.com/png.latex?G%20=%207.5">.</p>
<p>The code below seems like a lot of overhead, but it will be very helpful to sweep a variety of cosine schedules later on.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="co" style="color: #5E5E5E;"># create the baseline Classifier-free Guidance</span></span>
<span id="cb13-2">baseline_run <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb13-3">    <span class="st" style="color: #20794D;">'max_val'</span>: [<span class="fl" style="color: #AD0000;">7.5</span>],</span>
<span id="cb13-4">}</span>
<span id="cb13-5"></span>
<span id="cb13-6"><span class="co" style="color: #5E5E5E;"># parameters we are sweeping</span></span>
<span id="cb13-7">baselines_names <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">sorted</span>(<span class="bu" style="color: null;">list</span>(baseline_run))</span>
<span id="cb13-8">baseline_scheds <span class="op" style="color: #5E5E5E;">=</span> L()</span>
<span id="cb13-9"></span>
<span id="cb13-10"><span class="co" style="color: #5E5E5E;"># step through each parameter</span></span>
<span id="cb13-11"><span class="cf" style="color: #003B4F;">for</span> idx,name <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(baselines_names):</span>
<span id="cb13-12">    <span class="co" style="color: #5E5E5E;"># step through each of its values</span></span>
<span id="cb13-13">    <span class="cf" style="color: #003B4F;">for</span> idj,val <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(baseline_run[name]):</span>
<span id="cb13-14"></span>
<span id="cb13-15">        <span class="co" style="color: #5E5E5E;"># create the baseline experimeent</span></span>
<span id="cb13-16">        expt <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb13-17">            <span class="st" style="color: #20794D;">'param_name'</span>: name,</span>
<span id="cb13-18">            <span class="st" style="color: #20794D;">'val'</span>: val,</span>
<span id="cb13-19">            <span class="st" style="color: #20794D;">'schedule'</span>: [val <span class="cf" style="color: #003B4F;">for</span> _ <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(num_steps)]</span>
<span id="cb13-20">        }</span>
<span id="cb13-21">        <span class="co" style="color: #5E5E5E;"># for plotting</span></span>
<span id="cb13-22">        expt[<span class="st" style="color: #20794D;">'title'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="ss" style="color: #20794D;">f'Param: "</span><span class="sc" style="color: #5E5E5E;">{</span>name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">", val=</span><span class="sc" style="color: #5E5E5E;">{</span>val<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb13-23">        </span>
<span id="cb13-24">        <span class="co" style="color: #5E5E5E;"># add to the running list of experiments</span></span>
<span id="cb13-25">        baseline_scheds.append(expt)</span></code></pre></div>
</div>
<p>Let’s create the baseline image. The hope is that our guidance changes can then improve on it.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">basline_res <span class="op" style="color: #5E5E5E;">=</span> run(prompt, baseline_scheds, guide_tfm<span class="op" style="color: #5E5E5E;">=</span>GuidanceTfm, show_each<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Using Guidance Transform: &lt;class 'cf_guidance.transforms.GuidanceTfm'&gt;
Running experiment [1 of 1]: Param: "max_val", val=7.5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ba08c40877914d98861104423086dee4","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-20-guidance-expts-2/index_files/figure-html/cell-15-output-3.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.</code></pre>
</div>
</div>
<p>Not bad for a starting point. Let’s see if we can do better.</p>
</section>
<section id="trying-to-improve-the-baseline" class="level1">
<h1>Trying to improve the baseline</h1>
<p>We now use the <a href="https://github.com/enzokro/guidance_transforms">cf_guidance</a> library to create a variety of Cosine schedules.</p>
<p>From the previous notebook, we know that a regular Cosine schedule can improve image generations. The goal now is to figure out exactly what makes for a good Cosine schedule.</p>
<p>This is a hard question to answer. We can start by trying incremental, minimum-pair changes to a baseline schedule. Then we check what effects, if any, our dynamic guidances have on the generated images.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The recent trend in Diffusion variance schedules is to add noise in a slower, more gradual way. This change seems to improve both model training and inference generations.</p>
<p>We will keep this in mind in future notebooks as we explore more schedules.</p>
</div>
</div>
<p>Once we have a sense of which schedules work (and which don’t), we can explore the scheduling space in a better, more principled way.</p>
<section id="default-schedule-parameters" class="level2">
<h2 class="anchored" data-anchor-id="default-schedule-parameters">Default schedule parameters</h2>
<p>We start from the guidance schedule value from the previous notebook.</p>
<p>Recall that there were three kinds of schedules:</p>
<ol type="1">
<li>A static schedule with a constant <img src="https://latex.codecogs.com/png.latex?G">.<br>
</li>
<li>A decreasing Cosine schedule.<br>
</li>
<li>A Cosine schedule with some initial warm up steps.</li>
</ol>
<div class="cell">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="co" style="color: #5E5E5E;"># Default schedule parameters from the blog post</span></span>
<span id="cb17-2"><span class="co" style="color: #5E5E5E;">######################################</span></span>
<span id="cb17-3">max_val           <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">7.5</span>   <span class="co" style="color: #5E5E5E;"># guidance scaling value</span></span>
<span id="cb17-4">min_val           <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span>     <span class="co" style="color: #5E5E5E;"># minimum guidance scaling</span></span>
<span id="cb17-5">num_steps         <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">50</span>    <span class="co" style="color: #5E5E5E;"># number of diffusion steps</span></span>
<span id="cb17-6">num_warmup_steps  <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span>     <span class="co" style="color: #5E5E5E;"># number of warmup steps</span></span>
<span id="cb17-7">warmup_init_val   <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span>     <span class="co" style="color: #5E5E5E;"># the intial warmup value</span></span>
<span id="cb17-8">num_cycles        <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.5</span>   <span class="co" style="color: #5E5E5E;"># number of cosine cycles</span></span>
<span id="cb17-9">k_decay           <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span>     <span class="co" style="color: #5E5E5E;"># k-decay for cosine curve scaling </span></span>
<span id="cb17-10"><span class="co" style="color: #5E5E5E;">######################################</span></span></code></pre></div>
</div>
<p>To make sure our changes always reference this shared starting point, we can wrap these parameters in a dictionary.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1">DEFAULT_COS_PARAMS <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb18-2">    <span class="st" style="color: #20794D;">'max_val'</span>:           max_val,</span>
<span id="cb18-3">    <span class="st" style="color: #20794D;">'num_steps'</span>:         num_steps,</span>
<span id="cb18-4">    <span class="st" style="color: #20794D;">'min_val'</span>:           min_val,</span>
<span id="cb18-5">    <span class="st" style="color: #20794D;">'num_cycles'</span>:        num_cycles,</span>
<span id="cb18-6">    <span class="st" style="color: #20794D;">'k_decay'</span>:           k_decay,</span>
<span id="cb18-7">    <span class="st" style="color: #20794D;">'num_warmup_steps'</span>:  num_warmup_steps,</span>
<span id="cb18-8">    <span class="st" style="color: #20794D;">'warmup_init_val'</span>:   warmup_init_val,</span>
<span id="cb18-9">}</span></code></pre></div>
</div>
<p>Then, every minimum-pair change will start from this shared dictionary and update a single parameter. The <code>cos_harness</code> below gives us an easy way of making these minimum-pair changes.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="kw" style="color: #003B4F;">def</span> cos_harness(new_params<span class="op" style="color: #5E5E5E;">=</span>{}, cos_params<span class="op" style="color: #5E5E5E;">=</span>DEFAULT_COS_PARAMS):</span>
<span id="cb19-2">    <span class="co" style="color: #5E5E5E;">'''Creates cosine schedules with updated parameters in `new_params`'''</span></span>
<span id="cb19-3">    </span>
<span id="cb19-4">    <span class="co" style="color: #5E5E5E;"># start from the given baseline `cos_params`</span></span>
<span id="cb19-5">    cos_params <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">dict</span>(cos_params)</span>
<span id="cb19-6">    </span>
<span id="cb19-7">    <span class="co" style="color: #5E5E5E;"># update the schedule with any new parameters</span></span>
<span id="cb19-8">    <span class="cf" style="color: #003B4F;">if</span> new_params: cos_params.update(new_params)</span>
<span id="cb19-9">    </span>
<span id="cb19-10">    <span class="co" style="color: #5E5E5E;"># return the new cosine schedule</span></span>
<span id="cb19-11">    sched <span class="op" style="color: #5E5E5E;">=</span> get_cos_sched(<span class="op" style="color: #5E5E5E;">**</span>cos_params)</span>
<span id="cb19-12">    <span class="cf" style="color: #003B4F;">return</span> sched</span></code></pre></div>
</div>
<p>Let’s use the cosine harness to plot three test schedules, just to make sure things are working:</p>
<ul>
<li>The baseline with no warmup.<br>
</li>
<li>Warmup for 5 steps.<br>
</li>
<li>Warmup for 10 steps.</li>
</ul>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The schedule plotting function <code>plot_schedules</code> is available in the post’s notebook.</p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="co" style="color: #5E5E5E;"># plot cosine schedules with different number of warmup steps</span></span>
<span id="cb20-2">warmup_steps <span class="op" style="color: #5E5E5E;">=</span> (<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">5</span>, <span class="dv" style="color: #AD0000;">10</span>)</span>
<span id="cb20-3">warm_g <span class="op" style="color: #5E5E5E;">=</span> L( </span>
<span id="cb20-4">    {<span class="st" style="color: #20794D;">'sched'</span>: cos_harness({<span class="st" style="color: #20794D;">'num_warmup_steps'</span>: w}), </span>
<span id="cb20-5">     <span class="st" style="color: #20794D;">'title'</span>: <span class="ss" style="color: #20794D;">f'Warmup Steps: </span><span class="sc" style="color: #5E5E5E;">{</span>w<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>}</span>
<span id="cb20-6">    <span class="cf" style="color: #003B4F;">for</span> w <span class="kw" style="color: #003B4F;">in</span> warmup_steps</span>
<span id="cb20-7">)</span>
<span id="cb20-8"></span>
<span id="cb20-9"><span class="co" style="color: #5E5E5E;"># plot the schedules</span></span>
<span id="cb20-10"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Plotting sample cosine schedules...'</span>)</span>
<span id="cb20-11">plot_schedules(warm_g.itemgot(<span class="st" style="color: #20794D;">'sched'</span>), rows<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>, titles<span class="op" style="color: #5E5E5E;">=</span>warm_g.itemgot(<span class="st" style="color: #20794D;">'title'</span>))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Plotting sample cosine schedules...</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-20-guidance-expts-2/index_files/figure-html/cell-20-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="creating-the-cosine-experiments" class="level2">
<h2 class="anchored" data-anchor-id="creating-the-cosine-experiments">Creating the Cosine experiments</h2>
<p>Now we can create the different Cosine schedules that will be swept.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1">cos_param_sweep <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb22-2">    <span class="st" style="color: #20794D;">'num_warmup_steps'</span>: [<span class="dv" style="color: #AD0000;">5</span>, <span class="dv" style="color: #AD0000;">10</span>, <span class="dv" style="color: #AD0000;">15</span>],</span>
<span id="cb22-3">    <span class="st" style="color: #20794D;">'num_cycles'</span>:       [<span class="dv" style="color: #AD0000;">1</span>, <span class="fl" style="color: #AD0000;">1.5</span>],</span>
<span id="cb22-4">    <span class="st" style="color: #20794D;">'k_decay'</span>:          [<span class="fl" style="color: #AD0000;">0.8</span>, <span class="fl" style="color: #AD0000;">0.6</span>],</span>
<span id="cb22-5">    <span class="st" style="color: #20794D;">'max_val'</span>:          [<span class="dv" style="color: #AD0000;">10</span>],</span>
<span id="cb22-6">    <span class="st" style="color: #20794D;">'min_val'</span>:          [<span class="dv" style="color: #AD0000;">3</span>],</span>
<span id="cb22-7">}</span>
<span id="cb22-8"></span>
<span id="cb22-9">param_names <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">sorted</span>(<span class="bu" style="color: null;">list</span>(cos_param_sweep))</span>
<span id="cb22-10"></span>
<span id="cb22-11">cos_scheds <span class="op" style="color: #5E5E5E;">=</span> L()</span>
<span id="cb22-12"><span class="cf" style="color: #003B4F;">for</span> idx,name <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(param_names):</span>
<span id="cb22-13">    <span class="cf" style="color: #003B4F;">for</span> idj,val <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(cos_param_sweep[name]):</span>
<span id="cb22-14"></span>
<span id="cb22-15">        <span class="co" style="color: #5E5E5E;"># create the cosine experimeent</span></span>
<span id="cb22-16">        expt <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb22-17">            <span class="st" style="color: #20794D;">'param_name'</span>: name,</span>
<span id="cb22-18">            <span class="st" style="color: #20794D;">'val'</span>: val,</span>
<span id="cb22-19">            <span class="st" style="color: #20794D;">'schedule'</span>: cos_harness({name: val})</span>
<span id="cb22-20">        }</span>
<span id="cb22-21">        <span class="co" style="color: #5E5E5E;"># for plotting</span></span>
<span id="cb22-22">        expt[<span class="st" style="color: #20794D;">'title'</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="ss" style="color: #20794D;">f'Param: "</span><span class="sc" style="color: #5E5E5E;">{</span>name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">", val=</span><span class="sc" style="color: #5E5E5E;">{</span>val<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb22-23">        </span>
<span id="cb22-24">        cos_scheds.append(expt)</span>
<span id="cb22-25">    </span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1">plot_schedules(cos_scheds.itemgot(<span class="st" style="color: #20794D;">'schedule'</span>), rows<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">3</span>, titles<span class="op" style="color: #5E5E5E;">=</span>cos_scheds.itemgot(<span class="st" style="color: #20794D;">'title'</span>))</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-20-guidance-expts-2/index_files/figure-html/cell-22-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="running-the-cosine-experiments" class="level2">
<h2 class="anchored" data-anchor-id="running-the-cosine-experiments">Running the cosine experiments</h2>
<p>We use the <code>run</code> function from before to run all of the cosine experiments.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1">cos_res <span class="op" style="color: #5E5E5E;">=</span> run(prompt, cos_scheds, guide_tfm<span class="op" style="color: #5E5E5E;">=</span>GuidanceTfm, show_each<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Using Guidance Transform: &lt;class 'cf_guidance.transforms.GuidanceTfm'&gt;
Running experiment [1 of 9]: Param: "k_decay", val=0.8...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"273f3cc220f44aa2bc25af8f8791753e","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [2 of 9]: Param: "k_decay", val=0.6...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"9db6048fe5ff410188bdc445b08b73c7","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [3 of 9]: Param: "max_val", val=10...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"0721592ec860420bbf5fcbe20208af6b","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [4 of 9]: Param: "min_val", val=3...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"47f49745744f444da072ac7c0a78c57c","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [5 of 9]: Param: "num_cycles", val=1...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"02d202d2eb194ff39707038b18702aba","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [6 of 9]: Param: "num_cycles", val=1.5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"37e213349cf64aaa81e94490f2e82e33","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [7 of 9]: Param: "num_warmup_steps", val=5...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"497570d656b341e5bb8186ccefb4ad82","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [8 of 9]: Param: "num_warmup_steps", val=10...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"2700c6f7046645b49e70fa054083b1df","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment [9 of 9]: Param: "num_warmup_steps", val=15...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"dbe6459024084500a01b81462dfb574d","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-20-guidance-expts-2/index_files/figure-html/cell-24-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="results" class="level1">
<h1>Results</h1>
<p>Going through the images, we can spot a few patterns.</p>
<p>Changing the minimum value of <img src="https://latex.codecogs.com/png.latex?G"> does not have a huge effect. However, changing the max value of <img src="https://latex.codecogs.com/png.latex?G"> to <img src="https://latex.codecogs.com/png.latex?10"> actively hurt the image.</p>
<p>It seems that going through more cosine cycles improved the horse’s anatomy. It now has two hind legs and its body looks more proportional.</p>
<p>The number of warmup steps has a mixed effect. The lower value of <img src="https://latex.codecogs.com/png.latex?5"> and <img src="https://latex.codecogs.com/png.latex?10"> produce… interesting outputs with morphed horses. If it weren’t for the floating horse head at 10 warmup steps, it would be a solid improvement. At <img src="https://latex.codecogs.com/png.latex?15"> warmup steps we get a lovely image with a nice, detailed background..</p>
<section id="analysis" class="level2">
<h2 class="anchored" data-anchor-id="analysis">Analysis</h2>
<p>Certain Cosine schedules seem promising. They either increase the details of the astronaut or background, or they create more anatomically correct horses.</p>
<p>In the rest of the series, we will explore the promising Cosine changes:</p>
<ul>
<li>Setting a higher Guidance ceiling.<br>
</li>
<li>Allowing the Cosine to go through multiple cycles.<br>
</li>
<li>Warming up for a few steps.</li>
</ul>
</section>
<section id="bringing-in-normalizations" class="level2">
<h2 class="anchored" data-anchor-id="bringing-in-normalizations">Bringing in Normalizations</h2>
<p>In the previous notebooks, we found that normalization can have a huge improvement on generated images. The next logical step is to add normalizations to our schedules to see if the gains compound.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>This notebook used the <code>cf_guidance</code> library to run a set of Guidance experiments. We swept a variety of Cosine schedules and compared the results to a baseline generation.</p>
<p>We showed that the guidance schedule has a big impact on the quality and syntax of generated images. We also found a set of Cosine schedules with the potential to improve generated images.</p>
<p>In the next part of this series, we will combine cosine schedules with normalizations.</p>


</section>

 ]]></description>
  <category>diffusion</category>
  <category>classifier-free guidance</category>
  <category>deep learning</category>
  <guid>https://enzokro.dev/blog/posts/2022-11-20-guidance-expts-2/index.html</guid>
  <pubDate>Sun, 20 Nov 2022 00:00:00 GMT</pubDate>
  <media:content url="https://enzokro.dev/blog/posts/2022-11-20-guidance-expts-2/better-gen-horse.png" medium="image" type="image/png" height="144" width="144"/>
</item>
<item>
  <title>A PyTorch SLERP implementation</title>
  <dc:creator>enzokro</dc:creator>
  <link>https://enzokro.dev/blog/posts/2022-11-16-pytorch-slerp/index.html</link>
  <description><![CDATA[ 



<blockquote class="blockquote">
<p>SLERP implemented in PyTorch with proper thresholding.</p>
</blockquote>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>This notebook introduces a native PyTorch implementation of <a href="https://en.wikipedia.org/wiki/Slerp">SLERP</a>.</p>
<p>SLERP stands for “Spherical Linear Interpolation”. It is an extension of linear interpolation that preserves the length of the input vectors. We go over why preserving length is important in the Background section below.</p>
<p>In future posts, we will use SLERP to combine the latent vectors of Diffusion models.</p>
</section>
<section id="background" class="level1">
<h1>Background</h1>
<section id="why-do-we-need-slerp" class="level2">
<h2 class="anchored" data-anchor-id="why-do-we-need-slerp">Why do we need SLERP?</h2>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>If you don’t need the theory, you can skip straight to the code.</p>
</div>
</div>
<p>SLERP interpolates two vectors while keeping their magnitudes intact. Why would this be important for Diffusion models?</p>
<p>The reason has to do with how Gaussian distributions behave in higher dimensions. This <a href="https://www.inference.vc/high-dimensional-gaussian-distributions-are-soap-bubble/">blog post</a> by Ferenc Huszár has an excellent description of how exactly our intuitions fall apart in high dimensions. The post also has many good visualizations to drive the point home.</p>
<section id="gaussians-in-high-dimensions" class="level3">
<h3 class="anchored" data-anchor-id="gaussians-in-high-dimensions">Gaussians in high dimensions</h3>
<p>To summarize Ferenc’s blog post: a Gaussian in high dimensions is fundamentally different than its 1-D “Bell curve” version.</p>
<p>As we climb to higher dimensions the Gaussian distribution becomes a thin, hollow shell. Its probability density spreads out around this thin shell. Think about how different that is to a 1-D Gaussian. In the 1-D case, most of the density falls within a few standard deviations of the mean.</p>
<p>Before long, the inside of this high-dimensional Gaussian is empty. Only its thin shell has any probability at all. Borrowing Ferenc’s excellent analogy: the distribution turns into a “soap bubble”.</p>
<p>Recall that most Diffusion models are based on high-dimensional Gaussians. That means that, in Diffusion, we are actually dealing with many high-dimensional soap bubbles. If we treat them like regular 2-D or 3-D vectors, our intuitions will fail us.</p>
</section>
<section id="ok-so-where-does-slerp-come-in" class="level3">
<h3 class="anchored" data-anchor-id="ok-so-where-does-slerp-come-in">Ok, so where does SLERP come in?</h3>
<p>If we linearly interpolate two high-dimensional Gaussians, the result can easily fly away from the soap bubble’s surface. The section below has an example of what this looks like in 2-D space.</p>
<p>SLERP makes it possible to properly interpolate Diffusion vectors by keeping us firmly grounded on the surface of the soap bubble.</p>
</section>
</section>
<section id="what-about-linear-interpolation" class="level2">
<h2 class="anchored" data-anchor-id="what-about-linear-interpolation">What about linear interpolation?</h2>
<p>Regular linear interpolation (sometimes called LERP) is a powerful tool. It is a cornerstone in modern computer graphics to move an object between two points.</p>
<p>LERP has a loose analogy with gravity: the shortest distance between two points is a straight line.</p>
<p>For example, imagine you are drinking a cup of coffee. The mug is currently on the table. As you go to take a sip, you pick up the mug and bring it directly to your lips. You wouldn’t swing your arm around in a weird way. That would only be more work <em>and</em> delay the sip of coffee.</p>
<p>In other words, when moving objects in our 3-D world we want to do the least amount of work possible. That is what LERP does in 2-D and 3-D space. In a manner of speaking, you used LERP to bring the coffee mug to your lips and take a sip.</p>
<p>This coffee example brings us back to why we need SLERP in the first place. Our notions of 3-D paths break down in higher dimensions, and LERP does not work as intended. Here we are much better served by SLERP.</p>
<section id="a-concrete-lerp-example" class="level3">
<h3 class="anchored" data-anchor-id="a-concrete-lerp-example">A concrete LERP example</h3>
<p>Let’s show how linear interpolation works on vectors.</p>
<p>For this example we will use the familiar <img src="https://latex.codecogs.com/png.latex?x"> and <img src="https://latex.codecogs.com/png.latex?y"> basis vectors. We also draw the Unit Circle for reference.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The plotting function <code>plot_vectors</code> is available in the <a href="https://github.com/enzokro/chaski/blob/main/nbs/blog/posts/2022-11-16-pytorch-slerp/index.ipynb">post’s notebook</a>. It is omitted here for space.</p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb1-2"></span>
<span id="cb1-3"><span class="co" style="color: #5E5E5E;"># use the X and Y unit vectors as an example</span></span>
<span id="cb1-4">xhat <span class="op" style="color: #5E5E5E;">=</span> torch.tensor([<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">0</span>]).<span class="bu" style="color: null;">float</span>()</span>
<span id="cb1-5">yhat <span class="op" style="color: #5E5E5E;">=</span> torch.tensor([<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">1</span>]).<span class="bu" style="color: null;">float</span>()</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;"># plot the basis vectors, with a unit circle outline</span></span>
<span id="cb2-2">fig <span class="op" style="color: #5E5E5E;">=</span> plot_vectors(xhat, yhat, labels<span class="op" style="color: #5E5E5E;">=</span>[<span class="st" style="color: #20794D;">'$\hat</span><span class="sc" style="color: #5E5E5E;">{x}</span><span class="st" style="color: #20794D;">$'</span>, <span class="st" style="color: #20794D;">'$\hat</span><span class="sc" style="color: #5E5E5E;">{y}</span><span class="st" style="color: #20794D;">$'</span>], draw_unit_circle<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb2-3"></span>
<span id="cb2-4">plt.xlabel(<span class="st" style="color: #20794D;">'X Axis'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'x-large'</span>)</span>
<span id="cb2-5">plt.ylabel(<span class="st" style="color: #20794D;">'Y Axis'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'x-large'</span>)</span>
<span id="cb2-6">plt.title(<span class="st" style="color: #20794D;">'Basis Vectors on the Unit Circle'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'xx-large'</span>, pad<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span>)<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-16-pytorch-slerp/index_files/figure-html/cell-5-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>What happens if we linearly interpolate (LERP) these vectors to their midpoint?</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;"># use linear interpolation to find the midpoint</span></span>
<span id="cb3-2">p_lerp <span class="op" style="color: #5E5E5E;">=</span> (xhat <span class="op" style="color: #5E5E5E;">+</span> yhat) <span class="op" style="color: #5E5E5E;">/</span> <span class="dv" style="color: #AD0000;">2</span></span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;"># plotting the LERP of basis vectors x and y</span></span>
<span id="cb4-2">fig <span class="op" style="color: #5E5E5E;">=</span> plot_vectors(xhat, yhat, p_lerp, labels<span class="op" style="color: #5E5E5E;">=</span>[<span class="st" style="color: #20794D;">'$\hat</span><span class="sc" style="color: #5E5E5E;">{x}</span><span class="st" style="color: #20794D;">$'</span>, <span class="st" style="color: #20794D;">'$\hat</span><span class="sc" style="color: #5E5E5E;">{y}</span><span class="st" style="color: #20794D;">$'</span>, <span class="st" style="color: #20794D;">'P_lerp'</span>])</span>
<span id="cb4-3"></span>
<span id="cb4-4">plt.xlabel(<span class="st" style="color: #20794D;">'X Axis'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'x-large'</span>)</span>
<span id="cb4-5">plt.ylabel(<span class="st" style="color: #20794D;">'Y Axis'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'x-large'</span>)</span>
<span id="cb4-6">plt.title(<span class="st" style="color: #20794D;">'Linear Interpolation of Unit Vectors'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'xx-large'</span>, pad<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span>)<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-16-pytorch-slerp/index_files/figure-html/cell-7-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>If we only cared about getting from <img src="https://latex.codecogs.com/png.latex?%5Chat%7By%7D"> to <img src="https://latex.codecogs.com/png.latex?%5Chat%7Bx%7D"> then we are on the right track. LERP is following the shortest possible path.</p>
<p>But imagine if the Unit Circle was like a slice of a high-dimensional Gaussian. In that case, linear interpolation has moved us away from the surface of the soap bubble!</p>
<p>If we were dealing with a 1-D Gaussian, it’s as if we have moved very far from the mean. Imagine going out <img src="https://latex.codecogs.com/png.latex?+10"> <img src="https://latex.codecogs.com/png.latex?%5Csigma"> away. That would obviously be an incredibly unlikely sample. And that is exactly where the <img src="https://latex.codecogs.com/png.latex?P_%5Ctext%7BLERP%7D"> vector ends up.</p>
<p>With SLERP, we can still interpolate the vectors while also staying firmly anchored to the soap bubble.</p>
</section>
</section>
</section>
<section id="slerp-implementation" class="level1">
<h1>SLERP Implementation</h1>
<p>The code below is a refactor of a great numpy implementation by <a href="https://twitter.com/xsteenbrugge"><span class="citation" data-cites="xsteenbrugge">@xsteenbrugge</span></a>. There is an example of it in Andrej Karpathy’s <a href="https://gist.github.com/karpathy/00103b0037c5aaea32fe1da1af553355">Diffusion video script</a>.<br>
We also compare our SLERP to a short PyTorch implementation from <a href="https://twitter.com/ptrblck_de"><span class="citation" data-cites="ptrblck_de">@ptrblck_de</span></a> in the <a href="https://discuss.pytorch.org/t/help-regarding-slerp-function-for-generative-model-sampling/32475/4">pytorch forums</a>.</p>
<p>This version of SLERP is in pure pytorch. It doesn’t cast tensors to and from numpy. But, if GPU memory is at a premium, there is a flag <code>to_cpu</code> to compute SLERP on the CPU instead.</p>
<p>Our SLERP implementation has a threshold on the dot product to avoid <code>nans</code> if the vectors are too close to parallel. Finally, this SLERP also has a <code>zdim</code> argument to handle sequences of vectors.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="im" style="color: #00769E;">import</span> torch </span>
<span id="cb5-2"></span>
<span id="cb5-3"><span class="kw" style="color: #003B4F;">def</span> slerp(v1, v2, t, DOT_THR<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.9995</span>, to_cpu<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>, zdim<span class="op" style="color: #5E5E5E;">=-</span><span class="dv" style="color: #AD0000;">1</span>):</span>
<span id="cb5-4">    <span class="co" style="color: #5E5E5E;">"""SLERP for pytorch tensors interpolating `v1` to `v2` with scale of `t`.</span></span>
<span id="cb5-5"></span>
<span id="cb5-6"><span class="co" style="color: #5E5E5E;">    `DOT_THR` determines when the vectors are too close to parallel.</span></span>
<span id="cb5-7"><span class="co" style="color: #5E5E5E;">        If they are too close, then a regular linear interpolation is used.</span></span>
<span id="cb5-8"></span>
<span id="cb5-9"><span class="co" style="color: #5E5E5E;">    `to_cpu` is a flag that optionally computes SLERP on the CPU.</span></span>
<span id="cb5-10"><span class="co" style="color: #5E5E5E;">        If the input tensors were on a GPU, it moves them back after the computation.  </span></span>
<span id="cb5-11"></span>
<span id="cb5-12"><span class="co" style="color: #5E5E5E;">    `zdim` is the feature dimension over which to compute norms and find angles.</span></span>
<span id="cb5-13"><span class="co" style="color: #5E5E5E;">        For example: if a sequence of 5 vectors is input with shape [5, 768]</span></span>
<span id="cb5-14"><span class="co" style="color: #5E5E5E;">        Then `zdim = 1` or `zdim = -1` computes SLERP along the feature dim of 768.</span></span>
<span id="cb5-15"></span>
<span id="cb5-16"><span class="co" style="color: #5E5E5E;">    Theory Reference:</span></span>
<span id="cb5-17"><span class="co" style="color: #5E5E5E;">    https://splines.readthedocs.io/en/latest/rotation/slerp.html</span></span>
<span id="cb5-18"><span class="co" style="color: #5E5E5E;">    PyTorch reference:</span></span>
<span id="cb5-19"><span class="co" style="color: #5E5E5E;">    https://discuss.pytorch.org/t/help-regarding-slerp-function-for-generative-model-sampling/32475/3</span></span>
<span id="cb5-20"><span class="co" style="color: #5E5E5E;">    Numpy reference: </span></span>
<span id="cb5-21"><span class="co" style="color: #5E5E5E;">    https://gist.github.com/dvschultz/3af50c40df002da3b751efab1daddf2c</span></span>
<span id="cb5-22"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb5-23"></span>
<span id="cb5-24">    <span class="co" style="color: #5E5E5E;"># check if we need to move to the cpu</span></span>
<span id="cb5-25">    <span class="cf" style="color: #003B4F;">if</span> to_cpu:</span>
<span id="cb5-26">        orig_device <span class="op" style="color: #5E5E5E;">=</span> v1.device</span>
<span id="cb5-27">        v1, v2 <span class="op" style="color: #5E5E5E;">=</span> v1.to(<span class="st" style="color: #20794D;">'cpu'</span>), v2.to(<span class="st" style="color: #20794D;">'cpu'</span>)</span>
<span id="cb5-28"></span>
<span id="cb5-29">    <span class="co" style="color: #5E5E5E;"># take the dot product between normalized vectors</span></span>
<span id="cb5-30">    v1_norm <span class="op" style="color: #5E5E5E;">=</span> v1 <span class="op" style="color: #5E5E5E;">/</span> torch.norm(v1, dim<span class="op" style="color: #5E5E5E;">=</span>zdim, keepdim<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb5-31">    v2_norm <span class="op" style="color: #5E5E5E;">=</span> v2 <span class="op" style="color: #5E5E5E;">/</span> torch.norm(v2, dim<span class="op" style="color: #5E5E5E;">=</span>zdim, keepdim<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb5-32">    dot <span class="op" style="color: #5E5E5E;">=</span> (v1_norm <span class="op" style="color: #5E5E5E;">*</span> v2_norm).<span class="bu" style="color: null;">sum</span>(zdim)</span>
<span id="cb5-33"></span>
<span id="cb5-34">    <span class="co" style="color: #5E5E5E;"># if the vectors are too close, return a simple linear interpolation</span></span>
<span id="cb5-35">    <span class="cf" style="color: #003B4F;">if</span> (torch.<span class="bu" style="color: null;">abs</span>(dot) <span class="op" style="color: #5E5E5E;">&gt;</span> DOT_THR).<span class="bu" style="color: null;">any</span>():</span>
<span id="cb5-36">        <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'warning: v1 and v2 close to parallel, using linear interpolation instead.'</span>)</span>
<span id="cb5-37">        res <span class="op" style="color: #5E5E5E;">=</span> (<span class="dv" style="color: #AD0000;">1</span> <span class="op" style="color: #5E5E5E;">-</span> t) <span class="op" style="color: #5E5E5E;">*</span> v1 <span class="op" style="color: #5E5E5E;">+</span> t <span class="op" style="color: #5E5E5E;">*</span> v2    </span>
<span id="cb5-38"></span>
<span id="cb5-39">    <span class="co" style="color: #5E5E5E;"># else apply SLERP</span></span>
<span id="cb5-40">    <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb5-41">        <span class="co" style="color: #5E5E5E;"># compute the angle terms we need</span></span>
<span id="cb5-42">        theta   <span class="op" style="color: #5E5E5E;">=</span> torch.acos(dot)</span>
<span id="cb5-43">        theta_t <span class="op" style="color: #5E5E5E;">=</span> theta <span class="op" style="color: #5E5E5E;">*</span> t</span>
<span id="cb5-44">        sin_theta   <span class="op" style="color: #5E5E5E;">=</span> torch.sin(theta)</span>
<span id="cb5-45">        sin_theta_t <span class="op" style="color: #5E5E5E;">=</span> torch.sin(theta_t)</span>
<span id="cb5-46"></span>
<span id="cb5-47">        <span class="co" style="color: #5E5E5E;"># compute the sine scaling terms for the vectors</span></span>
<span id="cb5-48">        s1 <span class="op" style="color: #5E5E5E;">=</span> torch.sin(theta <span class="op" style="color: #5E5E5E;">-</span> theta_t) <span class="op" style="color: #5E5E5E;">/</span> sin_theta</span>
<span id="cb5-49">        s2 <span class="op" style="color: #5E5E5E;">=</span> sin_theta_t <span class="op" style="color: #5E5E5E;">/</span> sin_theta</span>
<span id="cb5-50"></span>
<span id="cb5-51">        <span class="co" style="color: #5E5E5E;"># interpolate the vectors</span></span>
<span id="cb5-52">        res <span class="op" style="color: #5E5E5E;">=</span> (s1.unsqueeze(zdim) <span class="op" style="color: #5E5E5E;">*</span> v1) <span class="op" style="color: #5E5E5E;">+</span> (s2.unsqueeze(zdim) <span class="op" style="color: #5E5E5E;">*</span> v2)</span>
<span id="cb5-53"></span>
<span id="cb5-54">        <span class="co" style="color: #5E5E5E;"># check if we need to move them back to the original device</span></span>
<span id="cb5-55">        <span class="cf" style="color: #003B4F;">if</span> to_cpu:</span>
<span id="cb5-56">            res.to(orig_device)</span>
<span id="cb5-57"></span>
<span id="cb5-58">    <span class="cf" style="color: #003B4F;">return</span> res</span></code></pre></div>
</div>
<section id="slerp-interpolation-of-the-unit-vectors" class="level2">
<h2 class="anchored" data-anchor-id="slerp-interpolation-of-the-unit-vectors">SLERP interpolation of the unit vectors</h2>
<p>What happens if we instead use SLERP to interpolate the unit vectors?</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="co" style="color: #5E5E5E;"># SLERP the unit vectors to their midpoint</span></span>
<span id="cb6-2">p <span class="op" style="color: #5E5E5E;">=</span> slerp(xhat, yhat, <span class="fl" style="color: #AD0000;">0.5</span>)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="co" style="color: #5E5E5E;"># plot the SLERP iterpolated vector</span></span>
<span id="cb7-2">fig <span class="op" style="color: #5E5E5E;">=</span> plot_vectors(xhat, yhat, p, labels<span class="op" style="color: #5E5E5E;">=</span>[<span class="st" style="color: #20794D;">'$\hat</span><span class="sc" style="color: #5E5E5E;">{x}</span><span class="st" style="color: #20794D;">$'</span>, <span class="st" style="color: #20794D;">'$\hat</span><span class="sc" style="color: #5E5E5E;">{y}</span><span class="st" style="color: #20794D;">$'</span>, <span class="st" style="color: #20794D;">"P_slerp"</span>])</span>
<span id="cb7-3">plt.xlabel(<span class="st" style="color: #20794D;">'X Axis'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'x-large'</span>)</span>
<span id="cb7-4">plt.ylabel(<span class="st" style="color: #20794D;">'Y Axis'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'x-large'</span>)</span>
<span id="cb7-5">plt.title(<span class="st" style="color: #20794D;">'SLERP on Unit Vectors to their midpoint P'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'xx-large'</span>, pad<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10</span>)<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-16-pytorch-slerp/index_files/figure-html/cell-10-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>That looks much better!</p>
<p>If the Unit Circle was like a Gaussian soap bubble, then we’ve properly moved along its film.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>This notebook described SLERP and its advantages over regular linear interpolation.</p>
<p>We also presented a PyTorch version of SLERP. This version handles vectors that are too close together, optionally moves computations to the CPU, and handles batched vectors.</p>
<p>Lastly, we drew some examples to make it clear why SLERP is better at interpolating high-dimensional vectors.</p>


</section>

 ]]></description>
  <category>diffusion</category>
  <category>latent interpolation</category>
  <category>SLERP</category>
  <guid>https://enzokro.dev/blog/posts/2022-11-16-pytorch-slerp/index.html</guid>
  <pubDate>Wed, 16 Nov 2022 00:00:00 GMT</pubDate>
  <media:content url="https://enzokro.dev/blog/posts/2022-11-16-pytorch-slerp/slerp.png" medium="image" type="image/png" height="102" width="144"/>
</item>
<item>
  <title>Intro to normalizing and scheduling Classifier-free Guidance</title>
  <dc:creator>enzokro</dc:creator>
  <link>https://enzokro.dev/blog/posts/2022-11-15-guidance-expts-1/index.html</link>
  <description><![CDATA[ 



<blockquote class="blockquote">
<p>Changing the Classifier-Free Guidance parameter during diffusion.</p>
</blockquote>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>This notebook covers the results of dynamically changing the guidance parameter during Classifier-Free Guidance (CFG). Most notably, we create a <code>GuidanceTfm</code> class so that others may easily import these ideas and start experimenting.</p>
</section>
<section id="background" class="level1">
<h1>Background</h1>
<p>We build on a great series of discussions on the <a href="https://forums.fast.ai/">fast.ai forums</a> about Classifier-Free Guidance. Some of the users involved were: (please let me know if I missed anyone):</p>
<ul>
<li><a href="https://twitter.com/FahimFarook">FahimF</a><br>
</li>
<li><a href="https://twitter.com/sebderhy">Seb</a><br>
</li>
<li><a href="https://twitter.com/rekil_prashanth">Rekil</a><br>
</li>
<li><a href="https://twitter.com/namrata_kamath">Namrata</a><br>
</li>
<li><a href="https://twitter.com/jeremyphoward">Jeremy</a></li>
</ul>
<p>In these talks, two two ideas came up for better Guidance:</p>
<ul>
<li>Normalizing the latents.<br>
</li>
<li>Scheduling the guidance scalar value.</li>
</ul>
<p>To see why these are good ideas, let’s quickly recap how Classifier-free Guidance works.</p>
<section id="classifier-free-guidance-overview" class="level2">
<h2 class="anchored" data-anchor-id="classifier-free-guidance-overview">Classifier-free Guidance overview</h2>
<p><a href="https://arxiv.org/abs/2207.12598">Classifier-free Guidance</a> is a way of steering the outputs of Diffusion models to better align with a given input. It is a key aspect of how we are able to type in a text prompt and get back a relevant, generated image.</p>
<p>CFG was needed because, by default, a Diffusion model starts from pure noise and randomly “walks” to unearth an image. Classifier-free Guidance can instead align the output according to a known, specific input. This known input is usually a meaningful piece of context like a sentence, or a segment of speech, or even another image.</p>
<p>In summary: Instead of randomly walking to generate random images, CFG allows Diffusion models to create targeted outputs.</p>
<section id="cfg-formula" class="level3">
<h3 class="anchored" data-anchor-id="cfg-formula">CFG Formula</h3>
<p>CFG updates the unconditioned latents to better match the conditional inputs as follows:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cepsilon%7D(x%20%5C%20%7C%5C%20%20y)%20=%20%5Cepsilon(x)%20+%20G%5Cleft(%5C%20%5Cepsilon(x%5C%20%20%7C%5C%20%20y)%20-%20%5Cepsilon(x)%5C%20%5Cright)"></p>
<p>We can think of this equation as a type of moving average. To be more specific, the terms are:</p>
<table class="table">
<thead>
<tr class="header">
<th><strong>Equation Term</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><img src="https://latex.codecogs.com/png.latex?%5Cepsilon(x)"></td>
<td>Unconditioned noise prediction</td>
</tr>
<tr class="even">
<td><img src="https://latex.codecogs.com/png.latex?%5Cepsilon(x%5C%20%7C%5C%20y)"></td>
<td>Conditional noise prediction</td>
</tr>
<tr class="odd">
<td><img src="https://latex.codecogs.com/png.latex?G"></td>
<td>Guidance scaling factor</td>
</tr>
<tr class="even">
<td><img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cepsilon%7D(x%5C%20%7C%5C%20y)"></td>
<td>The final, guided prediction.</td>
</tr>
</tbody>
</table>
<p>As several people have noticed, this update is not balanced. The reason for the unbalance is that <img src="https://latex.codecogs.com/png.latex?G"> is usually a large, fixed scalar. For example the default <img src="https://latex.codecogs.com/png.latex?G"> in Stable Diffusion pipelines is <img src="https://latex.codecogs.com/png.latex?G%20=%207.5">.</p>
<p>This brings up two questions:</p>
<ul>
<li>Does a large <img src="https://latex.codecogs.com/png.latex?G"> make the vectors too different?<br>
</li>
<li>Should <img src="https://latex.codecogs.com/png.latex?G"> be a fixed constant throughout the entire diffusion process?</li>
</ul>
<p>Fahim compiled the forum’s answers to these questions in <a href="https://github.com/FahimF/fai-exp/blob/main/guidance_variations.ipynb">this notebook</a>. His work compares both different normalizations and schedules for the Guidance parameter.</p>
<p>At first glance, it seems that both normalizing and scheduling the diffusion parameter improves the generated images. These better images are achieved for “free”, in the sense that we didn’t need any fine-tuning or new data.</p>
<p>Let’s take a look at some of the details and benefits of a dynamic guidance parameter.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>As <a href="https://twitter.com/poolio/status/1584699239342694402?s=20&amp;t=DxGXG7GsU6uLFqUN55tHWw">Ben Poole</a> points out in Jeremy’s twitter thread, these ideas are not new on their own.</p>
<p>One of the scalings was described in <a href="https://arxiv.org/pdf/2205.15370.pdf">Guided-TTS</a> for Speech diffusion. The normalizations are also related to the ones in <a href="https://arxiv.org/pdf/2205.12952.pdf">Pretraining is All You Need for Image-to-Image Translation</a> by Wang et. al.&nbsp;</p>
<p>Our normalizations are similar in spirit to the <code>Dynamic Thresholding</code> in the <a href="https://arxiv.org/abs/2205.11487">Imagen paper</a>.</p>
</div>
</div>
</section>
</section>
<section id="normalizing-the-guidance" class="level2">
<h2 class="anchored" data-anchor-id="normalizing-the-guidance">Normalizing the guidance</h2>
<p>This notebook explores two types of normalization we call <code>BaseNorm</code> and <code>T-Norm</code>:</p>
<ul>
<li><p><code>BaseNorm</code>: Normalize the entire prediction by the ratio of the conditioned and unconditioned norms.<br>
<img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cepsilon%7D(x%20%5C%20%7C%5C%20%20y)_%5Ctext%7BBaseNorm%7D%20=%20%5Chat%7B%5Cepsilon%7D(x%20%5C%20%7C%5C%20%20y)%5Ccdot%20%5Cfrac%7B%5C%7C%5Cepsilon(x)%5C%7C%7D%7B%5C%7C%5Cepsilon(x%20%5C%20%7C%5C%20%20y)%5C%7C%7D"></p></li>
<li><p><code>T-Norm</code>: Normalize the difference of the conditioned and unconditioned predictions. <img src="https://latex.codecogs.com/png.latex?%5Chat%7B%5Cepsilon%7D(x%20%5C%20%7C%5C%20%20y)_%5Ctext%7BTNorm%7D%20=%20%5Cepsilon(x)%20+%20G%5C%20%5Cfrac%7B%5Cepsilon(x%20%5C%20%7C%5C%20%20y)%20-%20%5Cepsilon(x)%7D%7B%5C%7C%5Cepsilon(x%20%5C%20%7C%5C%20%20y)%20-%20%5Cepsilon(x)%5C%7C%5Ccdot%20%5C%7C%5Cepsilon(x)%5C%7C%7D"></p></li>
</ul>
</section>
<section id="scheduling-the-guidance" class="level2">
<h2 class="anchored" data-anchor-id="scheduling-the-guidance">Scheduling the guidance</h2>
<p>In standard CFG the guidance scaling value is fixed. But since the final and initial images are so different, should we expect that the same value is optimal for the entire time?</p>
<p>To explore this question we can borrow from Neural Network optimizers. Specifically, our idea of a “guidance schedule” is based on the popular schedules for learning rates.</p>
<p>This notebook explores two new schedules for the CFG parameter <img src="https://latex.codecogs.com/png.latex?G">:</p>
<ul>
<li>Cosine<br>
</li>
<li>Cosine with Warmup.</li>
</ul>
</section>
<section id="combining-the-changes" class="level2">
<h2 class="anchored" data-anchor-id="combining-the-changes">Combining the changes</h2>
<p>The natural idea is to combine these approaches: we should both normalize <em>and</em> schedule <img src="https://latex.codecogs.com/png.latex?G">.</p>
<p>After exploring each change in isolation we combine them to see their joint effects.</p>
</section>
</section>
<section id="coding-setup" class="level1">
<h1>Coding Setup</h1>
<section id="python-imports" class="level2">
<h2 class="anchored" data-anchor-id="python-imports">Python imports</h2>
<p>First we import the python, PyTorch, and HuggingFace modules that we need. We also use the <code>timm</code> library for its built-in Cosine schedules.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> os</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> math</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">import</span> random</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> warnings</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">from</span> PIL <span class="im" style="color: #00769E;">import</span> Image</span>
<span id="cb1-6"><span class="im" style="color: #00769E;">from</span> typing <span class="im" style="color: #00769E;">import</span> List</span>
<span id="cb1-7"><span class="im" style="color: #00769E;">from</span> pathlib <span class="im" style="color: #00769E;">import</span> Path</span>
<span id="cb1-8"><span class="im" style="color: #00769E;">from</span> types <span class="im" style="color: #00769E;">import</span> SimpleNamespace</span>
<span id="cb1-9"></span>
<span id="cb1-10"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-11"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb1-12"><span class="im" style="color: #00769E;">from</span> textwrap <span class="im" style="color: #00769E;">import</span> wrap</span>
<span id="cb1-13"><span class="im" style="color: #00769E;">from</span> tqdm.auto <span class="im" style="color: #00769E;">import</span> tqdm </span>
<span id="cb1-14"></span>
<span id="cb1-15"><span class="co" style="color: #5E5E5E;"># imports for diffusion models</span></span>
<span id="cb1-16"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb1-17"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> logging</span>
<span id="cb1-18"><span class="im" style="color: #00769E;">from</span> transformers <span class="im" style="color: #00769E;">import</span> CLIPTextModel, CLIPTokenizer</span>
<span id="cb1-19"><span class="im" style="color: #00769E;">from</span> huggingface_hub <span class="im" style="color: #00769E;">import</span> notebook_login</span>
<span id="cb1-20"><span class="im" style="color: #00769E;">from</span> diffusers <span class="im" style="color: #00769E;">import</span> StableDiffusionPipeline</span>
<span id="cb1-21"><span class="im" style="color: #00769E;">from</span> diffusers <span class="im" style="color: #00769E;">import</span> AutoencoderKL, UNet2DConditionModel</span>
<span id="cb1-22"><span class="im" style="color: #00769E;">from</span> diffusers <span class="im" style="color: #00769E;">import</span> LMSDiscreteScheduler</span>
<span id="cb1-23"></span>
<span id="cb1-24"><span class="co" style="color: #5E5E5E;"># use cosine scheduler from timm</span></span>
<span id="cb1-25"><span class="im" style="color: #00769E;">from</span> timm.scheduler.cosine_lr <span class="im" style="color: #00769E;">import</span> CosineLRScheduler</span>
<span id="cb1-26"><span class="im" style="color: #00769E;">from</span> timm.optim <span class="im" style="color: #00769E;">import</span> create_optimizer</span>
<span id="cb1-27"><span class="im" style="color: #00769E;">from</span> timm <span class="im" style="color: #00769E;">import</span> create_model</span>
<span id="cb1-28"></span>
<span id="cb1-29"><span class="co" style="color: #5E5E5E;"># for clean outputs</span></span>
<span id="cb1-30">warnings.filterwarnings(<span class="st" style="color: #20794D;">"ignore"</span>)</span>
<span id="cb1-31">logging.set_verbosity_error()</span>
<span id="cb1-32"></span>
<span id="cb1-33"><span class="co" style="color: #5E5E5E;"># set the hardware device</span></span>
<span id="cb1-34">device <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"cuda"</span> <span class="cf" style="color: #003B4F;">if</span> torch.cuda.is_available() <span class="cf" style="color: #003B4F;">else</span> <span class="st" style="color: #20794D;">"mps"</span> <span class="cf" style="color: #003B4F;">if</span> torch.has_mps <span class="cf" style="color: #003B4F;">else</span> <span class="st" style="color: #20794D;">"cpu"</span></span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>2022-11-20 19:51:47.940762: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0</code></pre>
</div>
</div>
</section>
<section id="prompt-for-image-generations" class="level2">
<h2 class="anchored" data-anchor-id="prompt-for-image-generations">Prompt for image generations</h2>
<p>We use the following prompt to test our guidance changes:</p>
<blockquote class="blockquote">
<p>“a photograph of an astronaut riding a horse”</p>
</blockquote>
<p>This is the same prompt folks used in the forums. It seems like a good, simple starting point for future runs.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;"># the input prompt for diffusion</span></span>
<span id="cb3-2">prompt <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"a photograph of an astronaut riding a horse"</span></span></code></pre></div>
</div>
</section>
<section id="picking-a-diffusion-model" class="level2">
<h2 class="anchored" data-anchor-id="picking-a-diffusion-model">Picking a Diffusion model</h2>
<p>We also have to pick a Diffusion model. Some possible options are:</p>
<ul>
<li><code>stable-Diffusion-v1-4</code> from CompVis.<br>
</li>
<li><code>stable-Diffusion v1-5</code> from Runway.ml.</li>
</ul>
<p>Here we use the Stable Diffusion <code>v1-4</code> model from CompVis.</p>
<p>But it is worth mentioning that this code will work with any Diffusion model name on the HuggingFace hub.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;"># set the diffusion model</span></span>
<span id="cb4-2">model_name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"CompVis/stable-diffusion-v1-4"</span> <span class="co" style="color: #5E5E5E;"># "runwayml/stable-diffusion-v1-5"</span></span></code></pre></div>
</div>
</section>
<section id="utility-functions." class="level2">
<h2 class="anchored" data-anchor-id="utility-functions.">Utility functions.</h2>
<p>Next we define some helper functions.</p>
<p>These helpers create the text embeddings, convert latent features into images, and plot the decoded images. All of these functions are directly from Fahim’s notebook.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="kw" style="color: #003B4F;">def</span> text_embeddings(prompts, maxlen<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb5-2">    <span class="co" style="color: #5E5E5E;">"Extracts text embeddings from the given `prompts`."</span></span>
<span id="cb5-3">    maxlen <span class="op" style="color: #5E5E5E;">=</span> maxlen <span class="kw" style="color: #003B4F;">or</span> tokenizer.model_max_length</span>
<span id="cb5-4">    inp <span class="op" style="color: #5E5E5E;">=</span> tokenizer(prompts, padding<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"max_length"</span>, max_length<span class="op" style="color: #5E5E5E;">=</span>maxlen, truncation<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, return_tensors<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"pt"</span>)</span>
<span id="cb5-5">    <span class="cf" style="color: #003B4F;">return</span> text_encoder(inp.input_ids.to(device))[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb5-6"></span>
<span id="cb5-7"></span>
<span id="cb5-8"><span class="kw" style="color: #003B4F;">def</span> image_from_latents(latents):</span>
<span id="cb5-9">    <span class="co" style="color: #5E5E5E;">"Scales the diffusion `latents` and turns them into a PIL Image."</span></span>
<span id="cb5-10">    </span>
<span id="cb5-11">    <span class="co" style="color: #5E5E5E;"># scale and decode the latents</span></span>
<span id="cb5-12">    latents <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span> <span class="op" style="color: #5E5E5E;">/</span> <span class="fl" style="color: #AD0000;">0.18215</span> <span class="op" style="color: #5E5E5E;">*</span> latents</span>
<span id="cb5-13">    <span class="cf" style="color: #003B4F;">with</span> torch.no_grad():</span>
<span id="cb5-14">        data <span class="op" style="color: #5E5E5E;">=</span> vae.decode(latents).sample[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb5-15"></span>
<span id="cb5-16">    <span class="co" style="color: #5E5E5E;"># Create PIL image</span></span>
<span id="cb5-17">    data <span class="op" style="color: #5E5E5E;">=</span> (data <span class="op" style="color: #5E5E5E;">/</span> <span class="dv" style="color: #AD0000;">2</span> <span class="op" style="color: #5E5E5E;">+</span> <span class="fl" style="color: #AD0000;">0.5</span>).clamp(<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb5-18">    data <span class="op" style="color: #5E5E5E;">=</span> data.cpu().permute(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="dv" style="color: #AD0000;">0</span>).<span class="bu" style="color: null;">float</span>().numpy()</span>
<span id="cb5-19">    data <span class="op" style="color: #5E5E5E;">=</span> (data <span class="op" style="color: #5E5E5E;">*</span> <span class="dv" style="color: #AD0000;">255</span>).<span class="bu" style="color: null;">round</span>().astype(<span class="st" style="color: #20794D;">"uint8"</span>)</span>
<span id="cb5-20">    image <span class="op" style="color: #5E5E5E;">=</span> Image.fromarray(data)</span>
<span id="cb5-21">    <span class="cf" style="color: #003B4F;">return</span> image</span>
<span id="cb5-22">    </span>
<span id="cb5-23">    </span>
<span id="cb5-24"><span class="kw" style="color: #003B4F;">def</span> show_image(image, scale<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.5</span>):</span>
<span id="cb5-25">    <span class="co" style="color: #5E5E5E;">"Displays the given `image` resized based on `scale`."</span></span>
<span id="cb5-26">    img <span class="op" style="color: #5E5E5E;">=</span> image.resize(((<span class="bu" style="color: null;">int</span>)(image.width <span class="op" style="color: #5E5E5E;">*</span> scale), (<span class="bu" style="color: null;">int</span>)(image.height <span class="op" style="color: #5E5E5E;">*</span> scale)))</span>
<span id="cb5-27">    display(img)</span>
<span id="cb5-28">    <span class="cf" style="color: #003B4F;">return</span> img</span>
<span id="cb5-29"></span>
<span id="cb5-30"></span>
<span id="cb5-31"><span class="kw" style="color: #003B4F;">def</span> image_grid(images, rows <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span>, width<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">256</span>, height<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">256</span>, title<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb5-32">    <span class="co" style="color: #5E5E5E;">"Display an array of images in a nice grid, or single row"</span></span>
<span id="cb5-33">    count <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">len</span>(images)</span>
<span id="cb5-34">    cols <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">int</span>(count <span class="op" style="color: #5E5E5E;">/</span> rows)</span>
<span id="cb5-35">    <span class="cf" style="color: #003B4F;">if</span> cols <span class="op" style="color: #5E5E5E;">*</span> rows <span class="op" style="color: #5E5E5E;">&lt;</span> count:</span>
<span id="cb5-36">        rows <span class="op" style="color: #5E5E5E;">+=</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb5-37">    <span class="co" style="color: #5E5E5E;"># Calculate fig size based on individual image sizes    </span></span>
<span id="cb5-38">    px <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">/</span>plt.rcParams[<span class="st" style="color: #20794D;">'figure.dpi'</span>]</span>
<span id="cb5-39">    w <span class="op" style="color: #5E5E5E;">=</span> cols <span class="op" style="color: #5E5E5E;">*</span> width <span class="op" style="color: #5E5E5E;">*</span> px</span>
<span id="cb5-40">    <span class="co" style="color: #5E5E5E;"># Add some extra space for the caption/title since that can wrap</span></span>
<span id="cb5-41">    h <span class="op" style="color: #5E5E5E;">=</span> (rows <span class="op" style="color: #5E5E5E;">*</span> height <span class="op" style="color: #5E5E5E;">*</span> px) <span class="op" style="color: #5E5E5E;">+</span> (rows <span class="op" style="color: #5E5E5E;">*</span> <span class="dv" style="color: #AD0000;">30</span> <span class="op" style="color: #5E5E5E;">*</span> px)</span>
<span id="cb5-42">    fig, axes <span class="op" style="color: #5E5E5E;">=</span> plt.subplots(rows, cols, figsize<span class="op" style="color: #5E5E5E;">=</span>(w, h))</span>
<span id="cb5-43">    <span class="cf" style="color: #003B4F;">for</span> y <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(rows):</span>
<span id="cb5-44">        <span class="cf" style="color: #003B4F;">for</span> x <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(cols):</span>
<span id="cb5-45">            index <span class="op" style="color: #5E5E5E;">=</span> y<span class="op" style="color: #5E5E5E;">*</span>cols <span class="op" style="color: #5E5E5E;">+</span> x</span>
<span id="cb5-46">            ref <span class="op" style="color: #5E5E5E;">=</span> axes[x] <span class="cf" style="color: #003B4F;">if</span> rows <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">1</span> <span class="cf" style="color: #003B4F;">else</span> axes[y] <span class="cf" style="color: #003B4F;">if</span> cols <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">1</span> <span class="cf" style="color: #003B4F;">else</span> axes[y, x]</span>
<span id="cb5-47">            ref.axis(<span class="st" style="color: #20794D;">'off'</span>)</span>
<span id="cb5-48">            <span class="cf" style="color: #003B4F;">if</span> index <span class="op" style="color: #5E5E5E;">&gt;</span> count <span class="op" style="color: #5E5E5E;">-</span> <span class="dv" style="color: #AD0000;">1</span>:</span>
<span id="cb5-49">                <span class="cf" style="color: #003B4F;">continue</span></span>
<span id="cb5-50">            img <span class="op" style="color: #5E5E5E;">=</span> images[index]</span>
<span id="cb5-51">            txt <span class="op" style="color: #5E5E5E;">=</span> <span class="ss" style="color: #20794D;">f'Frame: </span><span class="sc" style="color: #5E5E5E;">{</span>index<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb5-52">            <span class="cf" style="color: #003B4F;">if</span> title <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb5-53">                <span class="cf" style="color: #003B4F;">if</span> <span class="bu" style="color: null;">isinstance</span>(title, <span class="bu" style="color: null;">str</span>):</span>
<span id="cb5-54">                    txt <span class="op" style="color: #5E5E5E;">=</span> <span class="ss" style="color: #20794D;">f'</span><span class="sc" style="color: #5E5E5E;">{</span>title<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">: </span><span class="sc" style="color: #5E5E5E;">{</span>index<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb5-55">                <span class="cf" style="color: #003B4F;">elif</span> <span class="bu" style="color: null;">isinstance</span>(title, List):</span>
<span id="cb5-56">                    txt <span class="op" style="color: #5E5E5E;">=</span> title[index]</span>
<span id="cb5-57">            <span class="co" style="color: #5E5E5E;"># small change for bigger, more visible titles</span></span>
<span id="cb5-58">            txt <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">'</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">'</span>.join(wrap(txt, width<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">70</span>))</span>
<span id="cb5-59">            ref.set_title(txt, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'x-large'</span>)</span>
<span id="cb5-60">            ref.imshow(img)</span>
<span id="cb5-61">            ref.axis(<span class="st" style="color: #20794D;">'off'</span>)</span>
<span id="cb5-62">            </span></code></pre></div>
</div>
</section>
</section>
<section id="splitting-the-diffusion-pipeline." class="level1">
<h1>Splitting the Diffusion pipeline.</h1>
<p>To test our hypotheses we need to change the parameter <img src="https://latex.codecogs.com/png.latex?G"> during diffusion.</p>
<p>That means we need more control than what is available via HuggingFace’s <code>pipeline</code> API.</p>
<p>We can achieve this finer control by separately loading each piece of the Stable Diffusion pipeline. Then, we can use these pieces to write our own image generation loop.</p>
<p>The function <code>get_sd_pieces()</code> returns the following pieces for a given Diffusion model:</p>
<ul>
<li>Tokenizer.</li>
<li>Text Encoder.<br>
</li>
<li>Variational Auto-Encoder (VAE).<br>
</li>
<li>U-Net.<br>
</li>
<li>Sampler.</li>
</ul>
<blockquote class="blockquote">
<p>Note: We are using a different <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BVAE%7D"> from <code>stability.ai</code> that was fine-tuned for more steps.</p>
</blockquote>
<div class="cell">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="kw" style="color: #003B4F;">def</span> get_sd_pieces(model_name, dtype<span class="op" style="color: #5E5E5E;">=</span>torch.float32):</span>
<span id="cb6-2">    <span class="co" style="color: #5E5E5E;">"Loads and returns the individual pieces in a Diffusion pipeline."</span></span>
<span id="cb6-3">    </span>
<span id="cb6-4">    <span class="co" style="color: #5E5E5E;"># create the tokenizer and text encoder</span></span>
<span id="cb6-5">    tokenizer <span class="op" style="color: #5E5E5E;">=</span> CLIPTokenizer.from_pretrained(</span>
<span id="cb6-6">        model_name,</span>
<span id="cb6-7">        subfolder<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"tokenizer"</span>,</span>
<span id="cb6-8">        torch_dtype<span class="op" style="color: #5E5E5E;">=</span>dtype)</span>
<span id="cb6-9">    text_encoder <span class="op" style="color: #5E5E5E;">=</span> CLIPTextModel.from_pretrained(</span>
<span id="cb6-10">        model_name,</span>
<span id="cb6-11">        subfolder<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"text_encoder"</span>,</span>
<span id="cb6-12">        torch_dtype<span class="op" style="color: #5E5E5E;">=</span>dtype).to(device)</span>
<span id="cb6-13"></span>
<span id="cb6-14">    <span class="co" style="color: #5E5E5E;"># we are using a VAE from stability that was trained for longer than the baseline </span></span>
<span id="cb6-15">    vae <span class="op" style="color: #5E5E5E;">=</span> AutoencoderKL.from_pretrained(<span class="st" style="color: #20794D;">"stabilityai/sd-vae-ft-ema"</span>, torch_dtype<span class="op" style="color: #5E5E5E;">=</span>dtype).to(device)</span>
<span id="cb6-16">    <span class="co" style="color: #5E5E5E;">## </span><span class="al" style="color: #AD0000;">NOTE</span><span class="co" style="color: #5E5E5E;">: we can also use these vae from Stability that were trained for even longer</span></span>
<span id="cb6-17">    <span class="co" style="color: #5E5E5E;">#vae = AutoencoderKL.from_pretrained("stabilityai/sd-vae-ft-mse", torch_dtype=dtype).to(device)</span></span>
<span id="cb6-18">    </span>
<span id="cb6-19">    <span class="co" style="color: #5E5E5E;"># build the unet</span></span>
<span id="cb6-20">    unet <span class="op" style="color: #5E5E5E;">=</span> UNet2DConditionModel.from_pretrained(</span>
<span id="cb6-21">        model_name,</span>
<span id="cb6-22">        subfolder<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"unet"</span>,</span>
<span id="cb6-23">        torch_dtype<span class="op" style="color: #5E5E5E;">=</span>dtype).to(device)</span>
<span id="cb6-24">    </span>
<span id="cb6-25">    <span class="co" style="color: #5E5E5E;"># enable unet attention slicing</span></span>
<span id="cb6-26">    slice_size <span class="op" style="color: #5E5E5E;">=</span> unet.config.attention_head_dim <span class="op" style="color: #5E5E5E;">//</span> <span class="dv" style="color: #AD0000;">2</span></span>
<span id="cb6-27">    unet.set_attention_slice(slice_size)</span>
<span id="cb6-28">        </span>
<span id="cb6-29">    <span class="co" style="color: #5E5E5E;"># build the scheduler</span></span>
<span id="cb6-30">    scheduler <span class="op" style="color: #5E5E5E;">=</span> LMSDiscreteScheduler.from_config(model_name, subfolder<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"scheduler"</span>)</span>
<span id="cb6-31">    </span>
<span id="cb6-32">    <span class="cf" style="color: #003B4F;">return</span> (</span>
<span id="cb6-33">        tokenizer,</span>
<span id="cb6-34">        text_encoder,</span>
<span id="cb6-35">        vae,</span>
<span id="cb6-36">        unet,</span>
<span id="cb6-37">        scheduler,</span>
<span id="cb6-38">    )</span>
<span id="cb6-39"></span>
<span id="cb6-40"></span>
<span id="cb6-41"><span class="co" style="color: #5E5E5E;"># load the individual diffusion pieces</span></span>
<span id="cb6-42">pieces <span class="op" style="color: #5E5E5E;">=</span> get_sd_pieces(model_name, dtype<span class="op" style="color: #5E5E5E;">=</span>torch.float16)</span>
<span id="cb6-43">(tokenizer, text_encoder, vae, unet, scheduler) <span class="op" style="color: #5E5E5E;">=</span> pieces</span></code></pre></div>
</div>
</section>
<section id="cosine-schedules-from-timm" class="level1">
<h1>Cosine schedules from <code>timm</code></h1>
<p>We test two different schedules for <img src="https://latex.codecogs.com/png.latex?G">:</p>
<ul>
<li>Cosine schedule.<br>
</li>
<li>Cosine with Warmup.</li>
</ul>
<p>The HuggingFace <code>pipeline</code> uses 50 diffusion timesteps by default. To keep things comparable, we also use 50 steps.</p>
<p>The Cosine schedule starts from the default <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bmax%7D%20=%207.5">. It then slowly works down to a minimum of <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bmin%7D%20=%200.15">.</p>
<p>We also make a schedule with Warmup. Warmup means that <img src="https://latex.codecogs.com/png.latex?G"> first starts low, then linearly works its way up to <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bmax%7D">. Only then does it start decreasing back down to <img src="https://latex.codecogs.com/png.latex?G_%5Ctext%7Bmin%7D">. As a starting point, we warmup during the first 10% of the Diffusion process (aka during the first 5 steps).</p>
<p>For T-Norm, we use a slightly different Cosine schedule with smaller values. We need this because a large <img src="https://latex.codecogs.com/png.latex?G"> with T-Norm makes the problem we are trying to solve (<img src="https://latex.codecogs.com/png.latex?G"> too large) even worse. The smaller T-Norm values also align much better with how we typically think about mixing or moving averages.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="co" style="color: #5E5E5E;"># parameters for CFG cosine schedules</span></span>
<span id="cb7-2">max_g <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">7.5</span></span>
<span id="cb7-3">min_g <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.15</span></span>
<span id="cb7-4">num_steps <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">50</span></span>
<span id="cb7-5"></span>
<span id="cb7-6"><span class="co" style="color: #5E5E5E;"># warmup from the minimum over 10% of the process</span></span>
<span id="cb7-7">warmup_ratio <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.10</span>  </span>
<span id="cb7-8">warmup_start <span class="op" style="color: #5E5E5E;">=</span> min_g</span>
<span id="cb7-9"></span>
<span id="cb7-10"></span>
<span id="cb7-11"><span class="co" style="color: #5E5E5E;"># cosine schedule parameters</span></span>
<span id="cb7-12">cos_params <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb7-13">    <span class="st" style="color: #20794D;">'max_val'</span>:         max_g,</span>
<span id="cb7-14">    <span class="st" style="color: #20794D;">'num_steps'</span>:       num_steps,</span>
<span id="cb7-15">    <span class="st" style="color: #20794D;">'min_val'</span>:         warmup_start,</span>
<span id="cb7-16">    <span class="st" style="color: #20794D;">'warmup_fact'</span>:     <span class="dv" style="color: #AD0000;">0</span>,</span>
<span id="cb7-17">}</span>
<span id="cb7-18"></span>
<span id="cb7-19"><span class="co" style="color: #5E5E5E;"># warmup-cosine parameters</span></span>
<span id="cb7-20">warmup_cos_params <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb7-21">    <span class="st" style="color: #20794D;">'max_val'</span>:         max_g,</span>
<span id="cb7-22">    <span class="st" style="color: #20794D;">'warmup_start'</span>:    warmup_start,</span>
<span id="cb7-23">    <span class="st" style="color: #20794D;">'num_steps'</span>:       num_steps,</span>
<span id="cb7-24">    <span class="st" style="color: #20794D;">'min_val'</span>:         warmup_start,</span>
<span id="cb7-25">    <span class="st" style="color: #20794D;">'warmup_init_val'</span>: warmup_start,</span>
<span id="cb7-26">    <span class="st" style="color: #20794D;">'warmup_fact'</span>:     warmup_ratio,</span>
<span id="cb7-27">}</span>
<span id="cb7-28"></span>
<span id="cb7-29"><span class="co" style="color: #5E5E5E;"># cosine schedule for T-Norm guidance</span></span>
<span id="cb7-30">t_scale_params <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb7-31">    <span class="st" style="color: #20794D;">'max_val'</span>:         <span class="fl" style="color: #AD0000;">0.25</span>,</span>
<span id="cb7-32">    <span class="st" style="color: #20794D;">'num_steps'</span>:       num_steps,</span>
<span id="cb7-33">    <span class="st" style="color: #20794D;">'min_val'</span>:         <span class="fl" style="color: #AD0000;">0.05</span>,</span>
<span id="cb7-34">}</span></code></pre></div>
</div>
<p>We use the Cosine scheduler in <code>timm</code> for convenience.</p>
<p>That means we need a bit of overhead code. Mainly, we need a dummy PyTorch optimizer and module.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;"># create dummy model</span></span>
<span id="cb8-2">model <span class="op" style="color: #5E5E5E;">=</span> torch.nn.Linear(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb8-3"></span>
<span id="cb8-4"><span class="co" style="color: #5E5E5E;"># arguments for the dummy optimizer</span></span>
<span id="cb8-5">default_opt_args <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb8-6">    <span class="st" style="color: #20794D;">'opt'</span>:           <span class="st" style="color: #20794D;">'adam'</span>,</span>
<span id="cb8-7">    <span class="st" style="color: #20794D;">'momentum'</span>:      <span class="fl" style="color: #AD0000;">1.0</span>,</span>
<span id="cb8-8">    <span class="st" style="color: #20794D;">'weight_decay'</span>:  <span class="dv" style="color: #AD0000;">0</span>,</span>
<span id="cb8-9">}</span>
<span id="cb8-10"></span>
<span id="cb8-11"></span>
<span id="cb8-12"><span class="kw" style="color: #003B4F;">def</span> get_cos_sched(<span class="op" style="color: #5E5E5E;">**</span>sched_params):</span>
<span id="cb8-13">    <span class="co" style="color: #5E5E5E;">"""Creates a Cosine schedule using the `timm` library."""</span></span>
<span id="cb8-14">    <span class="co" style="color: #5E5E5E;"># number of diffusion iterations</span></span>
<span id="cb8-15">    num_steps <span class="op" style="color: #5E5E5E;">=</span> sched_params[<span class="st" style="color: #20794D;">'num_steps'</span>]</span>
<span id="cb8-16">    </span>
<span id="cb8-17">    min_val, max_val <span class="op" style="color: #5E5E5E;">=</span> sched_params[<span class="st" style="color: #20794D;">'min_val'</span>], sched_params[<span class="st" style="color: #20794D;">'max_val'</span>]</span>
<span id="cb8-18">    </span>
<span id="cb8-19">    <span class="co" style="color: #5E5E5E;"># compute number of warmup steps, if given</span></span>
<span id="cb8-20">    <span class="cf" style="color: #003B4F;">if</span> sched_params.get(<span class="st" style="color: #20794D;">'warmup_fact'</span>):</span>
<span id="cb8-21">        warmup_t <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">int</span>(num_steps <span class="op" style="color: #5E5E5E;">*</span> sched_params[<span class="st" style="color: #20794D;">'warmup_fact'</span>])</span>
<span id="cb8-22">        warmup_init_val <span class="op" style="color: #5E5E5E;">=</span> sched_params.get(<span class="st" style="color: #20794D;">'warmup_init_val'</span>, <span class="dv" style="color: #AD0000;">0</span>)</span>
<span id="cb8-23">    <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb8-24">        warmup_t <span class="op" style="color: #5E5E5E;">=</span> warmup_init_val <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb8-25">    </span>
<span id="cb8-26">    <span class="co" style="color: #5E5E5E;"># get the dummy optimizer for the timm scheduler</span></span>
<span id="cb8-27">    opt_args <span class="op" style="color: #5E5E5E;">=</span> SimpleNamespace(lr<span class="op" style="color: #5E5E5E;">=</span>max_val, <span class="op" style="color: #5E5E5E;">**</span>default_opt_args)</span>
<span id="cb8-28">    optimizer <span class="op" style="color: #5E5E5E;">=</span> create_optimizer(opt_args, model)</span>
<span id="cb8-29">      </span>
<span id="cb8-30">    <span class="co" style="color: #5E5E5E;"># create the cosine schedule</span></span>
<span id="cb8-31">    lr_sched <span class="op" style="color: #5E5E5E;">=</span> CosineLRScheduler(</span>
<span id="cb8-32">        optimizer,</span>
<span id="cb8-33">        t_initial<span class="op" style="color: #5E5E5E;">=</span>num_steps,</span>
<span id="cb8-34">        lr_min<span class="op" style="color: #5E5E5E;">=</span>min_val,</span>
<span id="cb8-35">        warmup_t<span class="op" style="color: #5E5E5E;">=</span>warmup_t,</span>
<span id="cb8-36">        warmup_lr_init<span class="op" style="color: #5E5E5E;">=</span>warmup_init_val,</span>
<span id="cb8-37">    )</span>
<span id="cb8-38"></span>
<span id="cb8-39">    <span class="co" style="color: #5E5E5E;"># extract and return the CFG values at each iteration</span></span>
<span id="cb8-40">    cfg_per_step <span class="op" style="color: #5E5E5E;">=</span> [lr_sched.get_epoch_values(step)[<span class="dv" style="color: #AD0000;">0</span>] <span class="cf" style="color: #003B4F;">for</span> step <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(num_steps)]</span>
<span id="cb8-41">    <span class="cf" style="color: #003B4F;">return</span> cfg_per_step</span></code></pre></div>
</div>
<p>Now that we have both the parameters and builder functions for Cosine schedules, we can create them:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="co" style="color: #5E5E5E;"># baseline cosine guidance schedule</span></span>
<span id="cb9-2">cos_g <span class="op" style="color: #5E5E5E;">=</span> get_cos_sched(<span class="op" style="color: #5E5E5E;">**</span>cos_params)</span>
<span id="cb9-3"></span>
<span id="cb9-4"><span class="co" style="color: #5E5E5E;"># cosine schedule with warmup </span></span>
<span id="cb9-5">warmup_cos_g <span class="op" style="color: #5E5E5E;">=</span> get_cos_sched(<span class="op" style="color: #5E5E5E;">**</span>warmup_cos_params)</span>
<span id="cb9-6"></span>
<span id="cb9-7"><span class="co" style="color: #5E5E5E;"># cosine schedule with smaller G values for T-Norm</span></span>
<span id="cb9-8">t_scale_cos_g <span class="op" style="color: #5E5E5E;">=</span> get_cos_sched(<span class="op" style="color: #5E5E5E;">**</span>t_scale_params)</span></code></pre></div>
</div>
<section id="plotting-the-cosine-schedules" class="level2">
<h2 class="anchored" data-anchor-id="plotting-the-cosine-schedules">Plotting the Cosine schedules</h2>
<p>Let’s plot these new schedules to compare them against the previous, constant guidance.</p>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-15-guidance-expts-1/index_files/figure-html/cell-11-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="the-guidance-transform-class" class="level1">
<h1>The Guidance Transform class</h1>
<p>Here we create the Guidance Transformation class, <code>GuidanceTfm</code>. This class is heavily inspired by other <a href="https://fastai1.fast.ai/vision.transform.html">Transforms in the fast.ai library</a>.</p>
<p><code>GuidanceTfm</code> has an <code>encode()</code> method that takes the following inputs:</p>
<table class="table">
<thead>
<tr class="header">
<th><strong>encode Argument</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><img src="https://latex.codecogs.com/png.latex?%5Cepsilon(x)"></td>
<td>Unconditioned latents</td>
</tr>
<tr class="even">
<td><img src="https://latex.codecogs.com/png.latex?%5Cepsilon(x%5C%20%7C%5C%20y)"></td>
<td>Conditional latents</td>
</tr>
<tr class="odd">
<td><img src="https://latex.codecogs.com/png.latex?%5Ctext%7Bidx%7D"></td>
<td>The current diffusion step</td>
</tr>
</tbody>
</table>
<p>For convenience we call the unconditioned latents “<img src="https://latex.codecogs.com/png.latex?%5Ctext%7Bu%7D">” and the conditioned latents “<img src="https://latex.codecogs.com/png.latex?%5Ctext%7Bt%7D">”.</p>
<p>The base class applies a standard CFG update. However, there are also methods to pre and post process the latents. The goal of these other methods is to easily try different and custom normalizations. For example, we can implement all of our normalization ideas with these methods.</p>
<p>Lastly, <code>GuidanceTfm</code> takes one initialization parameter: <code>schedules</code>. This is a dictionary that maps a parameter name to an array-like, indexable sequence of values. This sequence is how we tap in to the scheduled <img src="https://latex.codecogs.com/png.latex?G"> value at timestep <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Bidx%7D">. And if we ever want to include or schedule other parameters, we can add them to <code>schedules</code> and access them in any of the <code>encode()</code> functions.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="kw" style="color: #003B4F;">class</span> GuidanceTfm:</span>
<span id="cb10-2">    <span class="co" style="color: #5E5E5E;">"Baseline Classifier-free Guidance for Difussion."</span></span>
<span id="cb10-3">    name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"CFGuidance"</span></span>
<span id="cb10-4">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, schedules, <span class="op" style="color: #5E5E5E;">*</span>args, <span class="op" style="color: #5E5E5E;">**</span>kwargs):</span>
<span id="cb10-5">        <span class="va" style="color: #111111;">self</span>.schedules <span class="op" style="color: #5E5E5E;">=</span> schedules</span>
<span id="cb10-6">        </span>
<span id="cb10-7">    <span class="kw" style="color: #003B4F;">def</span> encode(<span class="va" style="color: #111111;">self</span>, u, t, idx<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb10-8">        <span class="co" style="color: #5E5E5E;">"Applies guidance on `u` and `t` with optional pre/post processing."</span></span>
<span id="cb10-9">        <span class="va" style="color: #111111;">self</span>.pre_proc(u, t, idx)</span>
<span id="cb10-10">        <span class="va" style="color: #111111;">self</span>.guide(u, t, idx)</span>
<span id="cb10-11">        <span class="va" style="color: #111111;">self</span>.post_proc(u, t, idx)</span>
<span id="cb10-12">        <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">self</span>.pred</span>
<span id="cb10-13">    </span>
<span id="cb10-14">    <span class="kw" style="color: #003B4F;">def</span> guide(<span class="va" style="color: #111111;">self</span>, u, t, idx<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb10-15">        <span class="co" style="color: #5E5E5E;">"Mixes latents `u` and `t` based on guidance schedule for `g`."</span></span>
<span id="cb10-16">        <span class="va" style="color: #111111;">self</span>.pred <span class="op" style="color: #5E5E5E;">=</span> u <span class="op" style="color: #5E5E5E;">+</span> (<span class="va" style="color: #111111;">self</span>.scheduler(<span class="st" style="color: #20794D;">'g'</span>, idx) <span class="op" style="color: #5E5E5E;">*</span> (t <span class="op" style="color: #5E5E5E;">-</span> u))</span>
<span id="cb10-17"></span>
<span id="cb10-18">    <span class="kw" style="color: #003B4F;">def</span> pre_proc (<span class="va" style="color: #111111;">self</span>, u, t, idx<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>): <span class="cf" style="color: #003B4F;">pass</span></span>
<span id="cb10-19">    <span class="kw" style="color: #003B4F;">def</span> post_proc(<span class="va" style="color: #111111;">self</span>, u, t, idx<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>): <span class="cf" style="color: #003B4F;">pass</span></span>
<span id="cb10-20">    </span>
<span id="cb10-21">    <span class="kw" style="color: #003B4F;">def</span> scheduler(<span class="va" style="color: #111111;">self</span>, name, idx):</span>
<span id="cb10-22">        <span class="co" style="color: #5E5E5E;">"Gets the scheduled value for parameter `name` at timestep `idx`."</span></span>
<span id="cb10-23">        <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">self</span>.schedules.get(name)[idx]</span>
<span id="cb10-24">    </span>
<span id="cb10-25">    </span>
<span id="cb10-26"><span class="kw" style="color: #003B4F;">class</span> BaseNormGuidance(GuidanceTfm):</span>
<span id="cb10-27">    <span class="co" style="color: #5E5E5E;">"Scales the noise prediction by its overall norm."</span></span>
<span id="cb10-28">    name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"BaseNormGuidance"</span></span>
<span id="cb10-29">    <span class="kw" style="color: #003B4F;">def</span> post_proc(<span class="va" style="color: #111111;">self</span>, u, t, idx<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb10-30">        <span class="va" style="color: #111111;">self</span>.pred <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.pred <span class="op" style="color: #5E5E5E;">*</span> (torch.linalg.norm(u) <span class="op" style="color: #5E5E5E;">/</span> torch.linalg.norm(<span class="va" style="color: #111111;">self</span>.pred))</span>
<span id="cb10-31">        </span>
<span id="cb10-32">        </span>
<span id="cb10-33"><span class="kw" style="color: #003B4F;">class</span> TNormGuidance(GuidanceTfm):</span>
<span id="cb10-34">    <span class="co" style="color: #5E5E5E;">"Scales the latent mix of `t - u`"</span></span>
<span id="cb10-35">    name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"TNormGuidance"</span></span>
<span id="cb10-36">    <span class="kw" style="color: #003B4F;">def</span> guide(<span class="va" style="color: #111111;">self</span>, u, t, idx<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>):</span>
<span id="cb10-37">        <span class="va" style="color: #111111;">self</span>.pred <span class="op" style="color: #5E5E5E;">=</span> u <span class="op" style="color: #5E5E5E;">+</span> (<span class="va" style="color: #111111;">self</span>.scheduler(<span class="st" style="color: #20794D;">'g'</span>, idx) <span class="op" style="color: #5E5E5E;">*</span> (t <span class="op" style="color: #5E5E5E;">-</span> u)) <span class="op" style="color: #5E5E5E;">/</span> torch.linalg.norm(t <span class="op" style="color: #5E5E5E;">-</span> u) <span class="op" style="color: #5E5E5E;">*</span> torch.linalg.norm(u)</span>
<span id="cb10-38">        </span>
<span id="cb10-39">        </span>
<span id="cb10-40"><span class="kw" style="color: #003B4F;">class</span> FullNormGuidance(TNormGuidance, BaseNormGuidance):</span>
<span id="cb10-41">    <span class="co" style="color: #5E5E5E;">"Applies both Base and T-Norm on the noise prediction."</span></span>
<span id="cb10-42">    name <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"FullNormGuidance"</span></span>
<span id="cb10-43">    <span class="cf" style="color: #003B4F;">pass</span></span></code></pre></div>
</div>
</section>
<section id="creating-guidance-experiments" class="level1">
<h1>Creating guidance experiments</h1>
<p>Now that we have the transforms and schedules, we are finally ready to create some experiments!</p>
<section id="making-schedules-for-guidancetfm" class="level2">
<h2 class="anchored" data-anchor-id="making-schedules-for-guidancetfm">Making <code>schedules</code> for <code>GuidanceTfm</code></h2>
<p>We start with the following family of Guidance schedules:<br>
- Constant guidance with <img src="https://latex.codecogs.com/png.latex?%5Cleft(G%20=%207.5%5Cright)"><br>
- Constant guidance with <img src="https://latex.codecogs.com/png.latex?%5Cleft(G%20=%200.15%5Cright)"><br>
- A cosine schedule from <img src="https://latex.codecogs.com/png.latex?%5Cleft(G%20=%207.5%5Cright)"> down to <img src="https://latex.codecogs.com/png.latex?%5Cleft(G%20=%200.15%5Cright)"><br>
- A cosine schedule that warms up to <img src="https://latex.codecogs.com/png.latex?%5Cleft(G%20=%207.5%5Cright)"> over the first 10% of steps</p>
<p>For the T-Norm experiments, we also define a smaller-valued cosine schedule:<br>
- T-Norm cosine schedule from <img src="https://latex.codecogs.com/png.latex?%5Cleft(G%20=%200.25%5Cright)"> down to <img src="https://latex.codecogs.com/png.latex?%5Cleft(G%20=%200.05%5Cright)"></p>
<p>The schedule maps below will be the arguments to our <code>GuidanceTfm</code> instances.&nbsp;</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="co" style="color: #5E5E5E;"># baseline constant schedules with min and max values</span></span>
<span id="cb11-2">max_sched        <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'g'</span>: [max_g] <span class="op" style="color: #5E5E5E;">*</span> num_steps}</span>
<span id="cb11-3">min_sched        <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'g'</span>: [min_g] <span class="op" style="color: #5E5E5E;">*</span> num_steps}</span>
<span id="cb11-4"></span>
<span id="cb11-5"><span class="co" style="color: #5E5E5E;"># cosine schedules</span></span>
<span id="cb11-6">cos_sched        <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'g'</span>: cos_g}</span>
<span id="cb11-7">cos_warmup_sched <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'g'</span>: warmup_cos_g}</span>
<span id="cb11-8"></span>
<span id="cb11-9"><span class="co" style="color: #5E5E5E;"># normalized cosing schedules for T and Full-scale guidance</span></span>
<span id="cb11-10">small_cos_sched <span class="op" style="color: #5E5E5E;">=</span> {<span class="st" style="color: #20794D;">'g'</span>:  t_scale_cos_g}</span></code></pre></div>
</div>
</section>
<section id="recreating-the-forum-ideas" class="level2">
<h2 class="anchored" data-anchor-id="recreating-the-forum-ideas">Recreating the forum ideas</h2>
<p>First, let’s recreate the experiment baselines from the forums and Fahim’s notebook.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;"># stores the guidance experiements to run</span></span>
<span id="cb12-2">expts <span class="op" style="color: #5E5E5E;">=</span> {}</span>
<span id="cb12-3"></span>
<span id="cb12-4"></span>
<span id="cb12-5"><span class="co" style="color: #5E5E5E;">### RECREATE SCALING RUNS FROM fast.ai FORUM POSTS</span></span>
<span id="cb12-6"><span class="co" style="color: #5E5E5E;">#################################################</span></span>
<span id="cb12-7"><span class="co" style="color: #5E5E5E;">#################################################</span></span>
<span id="cb12-8">baseline        <span class="op" style="color: #5E5E5E;">=</span> GuidanceTfm(max_sched)       <span class="co" style="color: #5E5E5E;"># 1) No scaling, guidance fixed to 7.5</span></span>
<span id="cb12-9">scale_base_hi_g <span class="op" style="color: #5E5E5E;">=</span> BaseNormGuidance(max_sched)  <span class="co" style="color: #5E5E5E;"># 2) Scale the "whole" update</span></span>
<span id="cb12-10">scale_T_lo_g    <span class="op" style="color: #5E5E5E;">=</span> TNormGuidance(min_sched)     <span class="co" style="color: #5E5E5E;"># 3) Scale the update of "t"</span></span>
<span id="cb12-11">scale_all_hi_g  <span class="op" style="color: #5E5E5E;">=</span> FullNormGuidance(min_sched)  <span class="co" style="color: #5E5E5E;"># 4) Scale everything (steps 2 + 3)</span></span>
<span id="cb12-12"></span>
<span id="cb12-13"><span class="co" style="color: #5E5E5E;"># add baselines to the experiment list</span></span>
<span id="cb12-14">expts[<span class="ss" style="color: #20794D;">f'NoNorm_FixedG_</span><span class="sc" style="color: #5E5E5E;">{</span>max_g<span class="sc" style="color: #5E5E5E;">:.2f}</span><span class="ss" style="color: #20794D;">'</span>]   <span class="op" style="color: #5E5E5E;">=</span> baseline</span>
<span id="cb12-15">expts[<span class="ss" style="color: #20794D;">f'BaseNorm_FixedG_</span><span class="sc" style="color: #5E5E5E;">{</span>max_g<span class="sc" style="color: #5E5E5E;">:.2f}</span><span class="ss" style="color: #20794D;">'</span>] <span class="op" style="color: #5E5E5E;">=</span> scale_base_hi_g</span>
<span id="cb12-16">expts[<span class="ss" style="color: #20794D;">f'TNorm_FixedG_0</span><span class="sc" style="color: #5E5E5E;">{</span>min_g<span class="sc" style="color: #5E5E5E;">:.2f}</span><span class="ss" style="color: #20794D;">'</span>]   <span class="op" style="color: #5E5E5E;">=</span> scale_T_lo_g</span>
<span id="cb12-17">expts[<span class="ss" style="color: #20794D;">f'FullNorm_FixedG_</span><span class="sc" style="color: #5E5E5E;">{</span>min_g<span class="sc" style="color: #5E5E5E;">:.2f}</span><span class="ss" style="color: #20794D;">'</span>] <span class="op" style="color: #5E5E5E;">=</span> scale_all_hi_g</span>
<span id="cb12-18"><span class="co" style="color: #5E5E5E;">#################################################</span></span></code></pre></div>
</div>
</section>
<section id="combining-scales-and-schedules" class="level2">
<h2 class="anchored" data-anchor-id="combining-scales-and-schedules">Combining scales and schedules</h2>
<p>Next, we leverage our <code>GuidanceTfm</code> class to easily make new experiments.</p>
<p>We create the following:</p>
<ul>
<li>Default and BaseNorm Guidance with Cosine and Cosine Warmup schedules.</li>
<li>T-Norm and FullNorm Guidance with the smaller T-Cosine schedule.</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="co" style="color: #5E5E5E;"># group the cosine to run, and their names for plotting</span></span>
<span id="cb13-2">name2sched <span class="op" style="color: #5E5E5E;">=</span> {</span>
<span id="cb13-3">    <span class="st" style="color: #20794D;">'Cos'</span>:        cos_sched,</span>
<span id="cb13-4">    <span class="st" style="color: #20794D;">'CosWarmup'</span>:  cos_warmup_sched,</span>
<span id="cb13-5">    <span class="st" style="color: #20794D;">'TCos'</span>:       small_cos_sched,</span>
<span id="cb13-6">}</span>
<span id="cb13-7"></span>
<span id="cb13-8"></span>
<span id="cb13-9"><span class="co" style="color: #5E5E5E;"># T-Norm and FullNorm guidance with small T-Cosine</span></span>
<span id="cb13-10">norm_scalers <span class="op" style="color: #5E5E5E;">=</span> [TNormGuidance, FullNormGuidance]</span>
<span id="cb13-11"><span class="cf" style="color: #003B4F;">for</span> scaler <span class="kw" style="color: #003B4F;">in</span> norm_scalers:</span>
<span id="cb13-12">    </span>
<span id="cb13-13">    <span class="co" style="color: #5E5E5E;"># step through all cosine schedules</span></span>
<span id="cb13-14">    <span class="cf" style="color: #003B4F;">for</span> name <span class="kw" style="color: #003B4F;">in</span> [<span class="st" style="color: #20794D;">'TCos'</span>]:</span>
<span id="cb13-15"></span>
<span id="cb13-16">        <span class="co" style="color: #5E5E5E;"># experiment for this (scaling, schedule) pair</span></span>
<span id="cb13-17">        expt <span class="op" style="color: #5E5E5E;">=</span> scaler(name2sched[name])</span>
<span id="cb13-18">        <span class="co" style="color: #5E5E5E;"># unique name for this experiment</span></span>
<span id="cb13-19">        expt_name <span class="op" style="color: #5E5E5E;">=</span> <span class="ss" style="color: #20794D;">f'</span><span class="sc" style="color: #5E5E5E;">{</span>scaler<span class="sc" style="color: #5E5E5E;">.</span>name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">_Sched_</span><span class="sc" style="color: #5E5E5E;">{</span>name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb13-20"></span>
<span id="cb13-21">        <span class="co" style="color: #5E5E5E;"># add scaler to lists of experiments</span></span>
<span id="cb13-22">        expts[expt_name] <span class="op" style="color: #5E5E5E;">=</span> expt</span>
<span id="cb13-23"></span>
<span id="cb13-24">        </span>
<span id="cb13-25"><span class="co" style="color: #5E5E5E;"># Default and BaseNorm guidance with cosine schedules </span></span>
<span id="cb13-26">g_scalers <span class="op" style="color: #5E5E5E;">=</span> [GuidanceTfm, BaseNormGuidance]</span>
<span id="cb13-27"><span class="cf" style="color: #003B4F;">for</span> scaler <span class="kw" style="color: #003B4F;">in</span> g_scalers:</span>
<span id="cb13-28">    </span>
<span id="cb13-29">    <span class="co" style="color: #5E5E5E;"># step through all cosine schedules</span></span>
<span id="cb13-30">    <span class="cf" style="color: #003B4F;">for</span> name <span class="kw" style="color: #003B4F;">in</span> [<span class="st" style="color: #20794D;">'Cos'</span>, <span class="st" style="color: #20794D;">'CosWarmup'</span>]:</span>
<span id="cb13-31"></span>
<span id="cb13-32">        <span class="co" style="color: #5E5E5E;"># experiment for this (scaling, schedule) pair</span></span>
<span id="cb13-33">        expt <span class="op" style="color: #5E5E5E;">=</span> scaler(name2sched[name])</span>
<span id="cb13-34">        <span class="co" style="color: #5E5E5E;"># unique name for this experiment</span></span>
<span id="cb13-35">        expt_name <span class="op" style="color: #5E5E5E;">=</span> <span class="ss" style="color: #20794D;">f'</span><span class="sc" style="color: #5E5E5E;">{</span>scaler<span class="sc" style="color: #5E5E5E;">.</span>name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">_Sched_</span><span class="sc" style="color: #5E5E5E;">{</span>name<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span></span>
<span id="cb13-36"></span>
<span id="cb13-37">        <span class="co" style="color: #5E5E5E;"># add scaler to lists of experiments</span></span>
<span id="cb13-38">        expts[expt_name] <span class="op" style="color: #5E5E5E;">=</span> expt</span></code></pre></div>
</div>
<p>Here we print all of the queued experiments:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">"Guidance experiments to run:</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">"</span>)</span>
<span id="cb14-2"><span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">'</span>.join(<span class="ss" style="color: #20794D;">f'</span><span class="sc" style="color: #5E5E5E;">{</span>k<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span> <span class="cf" style="color: #003B4F;">for</span> k,_ <span class="kw" style="color: #003B4F;">in</span> expts.items()))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Guidance experiments to run:

NoNorm_FixedG_7.50
BaseNorm_FixedG_7.50
TNorm_FixedG_00.15
FullNorm_FixedG_0.15
TNormGuidance_Sched_TCos
FullNormGuidance_Sched_TCos
CFGuidance_Sched_Cos
CFGuidance_Sched_CosWarmup
BaseNormGuidance_Sched_Cos
BaseNormGuidance_Sched_CosWarmup</code></pre>
</div>
</div>
</section>
</section>
<section id="generating-images" class="level1">
<h1>Generating images</h1>
<p>We are almost there! Now we need a way to actually generate images.</p>
<p>The <code>generate()</code> function below is almost identical to the the <code>StableDiffusionPipeline()</code> from HuggingFace.</p>
<p>We make a few changes to ensure that the initial latents are the same between runs. That means that only the guidance schedule and/or normalization affects the outputs.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="co" style="color: #5E5E5E;"># create the shared, initial latents</span></span>
<span id="cb16-2">width, height <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">512</span>, <span class="dv" style="color: #AD0000;">512</span></span>
<span id="cb16-3"></span>
<span id="cb16-4"><span class="co" style="color: #5E5E5E;"># grab the initial set of latents</span></span>
<span id="cb16-5">seed <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1024</span></span>
<span id="cb16-6">torch.manual_seed(seed)</span>
<span id="cb16-7">init_latents <span class="op" style="color: #5E5E5E;">=</span> torch.randn((<span class="dv" style="color: #AD0000;">1</span>, unet.in_channels, height<span class="op" style="color: #5E5E5E;">//</span><span class="dv" style="color: #AD0000;">8</span>, width<span class="op" style="color: #5E5E5E;">//</span><span class="dv" style="color: #AD0000;">8</span>), dtype<span class="op" style="color: #5E5E5E;">=</span>unet.dtype, device<span class="op" style="color: #5E5E5E;">=</span>device)</span>
<span id="cb16-8"></span>
<span id="cb16-9"><span class="kw" style="color: #003B4F;">def</span> generate(prompt, gtfm<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>, width<span class="op" style="color: #5E5E5E;">=</span>width, height<span class="op" style="color: #5E5E5E;">=</span>height, guidance<span class="op" style="color: #5E5E5E;">=</span>max_g, steps<span class="op" style="color: #5E5E5E;">=</span>num_steps, <span class="op" style="color: #5E5E5E;">**</span>kwargs):</span>
<span id="cb16-10">    <span class="co" style="color: #5E5E5E;"># make sure we got a guidance function</span></span>
<span id="cb16-11">    <span class="cf" style="color: #003B4F;">assert</span> gtfm</span>
<span id="cb16-12">    </span>
<span id="cb16-13">    <span class="co" style="color: #5E5E5E;"># prepare text embeddings</span></span>
<span id="cb16-14">    text <span class="op" style="color: #5E5E5E;">=</span> text_embeddings(prompt)</span>
<span id="cb16-15">    uncond <span class="op" style="color: #5E5E5E;">=</span> text_embeddings(<span class="st" style="color: #20794D;">''</span>)</span>
<span id="cb16-16">    emb <span class="op" style="color: #5E5E5E;">=</span> torch.cat([uncond, text]).<span class="bu" style="color: null;">type</span>(unet.dtype)</span>
<span id="cb16-17">    </span>
<span id="cb16-18">    <span class="co" style="color: #5E5E5E;"># start from the shared, initial latents</span></span>
<span id="cb16-19">    latents <span class="op" style="color: #5E5E5E;">=</span> torch.clone(init_latents)</span>
<span id="cb16-20">    scheduler.set_timesteps(steps)</span>
<span id="cb16-21">    latents <span class="op" style="color: #5E5E5E;">=</span> latents <span class="op" style="color: #5E5E5E;">*</span> scheduler.init_noise_sigma</span>
<span id="cb16-22">    </span>
<span id="cb16-23">    <span class="co" style="color: #5E5E5E;"># run diffusion</span></span>
<span id="cb16-24">    <span class="cf" style="color: #003B4F;">for</span> i,ts <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">enumerate</span>(tqdm(scheduler.timesteps)):</span>
<span id="cb16-25">        inp <span class="op" style="color: #5E5E5E;">=</span> scheduler.scale_model_input(torch.cat([latents] <span class="op" style="color: #5E5E5E;">*</span> <span class="dv" style="color: #AD0000;">2</span>), ts)</span>
<span id="cb16-26">        <span class="cf" style="color: #003B4F;">with</span> torch.no_grad(): </span>
<span id="cb16-27">            tf <span class="op" style="color: #5E5E5E;">=</span> ts</span>
<span id="cb16-28">            <span class="cf" style="color: #003B4F;">if</span> torch.has_mps:</span>
<span id="cb16-29">                tf <span class="op" style="color: #5E5E5E;">=</span> ts.<span class="bu" style="color: null;">type</span>(torch.float32)</span>
<span id="cb16-30">            u,t <span class="op" style="color: #5E5E5E;">=</span> unet(inp, tf, encoder_hidden_states<span class="op" style="color: #5E5E5E;">=</span>emb).sample.chunk(<span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb16-31">        </span>
<span id="cb16-32">        <span class="co" style="color: #5E5E5E;"># run the guidance transform</span></span>
<span id="cb16-33">        pred <span class="op" style="color: #5E5E5E;">=</span> gtfm.encode(u, t, idx<span class="op" style="color: #5E5E5E;">=</span>i)</span>
<span id="cb16-34">        </span>
<span id="cb16-35">        <span class="co" style="color: #5E5E5E;"># update the latents</span></span>
<span id="cb16-36">        latents <span class="op" style="color: #5E5E5E;">=</span> scheduler.step(pred, ts, latents).prev_sample</span>
<span id="cb16-37">        </span>
<span id="cb16-38">    <span class="co" style="color: #5E5E5E;"># decode and return the final latents</span></span>
<span id="cb16-39">    image <span class="op" style="color: #5E5E5E;">=</span> image_from_latents(latents)</span>
<span id="cb16-40">    <span class="cf" style="color: #003B4F;">return</span> image    </span></code></pre></div>
</div>
<p>Let’s save ourselves some work by writing a harness function to automatically store the experiment results:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="co" style="color: #5E5E5E;"># store generated images and their title (the experiment name)</span></span>
<span id="cb17-2">images, titles <span class="op" style="color: #5E5E5E;">=</span> [], []</span>
<span id="cb17-3"></span>
<span id="cb17-4"><span class="kw" style="color: #003B4F;">def</span> harness(prompt, gtfm, title<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">''</span>):</span>
<span id="cb17-5">    img <span class="op" style="color: #5E5E5E;">=</span> generate(prompt, gtfm)</span>
<span id="cb17-6">    <span class="co" style="color: #5E5E5E;">#print(title)</span></span>
<span id="cb17-7">    <span class="co" style="color: #5E5E5E;">#show_image(img, scale=1)</span></span>
<span id="cb17-8">    images.append(img)</span>
<span id="cb17-9">    titles.append(title)</span></code></pre></div>
</div>
</section>
<section id="running-the-guidance-experiments." class="level1">
<h1>Running the guidance experiments.</h1>
<div class="cell">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="co" style="color: #5E5E5E;"># run each of the functions with the harness</span></span>
<span id="cb18-2"><span class="cf" style="color: #003B4F;">for</span> gname, gtfm <span class="kw" style="color: #003B4F;">in</span> expts.items():</span>
<span id="cb18-3">    <span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Running experiment: </span><span class="sc" style="color: #5E5E5E;">{</span>gname<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">...'</span>)</span>
<span id="cb18-4">    harness(prompt, gtfm, title<span class="op" style="color: #5E5E5E;">=</span>gname)</span>
<span id="cb18-5">    <span class="bu" style="color: null;">print</span>(<span class="st" style="color: #20794D;">'Done.'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Running experiment: NoNorm_FixedG_7.50...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"9e3cb44d425b4994a0aa363d1a14011d","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.
Running experiment: BaseNorm_FixedG_7.50...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"134fb54d395046bba9856700ca610b80","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.
Running experiment: TNorm_FixedG_00.15...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"fbf505ed0abd45378c252fb8670988e7","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.
Running experiment: FullNorm_FixedG_0.15...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ffca5d3f1d67453db00db873b9614ebc","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.
Running experiment: TNormGuidance_Sched_TCos...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4495dd788635406ba678603645c592d7","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.
Running experiment: FullNormGuidance_Sched_TCos...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1e1dc057dcda4a3987b63e783d2b09d9","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.
Running experiment: CFGuidance_Sched_Cos...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"886b4658518844ea8201f02fa98af963","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.
Running experiment: CFGuidance_Sched_CosWarmup...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1177d0ab4c4e4a2fadb288795f0fcc9f","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.
Running experiment: BaseNormGuidance_Sched_Cos...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b9fe3e42d55b4e2283c09dc82b1f7576","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.
Running experiment: BaseNormGuidance_Sched_CosWarmup...</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"28da7d2dcd1b4038b89354c866c156f5","version_major":2,"version_minor":0}
</script>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Done.</code></pre>
</div>
</div>
</section>
<section id="results" class="level1">
<h1>Results</h1>
<section id="showing-all-images-side-by-side" class="level2">
<h2 class="anchored" data-anchor-id="showing-all-images-side-by-side">Showing all images side by side</h2>
<p>Our starting image, the baseline, is in the top-left. All other images are from different Guidance normalizations and schedules.</p>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-15-guidance-expts-1/index_files/figure-html/cell-20-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>That’s a lot of images. Thankfully, there is one result that stands out above the rest:</p>
</section>
<section id="biggest-improvement-cosine-with-t-norm-and-fullnorm" class="level2">
<h2 class="anchored" data-anchor-id="biggest-improvement-cosine-with-t-norm-and-fullnorm">Biggest Improvement: Cosine with T-Norm and FullNorm</h2>
<p>There seems to be a consistent gain from using either T-Norm or FullNorm with a Cosine schedule.</p>
<p>The image below compares our baseline to T-Norm and Cosine schedule. We can see:</p>
<ul>
<li>A more semantically correct horse (it has all of its legs!).<br>
</li>
<li>Better details and colors in the background.</li>
</ul>
<p>The horse’s body is still not quite right, but it’s a marked improvement from the baseline.</p>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-15-guidance-expts-1/index_files/figure-html/cell-21-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="cosine-t-norm-vs.-cosine-fullnorm" class="level2">
<h2 class="anchored" data-anchor-id="cosine-t-norm-vs.-cosine-fullnorm">Cosine T-Norm vs.&nbsp;Cosine FullNorm</h2>
<p>These images are close, and both are better than the baseline. It seems we traded some background quality for subject quality with FullNorm vs.&nbsp;T-Norm.</p>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-15-guidance-expts-1/index_files/figure-html/cell-22-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>This notebook recaps a set of discussions on the fast.ai forums about how to improve Classifier-free Guidance.</p>
<p>Two changes were proposed and tested:<br>
- Normalizing the guidance parameter.<br>
- Scheduling the guidance parameter.</p>
<p>A <code>GuidanceTfm</code> class was created to easily leverage these approaches in other runs.</p>
<p>Overall, it seems that a combination of T-Norm and Cosine schedule improves both the details and syntax of generated images.</p>
<p>Given that these improvements are achieved for “free”, with a negligible increase in computation time, and without any external data or fine-tuning, they could be a healthy addition to any existing diffusion process.</p>
<section id="more-examples" class="level3">
<h3 class="anchored" data-anchor-id="more-examples">More examples</h3>
<p>Here is an example from a run using a different prompt:</p>
<blockquote class="blockquote">
<p>“a portrait of a great Incan Warlord wearing his ornate ceremonial armor”</p>
</blockquote>
<p>With a few Diffusion pipeline changes:</p>
<ul>
<li>Using Stable Diffusion <code>v1-5</code> from Runway.ml<br>
</li>
<li>Using <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BVAE-mse%7D"> from stability.ai</li>
</ul>
<p>We again see a huge improvement from using FullNorm with a Cosine schedule.</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: left;"><strong>Baseline</strong></th>
<th style="text-align: left;"><strong>FullNorm with Cosine schedule</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><img src="https://enzokro.dev/blog/posts/2022-11-15-guidance-expts-1/comp1.png" class="img-fluid"></td>
<td style="text-align: left;"><img src="https://enzokro.dev/blog/posts/2022-11-15-guidance-expts-1/comp2.png" class="img-fluid"></td>
</tr>
</tbody>
</table>
<p>This shows that the improvements may not be isolated to <code>v1-4</code> or any particular <img src="https://latex.codecogs.com/png.latex?VAE">!</p>
</section>
</section>
<section id="appendix-more-comparisons" class="level1">
<h1>Appendix: More comparisons</h1>
<p>The gains from other schedules are normalizations are less noticeable.</p>
<p>There are likely still universal gains from normalizing. But with Cosine schedules on their own the results are more mixed.</p>
<p>To drive this point home: there is a lot more exploration left to do for both schedule values and warmups. This notebook is hopefully a good starting point for others to build on!</p>
<section id="original-vs.-basenorm" class="level2">
<h2 class="anchored" data-anchor-id="original-vs.-basenorm">Original vs.&nbsp;BaseNorm</h2>
<p>Here we plot our default image and the result from BaseNorm.</p>
<p>The differences are subtle, but track the general observations from the forums:<br>
- More detail in the backgrounds.<br>
- Better shadowing on subjects.<br>
- Some moderate clarity gains.</p>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-15-guidance-expts-1/index_files/figure-html/cell-23-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="original-vs.-t-norm" class="level2">
<h2 class="anchored" data-anchor-id="original-vs.-t-norm">Original vs.&nbsp;T-Norm</h2>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-15-guidance-expts-1/index_files/figure-html/cell-24-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="original-vs.-fullnorm" class="level2">
<h2 class="anchored" data-anchor-id="original-vs.-fullnorm">Original vs.&nbsp;FullNorm</h2>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-15-guidance-expts-1/index_files/figure-html/cell-25-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="original-vs.-cosine" class="level2">
<h2 class="anchored" data-anchor-id="original-vs.-cosine">Original vs.&nbsp;Cosine</h2>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-15-guidance-expts-1/index_files/figure-html/cell-26-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="original-vs.-basenorm-with-cosine" class="level2">
<h2 class="anchored" data-anchor-id="original-vs.-basenorm-with-cosine">Original vs.&nbsp;BaseNorm with Cosine</h2>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-11-15-guidance-expts-1/index_files/figure-html/cell-27-output-1.png" class="img-fluid"></p>
</div>
</div>


</section>
</section>

 ]]></description>
  <category>diffusion</category>
  <category>classifier-free guidance</category>
  <category>deep learning</category>
  <guid>https://enzokro.dev/blog/posts/2022-11-15-guidance-expts-1/index.html</guid>
  <pubDate>Sun, 13 Nov 2022 00:00:00 GMT</pubDate>
  <media:content url="https://enzokro.dev/blog/posts/2022-11-15-guidance-expts-1/cat2.jpeg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Merging an arbitrary number of Binary Trees</title>
  <dc:creator>enzokro</dc:creator>
  <link>https://enzokro.dev/blog/posts/2022-11-08-merge-n-BSTs/index.html</link>
  <description><![CDATA[ 



<blockquote class="blockquote">
<p>Using functional python tools to merge several Binary Trees together.</p>
</blockquote>
<section id="introduction." class="level1">
<h1>Introduction.</h1>
<p>There is a classic programming interview question that asks us to merge two Binary Trees.</p>
<p>Below is one possible setup, borrowed from the official LeetCode problem description <a href="https://leetcode.com/problems/merge-two-binary-trees/">Merge Two Binary Trees</a>:<br>
<br></p>
<blockquote class="blockquote">
<p>You are given two binary trees <code>root1</code> and <code>root2</code>.</p>
<p>Imagine that when you put one of them to cover the other, some nodes of the two trees are overlapped while the others are not. You need to merge the two trees into a new binary tree. The merge rule is that if two nodes overlap, then sum node values up as the new value of the merged node. Otherwise, the NOT null node will be used as the node of the new tree.</p>
<p>Return the merged tree.</p>
<p><strong>Note</strong>: The merging process must start from the root nodes of both trees.</p>
</blockquote>
</section>
<section id="approaching-the-problem." class="level1">
<h1>Approaching the problem.</h1>
<p>Like many BST problems, this one is a natural fit for a recursive solution where we consider the following scenarios:</p>
<ol type="1">
<li>The base case(s): when to return and start working up the recursive stack.<br>
</li>
<li>If we are not in a base case, what specific actions must we take?<br>
</li>
<li>Then, call the function on the remaining sub-problems, usually the children of the current node.</li>
</ol>
<section id="the-intuition-to-merge-two-binary-trees." class="level2">
<h2 class="anchored" data-anchor-id="the-intuition-to-merge-two-binary-trees.">The intuition to merge two Binary Trees.</h2>
<p>The general intuition to solve this problem is:</p>
<ol type="1">
<li>Overlay the two trees together, starting from their root nodes.<br>
</li>
<li>Then, merge the values of the root nodes.<br>
</li>
<li>Finally, merge both the left and and right subtrees in the same way.</li>
</ol>
<p>What will these steps look like in code?</p>
</section>
</section>
<section id="merging-only-two-bsts" class="level1">
<h1>Merging only two BSTs</h1>
<p>We can translate the publicly available Java implementation to arrive at the following python solution:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="kw" style="color: #003B4F;">class</span> Solution:</span>
<span id="cb1-2">    <span class="kw" style="color: #003B4F;">def</span> mergeTrees(<span class="va" style="color: #111111;">self</span>, t1: Optional[TreeNode], t2: Optional[TreeNode]) <span class="op" style="color: #5E5E5E;">-&gt;</span> Optional[TreeNode]:</span>
<span id="cb1-3">        </span>
<span id="cb1-4">        <span class="co" style="color: #5E5E5E;"># Base cases:</span></span>
<span id="cb1-5">        <span class="co" style="color: #5E5E5E;">## 1) The first tree is null, return the second tree</span></span>
<span id="cb1-6">        <span class="co" style="color: #5E5E5E;">## 2) The second tree is null, return the first tree</span></span>
<span id="cb1-7">        <span class="cf" style="color: #003B4F;">if</span> (t1 <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span>):</span>
<span id="cb1-8">            <span class="cf" style="color: #003B4F;">return</span> t2</span>
<span id="cb1-9">        <span class="cf" style="color: #003B4F;">if</span> (t2 <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span>):</span>
<span id="cb1-10">            <span class="cf" style="color: #003B4F;">return</span> t1</span>
<span id="cb1-11">        </span>
<span id="cb1-12">        <span class="co" style="color: #5E5E5E;"># If we make it here, then there are two valid nodes we have to merge</span></span>
<span id="cb1-13">        </span>
<span id="cb1-14">        <span class="co" style="color: #5E5E5E;"># Merge the nodes (add the value from the first into the second)</span></span>
<span id="cb1-15">        t1.val <span class="op" style="color: #5E5E5E;">+=</span> t2.val</span>
<span id="cb1-16">        </span>
<span id="cb1-17">        <span class="co" style="color: #5E5E5E;"># Now merge the left and right subtrees. </span><span class="al" style="color: #AD0000;">NOTE</span><span class="co" style="color: #5E5E5E;">: this is recursive call</span></span>
<span id="cb1-18">        t1.left <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.mergeTrees(t1.left, t2.left)</span>
<span id="cb1-19">        t1.right <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.mergeTrees(t1.right, t2.right)</span>
<span id="cb1-20">        </span>
<span id="cb1-21">        <span class="co" style="color: #5E5E5E;"># At the end of the recursive stack, t1 will be the root of the valid, merged tree.</span></span>
<span id="cb1-22">        <span class="cf" style="color: #003B4F;">return</span> t1</span></code></pre></div>
</div>
<p>If a matching, overlapping node exists in both trees, then we add their values together.</p>
<p>If a node exists in one tree but not the other, then we take the value from the existing node.</p>
<p>Once all nodes have been visited, then the trees are fully merged and we are done.</p>
</section>
<section id="merging-an-arbitrary-number-of-binary-trees" class="level1">
<h1>Merging an arbitrary number of Binary Trees</h1>
<p>It turns out that we can leverage some functional tools from python to make the solution above even more general.</p>
<p>Specifically, we will use python’s functional <code>map</code> and <code>lambda</code>, together with <code>getattr</code> and sequence expansion via <code>*</code>, to merge an arbitrary number of Binary Trees.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="kw" style="color: #003B4F;">class</span> Solution:</span>
<span id="cb2-2">    <span class="kw" style="color: #003B4F;">def</span> mergeTrees(<span class="va" style="color: #111111;">self</span>, <span class="op" style="color: #5E5E5E;">*</span>args: Optional[List[TreeNode]]) <span class="op" style="color: #5E5E5E;">-&gt;</span> Optional[TreeNode]:</span>
<span id="cb2-3">        </span>
<span id="cb2-4">        <span class="co" style="color: #5E5E5E;"># Base case: all trees are empty, we have nothing to merge</span></span>
<span id="cb2-5">        <span class="cf" style="color: #003B4F;">if</span> <span class="kw" style="color: #003B4F;">not</span> <span class="bu" style="color: null;">any</span>(args): <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">None</span></span>
<span id="cb2-6">        </span>
<span id="cb2-7">        <span class="co" style="color: #5E5E5E;"># Get the values of every matched overlapping node, and sum them together.</span></span>
<span id="cb2-8">        vals <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">map</span>(<span class="kw" style="color: #003B4F;">lambda</span> n: <span class="bu" style="color: null;">getattr</span>(n, <span class="st" style="color: #20794D;">'val'</span>, <span class="dv" style="color: #AD0000;">0</span>), args)</span>
<span id="cb2-9">        node <span class="op" style="color: #5E5E5E;">=</span> TreeNode(<span class="bu" style="color: null;">sum</span>(vals))</span>
<span id="cb2-10">        </span>
<span id="cb2-11">        </span>
<span id="cb2-12">        <span class="co" style="color: #5E5E5E;"># Create the left child from the merged left-subtrees</span></span>
<span id="cb2-13">        node.left <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.mergeTrees(<span class="op" style="color: #5E5E5E;">*</span><span class="bu" style="color: null;">map</span>(<span class="kw" style="color: #003B4F;">lambda</span> n: <span class="bu" style="color: null;">getattr</span>(n, <span class="st" style="color: #20794D;">'left'</span>, <span class="va" style="color: #111111;">None</span>), args))</span>
<span id="cb2-14">        </span>
<span id="cb2-15">        <span class="co" style="color: #5E5E5E;"># Create the right child from the merged right-subtrees</span></span>
<span id="cb2-16">        node.right <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.mergeTrees(<span class="op" style="color: #5E5E5E;">*</span><span class="bu" style="color: null;">map</span>(<span class="kw" style="color: #003B4F;">lambda</span> n: <span class="bu" style="color: null;">getattr</span>(n, <span class="st" style="color: #20794D;">'right'</span>, <span class="va" style="color: #111111;">None</span>), args))</span>
<span id="cb2-17"></span>
<span id="cb2-18">        <span class="co" style="color: #5E5E5E;"># Return the new, merged tree        </span></span>
<span id="cb2-19">        <span class="cf" style="color: #003B4F;">return</span> node</span></code></pre></div>
</div>
<p>This solution is more general at the cost of more memory: we create a new <code>TreeNode</code> instead of adding to an existing node’s value.</p>
<p>However, this still follows the problem’s constraints that we return a “new binary tree”. In our more general solution, the returned <code>node</code> at the top of the recursive stack will be the root of a new binary tree.</p>
<section id="footnotes" class="level6">
<h6 class="anchored" data-anchor-id="footnotes"><strong>Footnotes</strong></h6>
<blockquote class="blockquote">
<p>The Binary Tree image for this post is from the good folks at <a href="https://www.codiwan.com/posts/tree/merge-two-binary-trees-617">Codiwan</a>.</p>
</blockquote>


</section>
</section>

 ]]></description>
  <category>Binary Tree</category>
  <category>algorithms</category>
  <category>functional</category>
  <guid>https://enzokro.dev/blog/posts/2022-11-08-merge-n-BSTs/index.html</guid>
  <pubDate>Tue, 08 Nov 2022 00:00:00 GMT</pubDate>
  <media:content url="https://enzokro.dev/blog/posts/2022-11-08-merge-n-BSTs/merging_bts.png" medium="image" type="image/png" height="138" width="144"/>
</item>
<item>
  <title>Complex Rayleigh Weight Initializations</title>
  <dc:creator>enzokro</dc:creator>
  <link>https://enzokro.dev/blog/posts/2022-09-01-rayleigh-init/index.html</link>
  <description><![CDATA[ 



<blockquote class="blockquote">
<p>Creating complex-valued Rayleigh initializations for neural networks.</p>
</blockquote>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Most neural networks use real-valued weights instead of complex ones. Real-valued networks include NLP transformers for text, CNNs in Computer Vision for images, and feed-forward networks for audio signals like speech. At initialization, each real-valued weight only needs a single real-valued number. These networks are quite powerful and have been extremely successful in their domains, so why do we need complex-valued weights at all?</p>
<p>It turns our that many signals are better represented in the complex domain. These complex-valued signals are found in:</p>
<ul>
<li>Robotics<br>
</li>
<li>Radio Frequency communications<br>
</li>
<li>Bio-informatics<br>
</li>
<li>Radar<br>
</li>
<li>Speech</li>
</ul>
<p>That does not mean that we <em>must</em> use complex values for these signals. The crucial point is that real-valued networks are potentially throwing away half of the information in the input.</p>
<p>Moreover, the phase of complex signals contains important information. For example, the phase of an image describes the position of the photo’s subjects, while the magnitude mainly has color information. In speech, the phase of a signal is important for how understandable the recording is. In sonar, communications, radar, and robotics the phase embeds information about both the signal’s content and its location.</p>
<p>If we want to leverage the full potential of these complex input signals, we need to match them with complex-valued neural networks. The key difference for complex weights is that we now need need two values: one for phase and the other for magnitude.</p>
<p>But we cannot simply take two regular, real-valued initializations and call it a day. The rest of this post goes over the details of accurately creating proper initializations for complex-valued weights.</p>
<section id="complex-numbers-a-brief-recap" class="level2">
<h2 class="anchored" data-anchor-id="complex-numbers-a-brief-recap">Complex Numbers: A brief recap</h2>
<p><br> Complex numbers have two components:<br>
- A real part.<br>
- An imaginary part.</p>
<p>The real component is a regular number like we would find on a plain number line. The imaginary component exists along the <code>i</code> axis.</p>
<p>To keep things simple, we can think of these numbers on a two-dimensional plot. The real number is on the x-axis while the imaginary number is on the y-axis.</p>
<section id="starting-with-a-real-number" class="level3">
<h3 class="anchored" data-anchor-id="starting-with-a-real-number">Starting with a real number</h3>
<p>Plotting examples is a great way to make things concrete. We first plot a regular, real number that we are all familiar with: <img src="https://latex.codecogs.com/png.latex?x%20=%202"></p>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-09-01-rayleigh-init/index_files/figure-html/cell-2-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="magnitude-of-a-real-number" class="level3">
<h3 class="anchored" data-anchor-id="magnitude-of-a-real-number">Magnitude of a real number</h3>
<p>The distance from the origin to our number tells us its magnitude. With positive values this feels redundant, since the magnitude is always the number itself.</p>
<p>But what about negative numbers? That is where the absolute value, represented as <img src="https://latex.codecogs.com/png.latex?%7Cx%7C">, comes into play. If we had picked <img src="https://latex.codecogs.com/png.latex?x%20=%20-2"> instead, the magnitude would still be the same: <img src="https://latex.codecogs.com/png.latex?%7C-2%7C%20=%20%7C2%7C%20=%202">.</p>
<p>So for any real number, positive or negative, we can find its magnitude by drawing an arrow starting from the origin <img src="https://latex.codecogs.com/png.latex?0">. The absolute length of the arrow will be the number’s magnitude.</p>
<p>Why are we spelling out this aspect of numbers so much? That will become clear when we introduce the imaginary component next.</p>
</section>
<section id="adding-an-imaginary-component" class="level3">
<h3 class="anchored" data-anchor-id="adding-an-imaginary-component">Adding an imaginary component</h3>
<p>We will keep our real component the same: <img src="https://latex.codecogs.com/png.latex?x%20=%202">.</p>
<p>But now, let’s an imaginary component: <img src="https://latex.codecogs.com/png.latex?y%20=%203">, to turn it into a complex number.</p>
<p>What does this new complex number look like? We can visualize it on a 2D plot:</p>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-09-01-rayleigh-init/index_files/figure-html/cell-3-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>We combined these two components to get a complex number! Let’s call this number <img src="https://latex.codecogs.com/png.latex?z">.</p>
<p><img src="https://latex.codecogs.com/png.latex?z"> will be defined as: <img src="https://latex.codecogs.com/png.latex?z%20=%20x%20+%20iy"></p>
<p>The “<img src="https://latex.codecogs.com/png.latex?i">” next to a number means that it is the imaginary component.</p>
</section>
<section id="magnitude-of-a-complex-number" class="level3">
<h3 class="anchored" data-anchor-id="magnitude-of-a-complex-number">Magnitude of a complex number</h3>
<p>While we could use the real and imaginary components, there is another representation of complex numbers that will be more useful to us. This other representation is the <em>magnitude</em> and <em>phase</em> of a complex number.</p>
<p>Remember how for a real number, its magnitude was the length of an arrow starting from the origin? The same idea applies to complex numbers. With one new detail: we have two components now, so our arrow’s length will be different.<br>
Let’s first draw our new complex number as an arrow.</p>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-09-01-rayleigh-init/index_files/figure-html/cell-4-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>The formula to compute the magnitude of a complex number <img src="https://latex.codecogs.com/png.latex?z"> is:<br>
<img src="https://latex.codecogs.com/png.latex?%7Cz%7C%20=%20%5Csqrt%7Bx%5E%7B2%7D%20+%20y%5E%7B2%7D%7D"></p>
<p>Plugging in our <img src="https://latex.codecogs.com/png.latex?x"> and <img src="https://latex.codecogs.com/png.latex?y"> values gives our complex <img src="https://latex.codecogs.com/png.latex?z"> a magnitude of:</p>
<p><img src="https://latex.codecogs.com/png.latex?%7Cz%7C%20=%20%5Csqrt%7B2%5E%7B2%7D%20+%203%5E%7B2%7D%7D%20=%20%5Csqrt%7B4%20+%209%7D%20=%20%5Csqrt%7B13%7D"></p>
<p>While knowing the magnitude is important, it is not enough to fully describe <img src="https://latex.codecogs.com/png.latex?z">. For example what if instead of <img src="https://latex.codecogs.com/png.latex?(x%20=%202,%20y%20=%203)"> we had swapped them around as <img src="https://latex.codecogs.com/png.latex?(x%20=%203,%20y%20=%202)">. If we plug these values into the magnitude equation we get back the exact same number <img src="https://latex.codecogs.com/png.latex?%5Csqrt%7B13%7D">.</p>
<p>But looking at our 2D plots, these swapped points would obviously be in different locations. So if we were given only the magnitude, how could we tell that it came from our true, original <img src="https://latex.codecogs.com/png.latex?z">?</p>
</section>
<section id="phase-telling-complex-magnitudes-apart-from-each-other" class="level3">
<h3 class="anchored" data-anchor-id="phase-telling-complex-magnitudes-apart-from-each-other">Phase: telling complex magnitudes apart from each other</h3>
<p>The way to tell two complex numbers with the same magnitude apart lies in the fact that the arrows are no longer flat along the x-axis.</p>
<p>Instead they are now elevated (“pulled up”) by the imaginary component <img src="https://latex.codecogs.com/png.latex?y%20=%203">. The complex number now has an <em>angle</em> respective to the x-axis.</p>
<p>This angle, together with a magnitude, is enough to perfectly describe our complex <img src="https://latex.codecogs.com/png.latex?z">. In other words: we know both how long to make the vector and where to point it.</p>
<p>Let’s complete the picture by including the angle of <img src="https://latex.codecogs.com/png.latex?z">:</p>
<div class="cell">
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-09-01-rayleigh-init/index_files/figure-html/cell-5-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>We use <img src="https://latex.codecogs.com/png.latex?%5Ctheta"> to represent the angle. The formula to compute <img src="https://latex.codecogs.com/png.latex?%5Ctheta"> is:<br>
<img src="https://latex.codecogs.com/png.latex?%5Ctheta%20=%20%5Carctan%7B%5Cfrac%7By%7D%7Bx%7D%7D"></p>
<p>Plugging in <img src="https://latex.codecogs.com/png.latex?x"> and <img src="https://latex.codecogs.com/png.latex?y"> for our complex number <img src="https://latex.codecogs.com/png.latex?z"> gives us an angle of:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Ctheta%20=%20%5Carctan%7B%5Cfrac%7B3%7D%7B2%7D%7D%20=%2056.31%20%5E%5Ccirc"></p>
<p>With the phase and magnitude, we now have a unique way of representing our complex number <img src="https://latex.codecogs.com/png.latex?z">.</p>
</section>
</section>
<section id="recap-complex-numbers" class="level2">
<h2 class="anchored" data-anchor-id="recap-complex-numbers">Recap: Complex Numbers</h2>
<p>In this section, we gave a brief overview of complex numbers and their representation. To make things concrete, we picked a complex number <img src="https://latex.codecogs.com/png.latex?z"> with a real component <img src="https://latex.codecogs.com/png.latex?x%20=%202"> and an imaginary component <img src="https://latex.codecogs.com/png.latex?y%20=%203">.</p>
<p>Then, we showed that we can perfectly represent this complex number <img src="https://latex.codecogs.com/png.latex?z"> with two pieces of information: its <em>magnitude</em> and its <em>phase</em>.</p>
<ul>
<li><strong>Magnitude</strong>: the length of a vector.<br>
</li>
<li><strong>Phase</strong>: the angle, or direction, where a vector is pointing.</li>
</ul>
</section>
</section>
<section id="distributions-for-complex-initializations." class="level1">
<h1>Distributions for complex initializations.</h1>
<p>Now that we know what complex numbers are, how do we pick them to make sure they are good initial weight values?</p>
<section id="background-on-neural-network-initializations" class="level2">
<h2 class="anchored" data-anchor-id="background-on-neural-network-initializations">Background on neural network initializations</h2>
<p>While initializations are now taken for granted, they were part of the first key pieces that made it possible to train deep neural networks. Before we knew how to properly initialize networks, training was very unstable as the gradients would either diverge or collapse to 0. This is known as gradient explosion or vanishing, respectively.</p>
<p>The main insights to prevent gradients from vanishing or exploding came from analyzing their variance during training.<br>
&gt; <strong>Aside</strong>: this is still an important error analysis tool! Looking at the behavior and distribution of gradients is a surefire way to catch problems with the training. Especially during the earliest optimizer steps.</p>
<section id="achieving-smooth-gradient-flows" class="level3">
<h3 class="anchored" data-anchor-id="achieving-smooth-gradient-flows">Achieving smooth gradient flows</h3>
<p>It was the seminal work by <a href="https://arxiv.org/pdf/1502.01852.pdf">He</a> and <a href="http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf">Glorot, Bengio</a> that showed how to control the variance of gradients to make sure that training was successful. They found that the variance of the sampling distributions, either Normal or Uniform, must meet certain criteria for the gradients to flow “smoothly”.</p>
<p>Here, “smoothly” means that the gradients neither disappear nor explode during training.</p>
<p>The initializations derived in these papers are now the defaults in popular deep learning libraries like TensorFlow and pytorch.</p>
<p>Unfortunately, the theory of complex-valued neural networks is not as well established. How can we know what are good variances and distributions for complex weights?</p>
<p>It turns out we can borrow these hard-earned lessons about good real-valued initializations to make sure that our complex gradients flow smoothly.</p>
</section>
</section>
<section id="initializing-complex-magnitudes" class="level2">
<h2 class="anchored" data-anchor-id="initializing-complex-magnitudes">Initializing complex magnitudes</h2>
<p>Instead of drawing from a Normal or Uniform distribution, like we do for real-valued networks, the magnitudes will instead be drawn from a <strong><a href="https://en.wikipedia.org/wiki/Rayleigh_distribution%5D">Rayleigh distribution</a></strong>. The reasons for this are described below. We can think of a Rayleigh distribution as the complex version of the familiar Normal distribution we use for real-valued weights.</p>
</section>
<section id="initializing-phases" class="level2">
<h2 class="anchored" data-anchor-id="initializing-phases">Initializing phases</h2>
<p>The phases will be drawn from a Uniform distribution. To see why, think about a compass with 360 degrees to choose from.</p>
<p>We could randomly pick a degree and start walking in that direction for a given amount of time. Assuming we are on a flat surface, each degree choice will place us in a different, unique location.</p>
<p>Because we don’t know which direction our learned complex weights should point in, the best we can do is to start by randomly pointing everywhere and letting the gradients steer the vectors instead.</p>
</section>
</section>
<section id="history-of-complex-networks" class="level1">
<h1>History of Complex Networks</h1>
<p>Despite the fact that they are not as popular as real-valued approaches, complex networks have a rich and long history. See Chapter 3 of this thesis on <a href="https://digitalcommons.dartmouth.edu/dissertations/55/">Complex Networks for Audio</a> by Andy M. Sarroff for a great historical recap.</p>
<p>The first modern, complete work on complex neural nets was <a href="https://arxiv.org/pdf/1705.09792.pdf">Deep Complex Networks</a> by Trabelsi et. al.&nbsp;This paper explored many fundamental building blocks for deep complex networks. It developed complex versions of initializations, convolutions, activations, and batch normalizations. It then stacked these blocks together to build complex versions of popular networks like ResNets.</p>
<p>Despite this fantastic work the field remained somewhat quiet. But! There has been a recent activity spike in exciting fields like medical imaging, radio frequency signal processing, optical networks, and even quantum networks!</p>
<p>Some of these newer applications and advances are described in this comprehensive <a href="https://arxiv.org/pdf/2101.12249.pdf">Survey of Complex-Valued Neural Networks</a> by Bassey at. al.&nbsp;</p>
<p>Now that we know a bit more about Complex Networks, we are finally ready to initialize their weights. Let’s start by looking at the Rayleigh distribution to learn more about our complex magnitudes.</p>
</section>
<section id="the-rayleigh-distribution" class="level1">
<h1>The Rayleigh Distribution</h1>
<p>A Rayleigh distribution happens when two random variables are added together. In order to be Rayleigh distributed, the random variables must be uncorrelated, normally distributed, have zero mean, and share the same standard deviation. Let’s make this more concrete with a few examples.</p>
<p>First, imagine setting up a sensor that measures wind speed out in an open field. If we analyzed the wind speed through this sensor in two directions, say North and East, then the magnitude of the wind’s velocity will follow a Rayleigh distribution.</p>
<p>For another example, imagine tuning your car radio and accidentally ending up at an empty station. Only the familiar crackle of static is audible. This static means that the radio spectrum is empty and all we hear is noise. If we recorded the real and imaginary components of this noise, its magnitude would follow a Rayleigh distribution. In other words, pure RF noise follows a Rayleigh distribution.</p>
<section id="why-rayleigh" class="level2">
<h2 class="anchored" data-anchor-id="why-rayleigh">Why Rayleigh?</h2>
<p>Why do we choose the Rayleigh distribution? The reason is that, without having more information about what our complex magnitudes <em>should</em> be, it is the best, unbiased starting point for the network.</p>
<p>In other words, we pick the maximum entropy distribution to avoid a-priori biasing our network toward any particular outcome. One of the successes of Deep Learning has been that it’s best to let the learning procedure figure out the values on its own in its higher dimensional activation feature space.</p>
<p>This is the complex-valued version of the same logic for using Normal or Uniform distribution to initialize real-valued networks.</p>
</section>
<section id="details-of-the-rayleigh-distribution" class="level2">
<h2 class="anchored" data-anchor-id="details-of-the-rayleigh-distribution">Details of the Rayleigh distribution</h2>
<p>Let’s dive into the details. The equation below is the Probability Density Function (PDF) of the Rayleigh distribution.</p>
<p><img src="https://latex.codecogs.com/png.latex?f(x,%5Csigma)%20=%20%5Cfrac%7Bx%7D%7B%5Csigma%5E2%7De%5E%7B-x%5E2/(2%5Csigma%5E2)%7D,%20%5C%20%5C%20x%20%5Cgeq%200"></p>
<p>This equation is a bit intimidating in written form. Let’s instead code it up as a python function with NumPy to make it cleaner.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="co" style="color: #5E5E5E;"># start by importing the libraries we need</span></span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> torch</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">from</span> numpy.random <span class="im" style="color: #00769E;">import</span> default_rng</span>
<span id="cb1-6"><span class="im" style="color: #00769E;">import</span> warnings</span>
<span id="cb1-7">warnings.filterwarnings(<span class="st" style="color: #20794D;">"ignore"</span>)</span>
<span id="cb1-8"></span>
<span id="cb1-9"><span class="co" style="color: #5E5E5E;"># define the Rayleigh PDF</span></span>
<span id="cb1-10"><span class="kw" style="color: #003B4F;">def</span> rayleigh_pdf(x, sigma):</span>
<span id="cb1-11">    <span class="co" style="color: #5E5E5E;">"Evaluates the Rayleigh PDF at a given point `x`."</span></span>
<span id="cb1-12">    p <span class="op" style="color: #5E5E5E;">=</span> (x <span class="op" style="color: #5E5E5E;">/</span> sigma<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span>) <span class="op" style="color: #5E5E5E;">*</span> np.exp(<span class="op" style="color: #5E5E5E;">-</span>x<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span> <span class="op" style="color: #5E5E5E;">/</span> (<span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">*</span>sigma<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span>)) <span class="co" style="color: #5E5E5E;"># see if you can match this code to the equation above</span></span>
<span id="cb1-13">    <span class="cf" style="color: #003B4F;">return</span> p</span></code></pre></div>
</div>
<p>The parameter sigma <img src="https://latex.codecogs.com/png.latex?(%5Csigma)"> is known as the distribution’s scale. It is commonly found in many probability distributions and often controls how spread out or narrow a distribution is.</p>
<p>Let us start by setting <img src="https://latex.codecogs.com/png.latex?%5Csigma%20=%201"> to draw the “basic” Rayleigh shape. We will then change sigma to see how this affects the distribution’s shape.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;"># start with sigma of one as the base case</span></span>
<span id="cb2-2">sigma <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb2-3"></span>
<span id="cb2-4"><span class="co" style="color: #5E5E5E;"># calculate the Rayleigh PDF on 100 equally spaced points between 0 and 5</span></span>
<span id="cb2-5">points <span class="op" style="color: #5E5E5E;">=</span> np.linspace(<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">5</span>, <span class="dv" style="color: #AD0000;">100</span>)</span>
<span id="cb2-6">ray_pdf <span class="op" style="color: #5E5E5E;">=</span> rayleigh_pdf(points, sigma)  </span>
<span id="cb2-7"></span>
<span id="cb2-8"><span class="co" style="color: #5E5E5E;"># setup the plot</span></span>
<span id="cb2-9">fig, ax <span class="op" style="color: #5E5E5E;">=</span> plt.subplots(figsize<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">8</span>,<span class="dv" style="color: #AD0000;">7</span>), dpi<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">80</span>)</span>
<span id="cb2-10">ax.set_xticklabels([<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>] <span class="op" style="color: #5E5E5E;">+</span> <span class="bu" style="color: null;">list</span>(<span class="bu" style="color: null;">range</span>(<span class="bu" style="color: null;">len</span>(ax.get_xticklabels()))))</span>
<span id="cb2-11">ax.set_xlabel(<span class="st" style="color: #20794D;">'Sample Value'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'x-large'</span>)</span>
<span id="cb2-12">ax.set_ylabel(<span class="st" style="color: #20794D;">'Probability Density'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'x-large'</span>)</span>
<span id="cb2-13">ax.set_title(<span class="st" style="color: #20794D;">'Rayleigh PDF'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'xx-large'</span>)<span class="op" style="color: #5E5E5E;">;</span></span>
<span id="cb2-14"></span>
<span id="cb2-15"><span class="co" style="color: #5E5E5E;"># plot the Rayleigh pdf</span></span>
<span id="cb2-16">ax.plot(ray_pdf)<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-09-01-rayleigh-init/index_files/figure-html/cell-7-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>As we mentioned the scale <img src="https://latex.codecogs.com/png.latex?%5Csigma"> controls the width or narrowness of the distribution.<br>
Let’s both halve and double sigma to (<img src="https://latex.codecogs.com/png.latex?%5Cfrac%7B1%7D%7B2%7D,%20%7B2%7D)"> respectively to see what happens.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;"># setup plot</span></span>
<span id="cb3-2">fig,ax <span class="op" style="color: #5E5E5E;">=</span> plt.subplots(figsize<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">8</span>,<span class="dv" style="color: #AD0000;">7</span>), dpi<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">80</span>)</span>
<span id="cb3-3">ax.set_xlabel(<span class="st" style="color: #20794D;">'Sample Value'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'x-large'</span>)</span>
<span id="cb3-4">ax.set_ylabel(<span class="st" style="color: #20794D;">'Probability Density'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'x-large'</span>)</span>
<span id="cb3-5">ax.set_title(<span class="st" style="color: #20794D;">'Rayleigh PDFs'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'xx-large'</span>)<span class="op" style="color: #5E5E5E;">;</span> </span>
<span id="cb3-6"></span>
<span id="cb3-7"></span>
<span id="cb3-8"><span class="co" style="color: #5E5E5E;"># different colors for each sigma</span></span>
<span id="cb3-9">sigmas <span class="op" style="color: #5E5E5E;">=</span> [<span class="fl" style="color: #AD0000;">0.5</span>, <span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">2</span>]</span>
<span id="cb3-10">colors <span class="op" style="color: #5E5E5E;">=</span> [<span class="st" style="color: #20794D;">'m'</span>, <span class="st" style="color: #20794D;">'b'</span>, <span class="st" style="color: #20794D;">'r'</span>]</span>
<span id="cb3-11"></span>
<span id="cb3-12"><span class="co" style="color: #5E5E5E;"># plot the distributions with different scales</span></span>
<span id="cb3-13"><span class="cf" style="color: #003B4F;">for</span> color,sig <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">zip</span>(colors,sigmas):</span>
<span id="cb3-14">    rpdf <span class="op" style="color: #5E5E5E;">=</span> rayleigh_pdf(points, sig)</span>
<span id="cb3-15">    ax.plot(points, rpdf, c<span class="op" style="color: #5E5E5E;">=</span>color, label<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f'σ: </span><span class="sc" style="color: #5E5E5E;">{</span>sig<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb3-16">ax.set_xticklabels([<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>] <span class="op" style="color: #5E5E5E;">+</span> <span class="bu" style="color: null;">list</span>(<span class="bu" style="color: null;">range</span>(<span class="bu" style="color: null;">len</span>(ax.get_xticklabels()))))</span>
<span id="cb3-17">ax.legend()<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-09-01-rayleigh-init/index_files/figure-html/cell-8-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>The blue line in the plot above is the same PDF from our first plot where <img src="https://latex.codecogs.com/png.latex?%5Csigma%20=%201">.</p>
<p>We can see how <img src="https://latex.codecogs.com/png.latex?(%5Csigma%20=%200.5)"> pulls the distribution up and to the left, while <img src="https://latex.codecogs.com/png.latex?(%5Csigma%20=%202)"> squishes it down and to the right.</p>
<p>In other words, a smaller sigma makes our distribution narrower while a larger sigma makes it wider.</p>
<p>Plotting the theoretical Rayleigh PDF only shows what the distribution <em>should</em> looks like. Next, we need to actually generate some Rayleigh values.</p>
</section>
</section>
<section id="generating-rayleigh-samples" class="level1">
<h1>Generating Rayleigh samples</h1>
<p>We use the <a href="https://numpy.org/doc/stable/reference/random/generator.html">default_rng</a> class in numpy to draw Rayleigh samples. <code>default_rng</code> is a helpful class that can sample from just about every known distribution.</p>
<p>First we create the <code>default_rng</code> class with an arbitrary seed of <img src="https://latex.codecogs.com/png.latex?0">.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">seed <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb4-2">rand <span class="op" style="color: #5E5E5E;">=</span> default_rng(seed)</span></code></pre></div>
</div>
<p>This <code>default_rng</code> instance can now sample directly from a Rayleigh distribution. We can use the sampling function <code>default_rng.rayleigh</code> which accepts two parameters:<br>
- <code>scale</code>: <img src="https://latex.codecogs.com/png.latex?%5Csigma"> with a default value of 1.<br>
- <code>size</code>: the shape of the output array</p>
<p>Let’s start by drawing 1,000 Rayleigh samples with <img src="https://latex.codecogs.com/png.latex?%5Csigma%20=%201">.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">sigma <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span></span>
<span id="cb5-2">shape <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1000</span></span>
<span id="cb5-3"><span class="co" style="color: #5E5E5E;"># one dimensional vector with 1000 samples</span></span>
<span id="cb5-4">ray_vals <span class="op" style="color: #5E5E5E;">=</span> rand.rayleigh(scale<span class="op" style="color: #5E5E5E;">=</span>sigma, size<span class="op" style="color: #5E5E5E;">=</span>shape)</span></code></pre></div>
</div>
<p>How can we check check if these samples are actually Rayleigh distributed? We can compare these values to the plots of the theoretical Rayleigh PDF from the previous section.</p>
<p>The easiest way to compare the samples is with a histogram.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="co" style="color: #5E5E5E;"># setup the histogram plot for our drawn samples</span></span>
<span id="cb6-2">plt.figure(figsize<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">8</span>,<span class="dv" style="color: #AD0000;">7</span>), dpi<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">80</span>)</span>
<span id="cb6-3">plt.xlabel(<span class="st" style="color: #20794D;">'Sample Value'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'x-large'</span>)</span>
<span id="cb6-4">plt.ylabel(<span class="st" style="color: #20794D;">'Counts'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'x-large'</span>)</span>
<span id="cb6-5">plt.title(<span class="ss" style="color: #20794D;">f'Histogram of </span><span class="sc" style="color: #5E5E5E;">{</span>shape<span class="sc" style="color: #5E5E5E;">:,}</span><span class="ss" style="color: #20794D;"> Rayleigh samples'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'xx-large'</span>)</span>
<span id="cb6-6"></span>
<span id="cb6-7"><span class="co" style="color: #5E5E5E;"># plot the histogram of 1000 Rayleigh samples</span></span>
<span id="cb6-8">plt.hist(ray_vals, bins<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">50</span>)<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-09-01-rayleigh-init/index_files/figure-html/cell-11-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>This is an ok start. If we squint, we can almost see the Rayleigh PDF shape we plotted earlier. But <img src="https://latex.codecogs.com/png.latex?1,000"> is a small number of samples.</p>
<p>As we draw more samples, the distribution should grow closer and closer to the theoretical PDF plots. Let’s make sure this happens by now drawing <img src="https://latex.codecogs.com/png.latex?10,000"> samples.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="co" style="color: #5E5E5E;"># setup the new plot with more samples</span></span>
<span id="cb7-2">plt.figure(figsize<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">8</span>,<span class="dv" style="color: #AD0000;">7</span>), dpi<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">80</span>)</span>
<span id="cb7-3">plt.xlabel(<span class="st" style="color: #20794D;">'Sample Value'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'x-large'</span>)</span>
<span id="cb7-4">plt.ylabel(<span class="st" style="color: #20794D;">'Counts'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'x-large'</span>)</span>
<span id="cb7-5"></span>
<span id="cb7-6"><span class="co" style="color: #5E5E5E;"># plot even more Rayleigh samples</span></span>
<span id="cb7-7">large_shape <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">10000</span></span>
<span id="cb7-8">plt.title(<span class="ss" style="color: #20794D;">f'Histogram of </span><span class="sc" style="color: #5E5E5E;">{</span>large_shape<span class="sc" style="color: #5E5E5E;">:,}</span><span class="ss" style="color: #20794D;"> Rayleigh samples'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'xx-large'</span>)</span>
<span id="cb7-9">many_ray_vals <span class="op" style="color: #5E5E5E;">=</span> rand.rayleigh(scale<span class="op" style="color: #5E5E5E;">=</span>sigma, size<span class="op" style="color: #5E5E5E;">=</span>large_shape)</span>
<span id="cb7-10">plt.hist(many_ray_vals, bins<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">35</span>)<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-09-01-rayleigh-init/index_files/figure-html/cell-12-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>This looks much better! Now we can compare this histogram to the theoretical Rayleigh PDF.</p>
<blockquote class="blockquote">
<p>Note that we pass <code>density=True</code> to the histogram function to normalize it and make it an approximate PDF.</p>
</blockquote>
<div class="cell">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;"># setup the plot again</span></span>
<span id="cb8-2">plt.figure(figsize<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">8</span>,<span class="dv" style="color: #AD0000;">7</span>), dpi<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">80</span>)</span>
<span id="cb8-3">plt.title(<span class="st" style="color: #20794D;">'Sampled vs. Theoretical Rayleigh PDFs'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'x-large'</span>)</span>
<span id="cb8-4">plt.xlabel(<span class="st" style="color: #20794D;">'Sample Value'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'x-large'</span>)</span>
<span id="cb8-5">plt.ylabel(<span class="st" style="color: #20794D;">'Probability Density'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'x-large'</span>)</span>
<span id="cb8-6"></span>
<span id="cb8-7"><span class="co" style="color: #5E5E5E;"># compare the sample and theoretical PDFs of the Rayleigh distribution</span></span>
<span id="cb8-8">plt.hist(many_ray_vals, density<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, bins<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">35</span>) <span class="co" style="color: #5E5E5E;"># makes the histogram sum to one to mimic a pdf</span></span>
<span id="cb8-9">plt.plot(points, ray_pdf, c<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'r'</span>, label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'theoretical rayleigh pdf'</span>, linewidth<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">3</span>)</span>
<span id="cb8-10">plt.legend()<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-09-01-rayleigh-init/index_files/figure-html/cell-13-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>A near perfect match! Now we can successfully generate our initial complex Rayleigh magnitudes.</p>
<p>We are ready to move on to the phase.</p>
</section>
<section id="sampling-phase-initializations" class="level1">
<h1>Sampling phase initializations</h1>
<p>The Rayleigh values from the previous section tell us the magnitude, or length, of our complex weights. But that is only one part of a complex number. We are still missing the angle, or phase, that these complex numbers are pointing in.</p>
<p>For the phase, is enough to use random, uniform angles. Why can we do this here, when we went to such care to get the correct magnitude values?</p>
<p>It turns out that many processes such as speech, medical images, and radio modulations encode information in the signal’s phase. But we don’t know what this phase should look like beforehand. And we don’t want to bias the networks to any particular phase orientation.</p>
<p>Instead, by uniformly picking random starting phases it is like we are pointing in every direction, roughly equally. Tying it back to our compass example from earlier. It’s as if we told each weight to random pick a degree and start walking in that direction.</p>
<p>Then, during training, the network will learn how to best orient the weights for its given task.</p>
<p>Sampling this random uniform phase is straightforward. We pick uniform samples from <img src="https://latex.codecogs.com/png.latex?-%5Cpi"> to <img src="https://latex.codecogs.com/png.latex?%5Cpi"> radians which maps to a full loop of the unit circle. Even better, we can also reuse the same <code>default_rng</code> from before!</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="co" style="color: #5E5E5E;"># pick random directions along the unit circle</span></span>
<span id="cb9-2">phase <span class="op" style="color: #5E5E5E;">=</span> rand.uniform(low<span class="op" style="color: #5E5E5E;">=-</span>np.pi, high<span class="op" style="color: #5E5E5E;">=</span>np.pi, size<span class="op" style="color: #5E5E5E;">=</span>ray_vals.shape)</span></code></pre></div>
</div>
<section id="magnitude-phase-vs.-real-imaginary" class="level2">
<h2 class="anchored" data-anchor-id="magnitude-phase-vs.-real-imaginary">(Magnitude, Phase) vs.&nbsp;(Real, Imaginary)</h2>
<p>We mentioned earlier that a complex number has real and imaginary components. But so far we have deal with magnitudes and phases instead. How are these quantities related?</p>
<p>It turns out that we can use the phase and magnitude to split our vector into its real and imaginary parts. The cosine of the phase and magnitude gives us the real part, and the sine of the phase gives us the imaginary part.</p>
<p>These are two different representations of the same complex number. We do not lose anything going from one to the other or vice-versa.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;"># splitting our phases and magnitues into real and imaginary components</span></span>
<span id="cb10-2">real <span class="op" style="color: #5E5E5E;">=</span> ray_vals <span class="op" style="color: #5E5E5E;">*</span> np.cos(phase)</span>
<span id="cb10-3">imag <span class="op" style="color: #5E5E5E;">=</span> ray_vals <span class="op" style="color: #5E5E5E;">*</span> np.sin(phase)</span></code></pre></div>
</div>
<p>It turns out this will be a key detail when we are creating complex-valued network layers. As a preview: we will give one set of weights the <code>real</code> values, and another set of weights the <code>imag</code> values. This is because complex operations like addition and multiplication work better on GPUs with real and imaginary representations.</p>
</section>
<section id="visualizing-our-random-phases" class="level2">
<h2 class="anchored" data-anchor-id="visualizing-our-random-phases">Visualizing our random phases</h2>
<p>Now we can check if these phases are truly orienting our magnitudes in random directions. To do so we plot the first 500 complex weights in the polar plane.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"></span>
<span id="cb11-2"><span class="co" style="color: #5E5E5E;"># indexes for the first 500 random weights</span></span>
<span id="cb11-3">chosen_samples <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">range</span>(<span class="dv" style="color: #AD0000;">500</span>) </span>
<span id="cb11-4"></span>
<span id="cb11-5"><span class="co" style="color: #5E5E5E;"># plot these first complex weights</span></span>
<span id="cb11-6">plt.figure(figsize<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">8</span>,<span class="dv" style="color: #AD0000;">7</span>), dpi<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">80</span>)</span>
<span id="cb11-7"><span class="cf" style="color: #003B4F;">for</span> idx <span class="kw" style="color: #003B4F;">in</span> chosen_samples:</span>
<span id="cb11-8"></span>
<span id="cb11-9">    <span class="co" style="color: #5E5E5E;"># index into phase and magnitude variables</span></span>
<span id="cb11-10">    angle,mag <span class="op" style="color: #5E5E5E;">=</span> phase[idx],ray_vals[idx]</span>
<span id="cb11-11"></span>
<span id="cb11-12">    <span class="co" style="color: #5E5E5E;"># plot them starting from the origin</span></span>
<span id="cb11-13">    plt.polar([<span class="dv" style="color: #AD0000;">0</span>,angle], [<span class="dv" style="color: #AD0000;">0</span>,mag], marker<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'o'</span>)</span>
<span id="cb11-14">    </span>
<span id="cb11-15">plt.title(<span class="st" style="color: #20794D;">'Magnitudes and Phases of our Complex Weights'</span>)<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-09-01-rayleigh-init/index_files/figure-html/cell-16-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>That definitely looks like a random, uniform orientation!</p>
</section>
</section>
<section id="recapping-phase-and-magnitude-so-far" class="level1">
<h1>Recapping Phase and Magnitude so far</h1>
<p>To recap we now have:<br>
- Magnitude initializations drawn from a Rayleigh distribution.<br>
- Phase initializations drawn from a Uniform distribution.</p>
<p>Putting these together, we have complex-valued numbers pointing roughly in all directions.</p>
<p>We are almost there. There is one more important detail to work out: the variance of our complex weights.</p>
</section>
<section id="matching-he-and-glorot-variance-criteria" class="level1">
<h1>Matching He and Glorot variance criteria</h1>
<p>Even though we now have random complex weights, they are not yet good initializations. The polar plot above gives some clues as to why.<br>
&gt; hint: look at the range of the vector’s magnitudes.</p>
<p>Remember from the background section on initializations: the key insight was that the variance of the distributions need to follow certain criteria. This variance criteria makes sure that the gradients flow well during backpropagation.</p>
<p>To be more specific, both the He and Glorot criteria are based on the incoming and outgoing connections of a network layer. This number of connections is typically called <code>fanIn</code> and <code>fanOut</code>, respectively.</p>
<p>The He criteria says that the variance of weights <img src="https://latex.codecogs.com/png.latex?W"> should be: <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BVar%7D(W)%20=%20%5Cfrac%7B2%7D%7B%5Ctext%7BfanIn%7D%7D"></p>
<p>The Glorot criteria says that the variance should be: <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BVar%7D(W)%20=%20%5Cfrac%7B2%7D%7B%5Ctext%7BfanIn%20+%20fanOut%7D%7D"></p>
<p>Deep Neural Networks can easily have thousands or even millions of connections. Looking at the criteria equations above, that means that we need very small variances since <code>fanIn</code> and <code>fanOut</code> will be large.</p>
<p>Now we can see why our weights so far, shown in the earlier polar plot, are not good: their variance is clearly too large!</p>
<section id="he-and-glorot-criteria-for-rayleigh-distributions" class="level2">
<h2 class="anchored" data-anchor-id="he-and-glorot-criteria-for-rayleigh-distributions">He and Glorot criteria for Rayleigh distributions</h2>
<p>How can we make sure our Rayleigh magnitudes meet the He and Glorot variance criteria?<br>
The <a href="https://arxiv.org/pdf/1705.09792.pdf">Complex Neural Nets paper</a> from earlier includes a nice derivation for the variance of a complex Rayleigh distribution: <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BVar%7D(W)%20=%202%5Csigma%5E%7B2%7D"></p>
<p>We can set the Rayleigh variance equal to the He and Glorot criteria and solve for sigma <img src="https://latex.codecogs.com/png.latex?%5Csigma">.</p>
<p>To meet the He criteria, sigma should be: <img src="https://latex.codecogs.com/png.latex?%5Csigma_%7B%5Ctext%7BHe%7D%7D%20=%20%5Cfrac%7B1%7D%7B%5Csqrt%7B%5Ctext%7BfanIn%7D%7D%7D"> <br></p>
<p>To meet the Glorot criteria, sigma should be: <img src="https://latex.codecogs.com/png.latex?%5Csigma_%7B%5Ctext%7BGlorot%7D%7D%20=%20%5Cfrac%7B1%7D%7B%5Csqrt%7B%5Ctext%7BfanIn%20+%20fanOut%7D%7D%7D"> <br></p>
<section id="starting-with-a-simple-one-layer-network" class="level3">
<h3 class="anchored" data-anchor-id="starting-with-a-simple-one-layer-network">Starting with a simple one-layer network</h3>
<p>In the previous sections we used a flat vector of complex weights for the examples and plots. Tying it back at our two concrete examples of wind speed and radio noise, it’s as if we took a single series of measurements.</p>
<p>But since the He and Glorot criteria are defined for network layers, we need a new example. Let’s start with to a simple one-layer network. Our layer will have 100 inputs and 50 outputs (<code>fanIn</code> = 100, <code>fanOut</code> = 50).</p>
<p>Plugging these <code>fanIn</code> and <code>fanOut</code> values into the Rayleigh sigma criteria gives: <img src="https://latex.codecogs.com/png.latex?%5Csigma_%7B%5Ctext%7BHe%7D%7D%20=%20%5Cfrac%7B1%7D%7B10%7D"></p>
<p><img src="https://latex.codecogs.com/png.latex?%5Csigma_%7B%5Ctext%7BGlorot%7D%7D%20=%20%5Cfrac%7B1%7D%7B5%5Csqrt%7B6%7D%7D"></p>
<p>Now we can pass either of these sigmas to our <code>default_rng</code> and it will draw Rayleigh samples with variances that match the chosen criteria.</p>
<blockquote class="blockquote">
<p>A quick word about <code>fanIn</code> and <code>fanOut</code>. We saw the simple feed-forward case with in our example for a single network layer. In that case the number of incoming connections was simply <code>fanIn</code> and the outgoing connections were <code>fanOut</code>.</p>
</blockquote>
<blockquote class="blockquote">
<p>However, the convolutional case is a bit more complicated. A convolutional layer has input and output feature maps which are roughly analogous to input and output units in feed-forward layers. But they also have a kernel size to consider. PyTorch has a nice <a href="https://pytorch.org/docs/stable/_modules/torch/nn/init.html#_calculate_fan_in_and_fan_out">convenience function</a> that handles this for us.</p>
</blockquote>
</section>
</section>
</section>
<section id="putting-it-all-together-a-complex-valued-pytorch-initializer" class="level1">
<h1>Putting it all together: A complex-valued PyTorch initializer</h1>
<p>Here is a recap of the previous sections: 1. We first saw a brief overview of complex numbers.<br>
2. We learned about the history of good initializations and Complex Networks.<br>
3. We analyzed the theoretical Rayleigh distribution.<br>
1. We drew some Rayleigh magnitudes to learn more about the distribution.<br>
2. We picked a random uniform phase, and saw how this orients our vectors in all directions.<br>
3. We matched our Rayleigh samples to the He and Glorot variance criteria for a single network layer.</p>
<p>To get usable initializations, we need a function that glues the important pieces together: - Draw random phase samples.<br>
- Draw Rayleigh magnitude samples.<br>
- Match the He or Glorot variance criteria.<br>
- Are PyTorch tensors with the correct shape for a given network layer.</p>
<p>We can refactor the earlier code into a function that does just this.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"></span>
<span id="cb12-2"><span class="kw" style="color: #003B4F;">def</span> get_complex_inits(module, seed<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>, criterion<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'he'</span>, dtype<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'float32'</span>):</span>
<span id="cb12-3">    <span class="co" style="color: #5E5E5E;">"""Initializes complex-valued Rayleigh weights as PyTorch tensors.</span></span>
<span id="cb12-4"><span class="co" style="color: #5E5E5E;">    """</span></span>
<span id="cb12-5">    <span class="co" style="color: #5E5E5E;"># random number generator</span></span>
<span id="cb12-6">    rand <span class="op" style="color: #5E5E5E;">=</span> default_rng(seed <span class="cf" style="color: #003B4F;">if</span> seed <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span> <span class="cf" style="color: #003B4F;">else</span> torch.initial_seed())</span>
<span id="cb12-7">    </span>
<span id="cb12-8">    <span class="co" style="color: #5E5E5E;"># get shape of the weights</span></span>
<span id="cb12-9">    weight_shape <span class="op" style="color: #5E5E5E;">=</span> module.weight.size()</span>
<span id="cb12-10">    </span>
<span id="cb12-11">    <span class="co" style="color: #5E5E5E;"># find the number of input and output connection</span></span>
<span id="cb12-12">    fan_in, fan_out <span class="op" style="color: #5E5E5E;">=</span> torch.nn.init._calculate_fan_in_and_fan_out(module.weight)</span>
<span id="cb12-13">    </span>
<span id="cb12-14">    <span class="co" style="color: #5E5E5E;"># compute the Rayleigh sigma that meets the chosen variance criteria</span></span>
<span id="cb12-15">    <span class="cf" style="color: #003B4F;">assert</span> criterion <span class="kw" style="color: #003B4F;">in</span> (<span class="st" style="color: #20794D;">'he'</span>,<span class="st" style="color: #20794D;">'glorot'</span>)</span>
<span id="cb12-16">    factor <span class="op" style="color: #5E5E5E;">=</span> fan_in <span class="cf" style="color: #003B4F;">if</span> criterion <span class="op" style="color: #5E5E5E;">==</span> <span class="st" style="color: #20794D;">'he'</span> <span class="cf" style="color: #003B4F;">else</span> fan_in <span class="op" style="color: #5E5E5E;">+</span> fan_out</span>
<span id="cb12-17">    sigma <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">1.</span> <span class="op" style="color: #5E5E5E;">/</span> np.sqrt(factor)</span>
<span id="cb12-18">    </span>
<span id="cb12-19">    <span class="co" style="color: #5E5E5E;"># draw the scaled rayleigh magnitudes</span></span>
<span id="cb12-20">    magnitude <span class="op" style="color: #5E5E5E;">=</span> rand.rayleigh(scale<span class="op" style="color: #5E5E5E;">=</span>sigma, size<span class="op" style="color: #5E5E5E;">=</span>weight_shape)</span>
<span id="cb12-21">    <span class="co" style="color: #5E5E5E;"># draw uniform angle samples</span></span>
<span id="cb12-22">    phase <span class="op" style="color: #5E5E5E;">=</span> rand.uniform(low<span class="op" style="color: #5E5E5E;">=-</span>np.pi, high<span class="op" style="color: #5E5E5E;">=</span>np.pi, size<span class="op" style="color: #5E5E5E;">=</span>magnitude.shape)</span>
<span id="cb12-23">    </span>
<span id="cb12-24">    <span class="co" style="color: #5E5E5E;"># split magnitudes into real and imaginary components</span></span>
<span id="cb12-25">    real <span class="op" style="color: #5E5E5E;">=</span> (magnitude <span class="op" style="color: #5E5E5E;">*</span> np.cos(phase)).astype(dtype)</span>
<span id="cb12-26">    imag <span class="op" style="color: #5E5E5E;">=</span> (magnitude <span class="op" style="color: #5E5E5E;">*</span> np.sin(phase)).astype(dtype)</span>
<span id="cb12-27">    </span>
<span id="cb12-28">    <span class="co" style="color: #5E5E5E;"># turn into float tensors and return</span></span>
<span id="cb12-29">    real,imag <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">map</span>(torch.from_numpy, [real,imag])</span>
<span id="cb12-30">    <span class="cf" style="color: #003B4F;">return</span> real,imag</span>
<span id="cb12-31">    </span></code></pre></div>
</div>
<p>Let’s use this function to get complex weight initializations for a Linear and Convolutional module.</p>
<section id="complex-initializations-for-nn.linear" class="level2">
<h2 class="anchored" data-anchor-id="complex-initializations-for-nn.linear">Complex initializations for <code>nn.Linear</code></h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="co" style="color: #5E5E5E;"># re-create out earlier example with a single layer</span></span>
<span id="cb13-2">fan_in, fan_out <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">100</span>, <span class="dv" style="color: #AD0000;">50</span></span>
<span id="cb13-3">sigma_he <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">1.</span> <span class="op" style="color: #5E5E5E;">/</span> np.sqrt(fan_in) <span class="co" style="color: #5E5E5E;"># to match the He criteria</span></span>
<span id="cb13-4"></span>
<span id="cb13-5"><span class="co" style="color: #5E5E5E;"># get the complex-valued weights</span></span>
<span id="cb13-6">m <span class="op" style="color: #5E5E5E;">=</span> torch.nn.Linear(fan_in, fan_out)</span>
<span id="cb13-7">real, imag <span class="op" style="color: #5E5E5E;">=</span> get_complex_inits(m)</span></code></pre></div>
</div>
<p>We should check that the magnitude of the weights actually follow a Rayleigh distribution.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="co" style="color: #5E5E5E;"># get linear magnitudes as a flat numpy vector</span></span>
<span id="cb14-2">magnitude <span class="op" style="color: #5E5E5E;">=</span> torch.sqrt(real<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span> <span class="op" style="color: #5E5E5E;">+</span> imag<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span>).numpy().reshape(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="co" style="color: #5E5E5E;"># setup the plot</span></span>
<span id="cb15-2">plt.figure(figsize<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">8</span>,<span class="dv" style="color: #AD0000;">7</span>), dpi<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">80</span>)</span>
<span id="cb15-3">plt.title(<span class="st" style="color: #20794D;">'Complex nn.Linear Weights vs. Theoretical Rayleigh PDF'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'x-large'</span>)</span>
<span id="cb15-4">plt.xlabel(<span class="st" style="color: #20794D;">'Sample Value'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'x-large'</span>)</span>
<span id="cb15-5">plt.ylabel(<span class="st" style="color: #20794D;">'Probability Density'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'x-large'</span>)</span>
<span id="cb15-6"></span>
<span id="cb15-7"><span class="co" style="color: #5E5E5E;"># pick points that cover the sample range to compare with theoretical rayleigh pdf</span></span>
<span id="cb15-8">points <span class="op" style="color: #5E5E5E;">=</span> np.linspace(<span class="dv" style="color: #AD0000;">0</span>, magnitude.<span class="bu" style="color: null;">max</span>(), <span class="dv" style="color: #AD0000;">1000</span>)</span>
<span id="cb15-9">ray_pdf <span class="op" style="color: #5E5E5E;">=</span> rayleigh_pdf(points, sigma<span class="op" style="color: #5E5E5E;">=</span>sigma_he)</span>
<span id="cb15-10"></span>
<span id="cb15-11"><span class="co" style="color: #5E5E5E;"># plot histogram of Linear magnitudes vs. the theoretical pdf</span></span>
<span id="cb15-12">plt.hist(magnitude, bins<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">35</span>, density<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb15-13">plt.plot(points, ray_pdf, c<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'r'</span>, linewidth<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">3</span>)<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-09-01-rayleigh-init/index_files/figure-html/cell-20-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Success! Our Linear module is properly initialized.</p>
</section>
<section id="complex-initializations-for-nn.conv2d" class="level2">
<h2 class="anchored" data-anchor-id="complex-initializations-for-nn.conv2d">Complex initializations for <code>nn.Conv2d</code></h2>
<p>Can we do the same for a convolutional layer? Our main concern is correctly handling both the tensor shape and <code>fan_in</code>, <code>fan_out</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="co" style="color: #5E5E5E;"># make conv layer with 100 input features, 50 output features, and (3x3) kernel</span></span>
<span id="cb16-2">k <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">3</span> <span class="co" style="color: #5E5E5E;"># kernel size</span></span>
<span id="cb16-3"><span class="co" style="color: #5E5E5E;"># now, these are the number of feature maps (chan_in and chan_out)</span></span>
<span id="cb16-4">fan_in, fan_out <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">100</span>, <span class="dv" style="color: #AD0000;">50</span></span>
<span id="cb16-5"></span>
<span id="cb16-6">conv_layer <span class="op" style="color: #5E5E5E;">=</span> torch.nn.Conv2d(fan_in, fan_out, k)</span>
<span id="cb16-7">real_conv, imag_conv <span class="op" style="color: #5E5E5E;">=</span> get_complex_inits(conv_layer) <span class="co" style="color: #5E5E5E;"># get the initial complex weights</span></span>
<span id="cb16-8"></span>
<span id="cb16-9"><span class="co" style="color: #5E5E5E;"># make sure the shape of weights is ok</span></span>
<span id="cb16-10"><span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f'Shapes of real and imaginary convolutional tensors: </span><span class="sc" style="color: #5E5E5E;">{</span>real_conv<span class="sc" style="color: #5E5E5E;">.</span>shape<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">, </span><span class="sc" style="color: #5E5E5E;">{</span>imag_conv<span class="sc" style="color: #5E5E5E;">.</span>shape<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Shapes of real and imaginary convolutional tensors: torch.Size([50, 100, 3, 3]), torch.Size([50, 100, 3, 3])</code></pre>
</div>
</div>
<p>Let’s check if these convolutional weights are still Rayleigh distributed.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="co" style="color: #5E5E5E;"># get convolutional magnitudes as a flat numpy vector</span></span>
<span id="cb18-2">conv_magnitude <span class="op" style="color: #5E5E5E;">=</span> torch.sqrt(real_conv<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span> <span class="op" style="color: #5E5E5E;">+</span> imag_conv<span class="op" style="color: #5E5E5E;">**</span><span class="dv" style="color: #AD0000;">2</span>).numpy().reshape(<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>)</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="co" style="color: #5E5E5E;"># setup the plots</span></span>
<span id="cb19-2">plt.figure(figsize<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">8</span>,<span class="dv" style="color: #AD0000;">7</span>), dpi<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">80</span>)</span>
<span id="cb19-3">plt.title(<span class="st" style="color: #20794D;">'Complex nn.Conv2d Weights vs. Theoretical Rayleigh PDF'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'x-large'</span>)</span>
<span id="cb19-4">plt.xlabel(<span class="st" style="color: #20794D;">'Sample Value'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'x-large'</span>)</span>
<span id="cb19-5">plt.ylabel(<span class="st" style="color: #20794D;">'Probability Density'</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'x-large'</span>)</span>
<span id="cb19-6"></span>
<span id="cb19-7"></span>
<span id="cb19-8"><span class="co" style="color: #5E5E5E;"># pick points that cover sample range to compare with theoretical rayleigh pdf</span></span>
<span id="cb19-9">points <span class="op" style="color: #5E5E5E;">=</span> np.linspace(<span class="dv" style="color: #AD0000;">0</span>, conv_magnitude.<span class="bu" style="color: null;">max</span>(), <span class="dv" style="color: #AD0000;">1000</span>)</span>
<span id="cb19-10"></span>
<span id="cb19-11"><span class="co" style="color: #5E5E5E;"># note: we need to re-compute fanIn for the convolutional layer</span></span>
<span id="cb19-12">fan_in, fan_out <span class="op" style="color: #5E5E5E;">=</span> torch.nn.init._calculate_fan_in_and_fan_out(conv_layer.weight)</span>
<span id="cb19-13">sigma_he_conv <span class="op" style="color: #5E5E5E;">=</span> sigma<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">1.</span> <span class="op" style="color: #5E5E5E;">/</span> np.sqrt(fan_in)</span>
<span id="cb19-14"></span>
<span id="cb19-15">ray_pdf <span class="op" style="color: #5E5E5E;">=</span> rayleigh_pdf(points, sigma_he_conv)</span>
<span id="cb19-16"></span>
<span id="cb19-17"><span class="co" style="color: #5E5E5E;"># plot histogram of magnitudes vs. theoretical pdf</span></span>
<span id="cb19-18">plt.hist(conv_magnitude, bins<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">35</span>, density<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb19-19">plt.plot(points, ray_pdf, c<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'r'</span>, linewidth<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">3</span>)<span class="op" style="color: #5E5E5E;">;</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://enzokro.dev/blog/posts/2022-09-01-rayleigh-init/index_files/figure-html/cell-23-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Another match! Our convolutional layer is also properly initialized.</p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>In this post we created Rayleigh initializations for complex-valued neural networks.</p>
<p>We started with an overview of complex numbers and weight initializations. Next we moved on to the history of Complex Networks and the Rayleigh distribution.</p>
<p>Then we used the Rayleigh distribution to sample the magnitudes of complex-valued weights. We then added uniform phase information to randomly orient the vectors. After that, we made sure that the variance of our complex weights made them good initial values.</p>
<p>Finally, we put all everything together into a python function that return complex initialization tensors. This initialization function will be the first building block of complex-valued neural networks.</p>


</section>

 ]]></description>
  <category>deep learning</category>
  <category>complex networks</category>
  <guid>https://enzokro.dev/blog/posts/2022-09-01-rayleigh-init/index.html</guid>
  <pubDate>Thu, 01 Sep 2022 00:00:00 GMT</pubDate>
  <media:content url="https://enzokro.dev/blog/posts/2022-09-01-rayleigh-init/polar_plot.png" medium="image" type="image/png" height="141" width="144"/>
</item>
<item>
  <title>Normalizing spectrograms for Deep Learning</title>
  <dc:creator>enzokro</dc:creator>
  <link>https://enzokro.dev/blog/posts/2022-08-20-spec-norms/index.html</link>
  <description><![CDATA[ 



<section id="how-to-normalize-spectrograms" class="level1">
<h1>How to normalize spectrograms</h1>
<blockquote class="blockquote">
<p>Scaling spectrograms for classification tasks with neural networks.</p>
</blockquote>
</section>
<section id="note-under-heavy-construction" class="level1">
<h1><strong>NOTE: under heavy construction</strong></h1>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Spectrograms are often used as images to train deep neural networks for audio tasks. By treating spectrograms as images, we can borrow from the many powerful ideas in image recognition with deep learning. A spectrogram, however, is fundamentally different than natural images as we will see below. That brings up the central question of this post: how should spectrograms be normalized during training?</p>
<p>This post assumes some familiarity with deep learning and signal processing concepts like the FFT. It is also a light introduction to the <a href="https://github.com/fastaudio/fastaudio">fastaudio</a> library.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span></code></pre></div>
</details>
</div>
</section>
<section id="transforming-audio-into-two-dimensions" class="level1">
<h1>Transforming audio into two dimensions</h1>
<p>Image classification is a challenging task that was previously done with expert, handcrafted features. Now, features are automatically learned from labeled data instead. The success of these learned features has completely shifted the paradigm of Computer Vision. We would ideally like to apply these same, proven techniques on audio tasks.</p>
<p>However, audio is treated like a one dimensional signal in most Machine Learning applications. That means raw audio is unusable with 2-D Convolutional Neural Networks (CNNs), which are the workhorses of modern image recognition. If we could somehow represent audio in two dimensions, like an image, then we could leverage the successful approaches in image classification.</p>
<p>Thankfully there are many ways of transforming audio into two dimensions. The most popular one is turning audio into a <a href="https://ccrma.stanford.edu/~jos/mdft/Spectrograms.html">spectrogram</a>. As an example, the image below shows the spectrogram of this <a href="https://upload.wikimedia.org/wikipedia/commons/d/d1/Violin_for_spectrogram.ogg">violin recording</a> taken from Wikipedia.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<figure class="figure">
<img src="https://enzokro.dev/blog/posts/2022-08-20-spec-norms/images/violin_spec.png" title="Spectrogram of a violing recording." class="img-fluid figure-img">
</figure>
<p></p><figcaption class="figure-caption">The spectrogram of a violin recording</figcaption><p></p>
</figure>
</div>
<p>The spectrogram is a 2-D signal representation in time and frequency, so we can use it with 2-D CNNs! But first it is crucial to preprocess and normalize the spectrograms. Neural networks have a much easier time learning when their inputs are normalized.</p>
<p>For natural images, normalization uses an estimated mean (<img src="https://latex.codecogs.com/png.latex?%5Cmu">) and standard deviation (<img src="https://latex.codecogs.com/png.latex?%5Csigma">) as follows: - Subtract <img src="https://latex.codecogs.com/png.latex?%5Cmu"> from the image values to give them a mean of <img src="https://latex.codecogs.com/png.latex?0">. - Divide the image values by <img src="https://latex.codecogs.com/png.latex?%5Csigma"> to give them a variance of <img src="https://latex.codecogs.com/png.latex?1">.</p>
<p>In math terms, if <img src="https://latex.codecogs.com/png.latex?x"> is our image then <img src="https://latex.codecogs.com/png.latex?x_%7B%5Ctext%7Bnorm%7D%7D"> is: <img src="https://latex.codecogs.com/png.latex?x_%7B%5Ctext%7Bnorm%7D%7D%20=%20%5Cfrac%7B(x%20-%20%5Cmu)%7D%7B%5Csigma%7D"></p>
<p>Since spectrograms are fundamentally different than natural images, we should reevaluate if this same normalization makes sense.</p>
</section>
<section id="why-spectrograms-are-not-images-and-how-to-normalize-them" class="level1">
<h1>Why spectrograms are not images and how to normalize them</h1>
<p>Now we can describe what makes spectrograms different from natural images. We start with a high-level overview of images and their normalization, then do the same for spectrograms. A quick recap of how spectrograms are computed will further show how different they are from images. This recap naturally leads to a specific normalization for spectrogram features. Finally, we talk about Transfer Learning and why we avoid it in this post.</p>
<p>In an image, both axes (height and width) are in the spatial domain and at the same scale. Images are stored as integers in the range of <code>[0, 255]</code>. To normalize them we first divide all pixels by 255, the max possible value, to map them into the range <code>[0, 1]</code>. Then, we find the statistics that approximately center the data with a mean of <img src="https://latex.codecogs.com/png.latex?0"> and a variance of <img src="https://latex.codecogs.com/png.latex?1">. The three RGB channels in a color image are normalized separately. If an image is greyscale then we normalize its single channel instead.</p>
<p>The axes in a spectrogram are from different domains than the axes in an image. In a spectrogram, the horizontal axis represents time and the vertical axis represents frequency. Each of these quantities has its own scale. The frequency dimension is determined by the size of the FFT window. The time dimension is set by the total length of the signal, the size of the FFT window, and the hop size of the window. You can check the documentation of the <a href="https://pytorch.org/docs/stable/generated/torch.stft.html">torch.stft</a> function for a breakdown of how each axis is determined.</p>
<p>To be more specific, a spectrogram is actually the log of the power spectrum. Below we give a quick recap of how the spectrogram is computed to show how much it differs from images.</p>
<p>If <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Bx%7D"> is our input audio then the STFT returns the spectrum: <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Bspectrum%7D%20=%20%5Ctext%7BSTFT(x)%7D"> We are more interested in the energy or power of the signal, so we take the absolute value of the STFT and square it:<br>
<img src="https://latex.codecogs.com/png.latex?%5Ctext%7BpowerSpectrum%7D%20=%20%7C%5Ctext%7BSTFT(x)%7D%7C%5E2"> We cannot use the power spectrum as a feature because it has a few strong peaks and many small values. You can check this other <a href="https://danielsdiscoveries.wordpress.com/2017/09/29/spectrogram-input-normalisation-for-neural-networks/">fantastic post</a> on spectrogram normalization to learn why this is a problem. Taking the log of the power spectrum spreads out the values and makes them better features. This becomes the spectrogram: <img src="https://latex.codecogs.com/png.latex?%5Ctext%7Bspectrogram%7D%20=%20log(%7C%5Ctext%7BSTFT(x)%7D%7C%5E2)"> The range of the log function is <img src="https://latex.codecogs.com/png.latex?-%5Cinfty"> to <img src="https://latex.codecogs.com/png.latex?+%5Cinfty"> which is clearly different than the integers from 0 to 255 in an image.</p>
<p>A spectrogram transformation can also be thought of as a very simple <a href="https://en.wikipedia.org/wiki/Channelizer">“channelizer”</a> in Digital Signal Processing (DSP) terms. That is a fancy way of saying that it splits the continuous frequency spectrum of a signal into discrete bins, or channels. For example, consider taking a spectrogram with 512 bins from a signal sampled at 16 kHz. This spectrogram will have 512 channels where each channel has a “bandwidth” of <img src="https://latex.codecogs.com/png.latex?16%20%5C%20%5Ctext%7BkHz%7D%20%5C%20%5C%20/%20%5C%20%5C%20512%20%5C%20%5Ctext%7Bbins%7D%20=%2031.25%20%5C%20%5Ctext%7BHz%20per%20bin%7D"></p>
<p><a href="https://en.wikipedia.org/wiki/Communication_channel">Spectrogram channels</a> are very different from the image channels we are used to. So it raises the question: should we normalize the entire spectrogram “image” with a single, global value? Or should we normalize each spectrogram channel just like the channels in an image? In the rest of this post, we compare global and channel-based spectrogram normalizations on a real-world dataset to find which is better.</p>
<section id="a-quick-note-on-transfer-learning" class="level2">
<h2 class="anchored" data-anchor-id="a-quick-note-on-transfer-learning">A quick note on Transfer Learning</h2>
<p>We also have to talk about Transfer Learning in the context of normalization. In Transfer Learning, it is best-practice to normalize the new dataset with the statistics from the old dataset. This makes sure that the new network inputs are at the same scale as the original inputs. Since most pretrained vision models were trained on ImageNet, we normalize any new inputs with ImageNet statistics.<br>
However, we avoid Transfer Learning in this post and instead train an 18-layer xResNet from scratch. The reason is that pretrained image models operate at a completely different scale than spectrograms. And the main goal here is to learn our own scalings instead!</p>
</section>
</section>
<section id="downloading-a-sample-dataset" class="level1">
<h1>Downloading a sample dataset</h1>
<p>To keep things practical, we will apply these spectrogram normalization techniques to a <a href="https://github.com/fastaudio/Audio-Competition">sound classification challenge</a> hosted by fastaudio. <a href="https://github.com/fastaudio/fastaudio">fastaudio</a> is a community extension of the <a href="https://github.com/fastai/fastai/tree/master/fastai">fastai</a> library to make audio tasks with neural networks more accessible.<br>
The challenge here is to classify sounds in the <a href="https://github.com/karolpiczak/ESC-50">ESC-50 dataset</a>, where ESC-50 stands for “Environment Sound Classification with 50 classes”. This dataset has many different types of sounds which show how varied audio spectrograms can be.</p>
<p>Many of the lines below are based on the fastaudio <a href="https://github.com/fastaudio/Audio-Competition/blob/master/ESC-50-baseline-1Fold.ipynb">baseline results notebook</a>.</p>
<section id="the-esc-50-dataset" class="level2">
<h2 class="anchored" data-anchor-id="the-esc-50-dataset">The ESC-50 dataset</h2>
<p>The first step is to download the data. ESC-50 is already included in fastaudio so we can grab it with <code>untar_data</code>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;"># from fastai.vision.all import *</span></span>
<span id="cb2-2"><span class="co" style="color: #5E5E5E;"># from fastaudio.core.all import *</span></span>
<span id="cb2-3"><span class="co" style="color: #5E5E5E;"># from fastaudio.augment.all import *</span></span>
<span id="cb2-4"></span>
<span id="cb2-5"><span class="co" style="color: #5E5E5E;"># already in fastaudio, can download with fastai's `untar_data`</span></span>
<span id="cb2-6"><span class="co" style="color: #5E5E5E;"># path = untar_data(URLs.ESC50)</span></span></code></pre></div>
</details>
</div>
<p>The downloaded audio files are inside the aptly named <code>audio</code> folder. Below we use the <code>ls</code> method, a fastai addition to python’s <code>pathlib.Path</code>, to check the contents of this folder.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="co" style="color: #5E5E5E;"># wavs = (path/"audio").ls()</span></span>
<span id="cb3-2"><span class="co" style="color: #5E5E5E;"># wavs</span></span></code></pre></div>
</details>
</div>
<p>The output of <code>ls</code> shows 2,000 audio files. But the filenames are not very descriptive, so how do we know what is actually in each one?<br>
Thankfully, as with many datasets, the download includes a table with more information about the data (aka metadata).</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;"># # read the audio metadata and show the first few rows</span></span>
<span id="cb4-2"><span class="co" style="color: #5E5E5E;"># df = pd.read_csv(path/"meta"/"esc50.csv")</span></span>
<span id="cb4-3"><span class="co" style="color: #5E5E5E;"># df.head()</span></span></code></pre></div>
</details>
</div>
<p>The key info from this table are in the <code>filename</code> and <code>category</code> columns.<br>
<code>filename</code> gives the name of a file inside of the <code>audio</code> folder.<br>
<code>category</code> tells us which class a file belongs to.</p>
<p>The last file in the data directory will be our working example for normalization. We can index into the metadata table above using this file’s <code>name</code> to learn more about it.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="co" style="color: #5E5E5E;"># # pick the row where "filename" matches the file's "name".</span></span>
<span id="cb5-2"><span class="co" style="color: #5E5E5E;"># df.loc[df.filename == wavs[-1].name]</span></span></code></pre></div>
</details>
</div>
<p>This is a recording of crickets!<br>
We can load this file with the <code>AudioTensor</code> class in fastaudio. Its <code>create</code> function reads the audio samples straight into a <code>torch.Tensor</code>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="co" style="color: #5E5E5E;"># # create an AudioTensor from a file path</span></span>
<span id="cb6-2"><span class="co" style="color: #5E5E5E;"># sample = AudioTensor.create(wavs[-1])</span></span></code></pre></div>
</details>
</div>
<p>An <code>AudioTensor</code> can plot and even play the audio with its <code>show</code> method.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="co" style="color: #5E5E5E;"># print(f'Audio shape [channels, samples]: {sample.shape}')</span></span>
<span id="cb7-2"><span class="co" style="color: #5E5E5E;"># sample.show();</span></span></code></pre></div>
</details>
</div>
<p>Each “burst” in the plot above is a cricket chirp. There are three full chirps and the early starts of a fourth chirp.</p>
</section>
</section>
<section id="normalizing-an-audio-waveform" class="level1">
<h1>Normalizing an audio waveform</h1>
<p>The first step is normalizing the audio waveform itself. We give it a mean of zero and unit variance in the usual way:</p>
<p><img src="https://latex.codecogs.com/png.latex?%5Ctext%7BnormedAudio%7D%20=%20%5Cfrac%7B%5Ctext%7Baudio%7D%20-%20mean(%5Ctext%7Baudio%7D)%7D%7Bstd(%5Ctext%7Baudio%7D)%7D%20"></p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="co" style="color: #5E5E5E;"># # normalize the waveform</span></span>
<span id="cb8-2"><span class="co" style="color: #5E5E5E;"># norm_sample = (sample - sample.mean()) / sample.std()</span></span></code></pre></div>
</details>
</div>
<p>Let’s check if the mean is roughly <img src="https://latex.codecogs.com/png.latex?0"> and the variance is roughly <img src="https://latex.codecogs.com/png.latex?1">:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="co" style="color: #5E5E5E;"># # checking the mean</span></span>
<span id="cb9-2"><span class="co" style="color: #5E5E5E;"># print(f'Original audio mean:   {sample.mean()}')</span></span>
<span id="cb9-3"><span class="co" style="color: #5E5E5E;"># print(f'Normalized audio mean: {norm_sample.mean()}')</span></span></code></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="co" style="color: #5E5E5E;"># # checking the standard deviation</span></span>
<span id="cb10-2"><span class="co" style="color: #5E5E5E;"># print(f'Original audio standard dev:   {sample.var()}')</span></span>
<span id="cb10-3"><span class="co" style="color: #5E5E5E;"># print(f'Normalized audio standard dev: {norm_sample.var()}')</span></span></code></pre></div>
</details>
</div>
<p>Success! The waveform is normalized.</p>
<p>For convenience later on, we define the <code>AudioNormalize</code> transform to normalize waveforms in a fastai training loop.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="co" style="color: #5E5E5E;"># class AudioNormalize(Transform):</span></span>
<span id="cb11-2"><span class="co" style="color: #5E5E5E;">#     "Normalizes a single `AudioTensor`."</span></span>
<span id="cb11-3"><span class="co" style="color: #5E5E5E;">#     def encodes(self, x:AudioTensor): return (x-x.mean()) / x.std()</span></span></code></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="co" style="color: #5E5E5E;"># # checking if the Transform normalized the waveform</span></span>
<span id="cb12-2"><span class="co" style="color: #5E5E5E;"># wav_norm = AudioNormalize()</span></span>
<span id="cb12-3"><span class="co" style="color: #5E5E5E;"># norm_sample = wav_norm(sample)</span></span>
<span id="cb12-4"><span class="co" style="color: #5E5E5E;"># print(f'Audio mean after transform: {norm_sample.mean()}')</span></span>
<span id="cb12-5"><span class="co" style="color: #5E5E5E;"># print(f'Audio standard dev after transform: {norm_sample.var()}')</span></span></code></pre></div>
</details>
</div>
</section>
<section id="extracting-spectrograms-from-audio" class="level1">
<h1>Extracting spectrograms from audio</h1>
<p>The next step is to extract a spectrogram from the normalized audio. We can do this with the <code>AudioToSpec</code> class in fastaudio. This class takes an <code>AudioTensor</code> as input and, as we might expect, returns an <code>AudioSpectrogram</code>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="co" style="color: #5E5E5E;"># # create a fastaudio Transform to convert audio into spectrograms</span></span>
<span id="cb13-2"><span class="co" style="color: #5E5E5E;"># cfg = AudioConfig.BasicSpectrogram() # with default torchaudio parameters</span></span>
<span id="cb13-3"><span class="co" style="color: #5E5E5E;"># audio2spec = AudioToSpec.from_cfg(cfg)</span></span>
<span id="cb13-4"></span>
<span id="cb13-5"><span class="co" style="color: #5E5E5E;"># # extract the spectrogram</span></span>
<span id="cb13-6"><span class="co" style="color: #5E5E5E;"># spec = audio2spec(norm_sample)</span></span></code></pre></div>
</details>
</div>
<p>The <code>show</code> method of the <code>AudioSpectrogram</code> is a great, quick way to plot the spectrogram.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="co" style="color: #5E5E5E;"># print(f'Spectrogram shape [channels, bins, time_steps]: {spec.shape}')</span></span>
<span id="cb14-2"><span class="co" style="color: #5E5E5E;"># spec.show();</span></span></code></pre></div>
</details>
</div>
<p>The colorbar on the right showing the power in the signal is especially helpful since <code>matplotlib</code> always scales the values in a plot to the same color range. Without this colorbar, it is impossible to know or even guess the specific values in a spectrogram plot.</p>
</section>
<section id="finding-spectrogram-normalization-stats" class="level1">
<h1>Finding spectrogram normalization stats</h1>
<p>To get the normalization stats, we have to step through the training set and find the mean and standard deviation of each mini-batch. Then we average all the mini-batch statistics to get a single pair of (<img src="https://latex.codecogs.com/png.latex?%5Cmu,%5Csigma)"> normalization statistics. Note that normalization statistics must alway come from the training set. This is a crucial place to avoid data leakage.</p>
<p>One small detail: if your training dataset is large enough it is not necessary to go through the whole set. Sampling 10% to 20% of the dataset can be enough for accurate statistics. However, since ESC-50 is small we find (<img src="https://latex.codecogs.com/png.latex?%5Cmu,%5Csigma)"> from the whole set.</p>
<p>To accumulate these statistics over mini-batches we can borrow and slightly refactor a class from this <a href="http://notmatthancock.github.io/2017/03/23/simple-batch-stat-updates.html">very helpful post</a>. The <code>StatsRecorder</code> class below tracks the mean and standard deviation across mini-batches.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><span class="co" style="color: #5E5E5E;"># class StatsRecorder:</span></span>
<span id="cb15-2"><span class="co" style="color: #5E5E5E;">#     def __init__(self, red_dims=(0,2,3)):</span></span>
<span id="cb15-3"><span class="co" style="color: #5E5E5E;">#         """Accumulates normalization statistics across mini-batches.</span></span>
<span id="cb15-4"><span class="co" style="color: #5E5E5E;">#         ref: http://notmatthancock.github.io/2017/03/23/simple-batch-stat-updates.html</span></span>
<span id="cb15-5"><span class="co" style="color: #5E5E5E;">#         """</span></span>
<span id="cb15-6"><span class="co" style="color: #5E5E5E;">#         self.red_dims = red_dims # which mini-batch dimensions to average over</span></span>
<span id="cb15-7"><span class="co" style="color: #5E5E5E;">#         self.nobservations = 0   # running number of observations</span></span>
<span id="cb15-8"></span>
<span id="cb15-9"><span class="co" style="color: #5E5E5E;">#     def update(self, data):</span></span>
<span id="cb15-10"><span class="co" style="color: #5E5E5E;">#         """</span></span>
<span id="cb15-11"><span class="co" style="color: #5E5E5E;">#         data: ndarray, shape (nobservations, ndimensions)</span></span>
<span id="cb15-12"><span class="co" style="color: #5E5E5E;">#         """</span></span>
<span id="cb15-13"><span class="co" style="color: #5E5E5E;">#         # initialize stats and dimensions on first batch</span></span>
<span id="cb15-14"><span class="co" style="color: #5E5E5E;">#         if self.nobservations == 0:</span></span>
<span id="cb15-15"><span class="co" style="color: #5E5E5E;">#             self.mean = data.mean(dim=self.red_dims, keepdim=True)</span></span>
<span id="cb15-16"><span class="co" style="color: #5E5E5E;">#             self.std  = data.std (dim=self.red_dims,keepdim=True)</span></span>
<span id="cb15-17"><span class="co" style="color: #5E5E5E;">#             self.nobservations = data.shape[0]</span></span>
<span id="cb15-18"><span class="co" style="color: #5E5E5E;">#             self.ndimensions   = data.shape[1]</span></span>
<span id="cb15-19"><span class="co" style="color: #5E5E5E;">#         else:</span></span>
<span id="cb15-20"><span class="co" style="color: #5E5E5E;">#             if data.shape[1] != self.ndimensions:</span></span>
<span id="cb15-21"><span class="co" style="color: #5E5E5E;">#                 raise ValueError('Data dims do not match previous observations.')</span></span>
<span id="cb15-22">            </span>
<span id="cb15-23"><span class="co" style="color: #5E5E5E;">#             # find mean of new mini batch</span></span>
<span id="cb15-24"><span class="co" style="color: #5E5E5E;">#             newmean = data.mean(dim=self.red_dims, keepdim=True)</span></span>
<span id="cb15-25"><span class="co" style="color: #5E5E5E;">#             newstd  = data.std(dim=self.red_dims, keepdim=True)</span></span>
<span id="cb15-26">            </span>
<span id="cb15-27"><span class="co" style="color: #5E5E5E;">#             # update number of observations</span></span>
<span id="cb15-28"><span class="co" style="color: #5E5E5E;">#             m = self.nobservations * 1.0</span></span>
<span id="cb15-29"><span class="co" style="color: #5E5E5E;">#             n = data.shape[0]</span></span>
<span id="cb15-30"></span>
<span id="cb15-31"><span class="co" style="color: #5E5E5E;">#             # update running statistics</span></span>
<span id="cb15-32"><span class="co" style="color: #5E5E5E;">#             tmp = self.mean</span></span>
<span id="cb15-33"><span class="co" style="color: #5E5E5E;">#             self.mean = m/(m+n)*tmp + n/(m+n)*newmean</span></span>
<span id="cb15-34"><span class="co" style="color: #5E5E5E;">#             self.std  = m/(m+n)*self.std**2 + n/(m+n)*newstd**2 +\</span></span>
<span id="cb15-35"><span class="co" style="color: #5E5E5E;">#                         m*n/(m+n)**2 * (tmp - newmean)**2</span></span>
<span id="cb15-36"><span class="co" style="color: #5E5E5E;">#             self.std  = torch.sqrt(self.std)</span></span>
<span id="cb15-37">                                 </span>
<span id="cb15-38"><span class="co" style="color: #5E5E5E;">#             # update total number of seen samples</span></span>
<span id="cb15-39"><span class="co" style="color: #5E5E5E;">#             self.nobservations += n</span></span></code></pre></div>
</details>
</div>
<p>By default <code>StatsRecorder</code> averages over the image channel dimensions (grayscale or RGB). The <code>red_dims</code> argument might look familiar from normalization code in other Computer Vision tasks (also the <code>Normalize</code> in fastai).<br>
To average over spectrogram channels instead we only need to pass a different <code>red_dims</code>.</p>
<section id="building-the-dataset-loader" class="level2">
<h2 class="anchored" data-anchor-id="building-the-dataset-loader">Building the dataset loader</h2>
<p>The setup below follows the fastaudio ESC-50 baseline to step through the training dataset. It is worth mentioning that the files in ESC-50 are sampled 44.1 kHz, but fastaudio will resample them to 16 kHz by default. Downsampling like this risks throwing away some information. But, keeping the higher sampling rate almost triples the “width” (aka time) of the spectrogram. This larger image will take up more memory in the GPU and limits our batch size and architecture choices. We keep this downsampling since it gives the spectrograms a very reasonable shape of <code>[201, 401]</code>, compared with the much larger shape of <code>[201, 1103]</code> if we don’t downsample.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><span class="co" style="color: #5E5E5E;"># def CrossValidationSplitter(col='fold', fold=1):</span></span>
<span id="cb16-2"><span class="co" style="color: #5E5E5E;">#     "Split `items` (supposed to be a dataframe) by fold in `col`"</span></span>
<span id="cb16-3"><span class="co" style="color: #5E5E5E;">#     def _inner(o):</span></span>
<span id="cb16-4"><span class="co" style="color: #5E5E5E;">#         assert isinstance(o, pd.DataFrame), "ColSplitter only works when your items are a pandas DataFrame"</span></span>
<span id="cb16-5"><span class="co" style="color: #5E5E5E;">#         col_values = o.iloc[:,col] if isinstance(col, int) else o[col]</span></span>
<span id="cb16-6"><span class="co" style="color: #5E5E5E;">#         valid_idx = (col_values == fold).values.astype('bool')</span></span>
<span id="cb16-7"><span class="co" style="color: #5E5E5E;">#         return IndexSplitter(mask2idxs(valid_idx))(o)</span></span>
<span id="cb16-8"><span class="co" style="color: #5E5E5E;">#     return _inner</span></span>
<span id="cb16-9"></span>
<span id="cb16-10"><span class="co" style="color: #5E5E5E;"># auds = DataBlock(blocks=(AudioBlock, CategoryBlock),  </span></span>
<span id="cb16-11"><span class="co" style="color: #5E5E5E;">#                  get_x=ColReader("filename", pref=path/"audio"), </span></span>
<span id="cb16-12"><span class="co" style="color: #5E5E5E;">#                  splitter=CrossValidationSplitter(fold=1),</span></span>
<span id="cb16-13"><span class="co" style="color: #5E5E5E;">#                  item_tfms = [AudioNormalize],</span></span>
<span id="cb16-14"><span class="co" style="color: #5E5E5E;">#                  batch_tfms = [audio2spec],</span></span>
<span id="cb16-15"><span class="co" style="color: #5E5E5E;">#                  get_y=ColReader("category"))</span></span>
<span id="cb16-16"><span class="co" style="color: #5E5E5E;"># dbunch = auds.dataloaders(df, bs=64)</span></span>
<span id="cb16-17"><span class="co" style="color: #5E5E5E;"># dbunch.show_batch(figsize=(7,7))</span></span></code></pre></div>
</details>
</div>
</section>
<section id="calculating-the-statistics" class="level2">
<h2 class="anchored" data-anchor-id="calculating-the-statistics">Calculating the statistics</h2>
<p>Next we make two recorders: one for global statistics and the other for channel-based statistics. Then we step through the training dataset to find both sets of stats.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><span class="co" style="color: #5E5E5E;"># # create recorders</span></span>
<span id="cb17-2"><span class="co" style="color: #5E5E5E;"># global_stats  = StatsRecorder()</span></span>
<span id="cb17-3"><span class="co" style="color: #5E5E5E;"># channel_stats = StatsRecorder(red_dims=(0,1,3))</span></span>
<span id="cb17-4"></span>
<span id="cb17-5"><span class="co" style="color: #5E5E5E;"># # step through the training dataset</span></span>
<span id="cb17-6"><span class="co" style="color: #5E5E5E;"># with torch.no_grad():</span></span>
<span id="cb17-7"><span class="co" style="color: #5E5E5E;">#     for idx,(x,y) in enumerate(iter(dbunch.train)):</span></span>
<span id="cb17-8"><span class="co" style="color: #5E5E5E;">#         # update normalization statistics</span></span>
<span id="cb17-9"><span class="co" style="color: #5E5E5E;">#         global_stats.update(x)</span></span>
<span id="cb17-10"><span class="co" style="color: #5E5E5E;">#         channel_stats.update(x)</span></span>
<span id="cb17-11">    </span>
<span id="cb17-12"><span class="co" style="color: #5E5E5E;"># # parse out both sets of stats</span></span>
<span id="cb17-13"><span class="co" style="color: #5E5E5E;"># global_mean,global_std = global_stats.mean,global_stats.std</span></span>
<span id="cb17-14"><span class="co" style="color: #5E5E5E;"># channel_mean,channel_std = channel_stats.mean,channel_stats.std</span></span></code></pre></div>
</details>
</div>
<p>We can check the shape of the statistics to make sure they are correct. For the global statistics, we expect a shape of: <code>[1,1,1,1]</code>. With spectrogram channel normalizations, we expect one value per spectrogram bin for a shape of <code>[1,1,201,1]</code>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><span class="co" style="color: #5E5E5E;"># print(f'Shape of global mean: {global_mean.shape}')</span></span>
<span id="cb18-2"><span class="co" style="color: #5E5E5E;"># print(f'Shape of global standard dev: {global_std.shape}')</span></span></code></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><span class="co" style="color: #5E5E5E;"># print(f'Shape of channel mean: {channel_mean.shape}')</span></span>
<span id="cb19-2"><span class="co" style="color: #5E5E5E;"># print(f'Shape of channel standard dev: {channel_std.shape}')</span></span></code></pre></div>
</details>
</div>
</section>
</section>
<section id="training-with-normalizations" class="level1">
<h1>Training with normalizations</h1>
<p>Now for the moment of truth. We train with the two different spectrogram normalizations and measure their impact. For this we again follow the fastaudio baseline and train each type of normalization for 20 epochs. The final score is the averaged accuracy of five runs.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="co" style="color: #5E5E5E;"># epochs = 20</span></span>
<span id="cb20-2"><span class="co" style="color: #5E5E5E;"># num_runs = 5</span></span></code></pre></div>
</details>
</div>
<section id="transforms-to-normalize-mini-batches" class="level2">
<h2 class="anchored" data-anchor-id="transforms-to-normalize-mini-batches"><code>Transforms</code> to normalize mini-batches</h2>
<p>We need to extend the fastai <code>Normalize</code> class in order to use the spectrogram normalization statistics. The reason is type dispatch. fastai normalization uses ImageNet statistics due to the focus on transfer learning with color images. But this ImageNet normalization is only applied on RGB images of the <code>TensorImage</code> class, while <code>AudioSpectrogram</code> subclasses the different <code>TensorImageBase</code>. The solution is to define <code>encodes</code> and <code>decodes</code> for <code>TensorImageBase</code> instead.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><span class="co" style="color: #5E5E5E;"># class SpecNormalize(Normalize):</span></span>
<span id="cb21-2"><span class="co" style="color: #5E5E5E;">#     "Normalize/denorm batch of `TensorImage`"</span></span>
<span id="cb21-3"><span class="co" style="color: #5E5E5E;">#     def encodes(self, x:TensorImageBase): return (x-self.mean) / self.std</span></span>
<span id="cb21-4"><span class="co" style="color: #5E5E5E;">#     def decodes(self, x:TensorImageBase):</span></span>
<span id="cb21-5"><span class="co" style="color: #5E5E5E;">#         f = to_cpu if x.device.type=='cpu' else noop</span></span>
<span id="cb21-6"><span class="co" style="color: #5E5E5E;">#         return (x*f(self.std) + f(self.mean))</span></span></code></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="co" style="color: #5E5E5E;"># # make global and channel normalizers</span></span>
<span id="cb22-2"><span class="co" style="color: #5E5E5E;"># GlobalSpecNorm  = SpecNormalize(global_mean,  global_std,  axes=(0,2,3))</span></span>
<span id="cb22-3"><span class="co" style="color: #5E5E5E;"># ChannelSpecNorm = SpecNormalize(channel_mean, channel_std, axes=(0,1,3))</span></span></code></pre></div>
</details>
</div>
</section>
<section id="training-helpers" class="level2">
<h2 class="anchored" data-anchor-id="training-helpers">Training helpers</h2>
<p>To avoid repeating ourselves, the helper functions below build the dataloaders and run the training loops.<br>
The <code>get_dls</code> function makes it clear which normalization is being applied. The <code>train_loops</code> function repeats training runs a given number of times.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="co" style="color: #5E5E5E;"># def get_dls(bs=64, item_tfms=[], batch_tfms=[]):</span></span>
<span id="cb23-2"><span class="co" style="color: #5E5E5E;">#     "Get dataloaders with given `bs` and batch/item tfms."</span></span>
<span id="cb23-3"><span class="co" style="color: #5E5E5E;">#     auds = DataBlock(blocks=(AudioBlock, CategoryBlock),  </span></span>
<span id="cb23-4"><span class="co" style="color: #5E5E5E;">#                      get_x=ColReader("filename", pref=path/"audio"), </span></span>
<span id="cb23-5"><span class="co" style="color: #5E5E5E;">#                      splitter=CrossValidationSplitter(fold=1),</span></span>
<span id="cb23-6"><span class="co" style="color: #5E5E5E;">#                      item_tfms=item_tfms,   # for waveform normalization</span></span>
<span id="cb23-7"><span class="co" style="color: #5E5E5E;">#                      batch_tfms=batch_tfms, # for spectrogram normalization</span></span>
<span id="cb23-8"><span class="co" style="color: #5E5E5E;">#                      get_y=ColReader("category"))</span></span>
<span id="cb23-9"><span class="co" style="color: #5E5E5E;">#     dls = auds.dataloaders(df, bs=bs)</span></span>
<span id="cb23-10"><span class="co" style="color: #5E5E5E;">#     return dls</span></span>
<span id="cb23-11"></span>
<span id="cb23-12"><span class="co" style="color: #5E5E5E;"># def make_xresnet_grayscale(model, n_in=1):</span></span>
<span id="cb23-13"><span class="co" style="color: #5E5E5E;">#     "Modifies xresnet `model` for single-channel images." </span></span>
<span id="cb23-14"><span class="co" style="color: #5E5E5E;">#     model[0][0].in_channels = n_in</span></span>
<span id="cb23-15"><span class="co" style="color: #5E5E5E;">#     # sum weights to reduce dimension</span></span>
<span id="cb23-16"><span class="co" style="color: #5E5E5E;">#     model[0][0].weight = torch.nn.parameter.Parameter(model[0][0].weight.mean(1, keepdim=True))</span></span>
<span id="cb23-17"></span>
<span id="cb23-18"><span class="co" style="color: #5E5E5E;"># def train_loops(dls, name, num_runs=num_runs, epochs=epochs, num_cls=50):</span></span>
<span id="cb23-19"><span class="co" style="color: #5E5E5E;">#     "Runs `num_runs` training loops with `dls` for given `epochs`."</span></span>
<span id="cb23-20"><span class="co" style="color: #5E5E5E;">#     accuracies = []</span></span>
<span id="cb23-21"><span class="co" style="color: #5E5E5E;">#     for i in range(num_runs):</span></span>
<span id="cb23-22"><span class="co" style="color: #5E5E5E;">#         # make new grayscale xresnet</span></span>
<span id="cb23-23"><span class="co" style="color: #5E5E5E;">#         model = xresnet18(pretrained=False, n_out=num_cls)</span></span>
<span id="cb23-24"><span class="co" style="color: #5E5E5E;">#         make_xresnet_grayscale(model, n_in=1)</span></span>
<span id="cb23-25"><span class="co" style="color: #5E5E5E;">#         # get learner for this run</span></span>
<span id="cb23-26"><span class="co" style="color: #5E5E5E;">#         learn = Learner(dls, model, metrics=[accuracy])</span></span>
<span id="cb23-27"><span class="co" style="color: #5E5E5E;">#         # train network and track accuracy</span></span>
<span id="cb23-28"><span class="co" style="color: #5E5E5E;">#         learn.fit_one_cycle(epochs)</span></span>
<span id="cb23-29"><span class="co" style="color: #5E5E5E;">#         accuracies.append(learn.recorder.values[-1][-1])</span></span>
<span id="cb23-30"><span class="co" style="color: #5E5E5E;">#     print(f'Average accuracy for "{name}": {sum(accuracies) / num_runs}')</span></span></code></pre></div>
</details>
</div>
</section>
<section id="baseline-performance" class="level2">
<h2 class="anchored" data-anchor-id="baseline-performance">Baseline performance</h2>
<p>Before getting carried away with normalization, we have to first set a baseline without normalizations. This allows us to evaluate the impact of normalization later on, else there is no way to know if normalization helps at all.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><span class="co" style="color: #5E5E5E;"># # data without normalization</span></span>
<span id="cb24-2"><span class="co" style="color: #5E5E5E;"># dls = get_dls(batch_tfms=[audio2spec])</span></span>
<span id="cb24-3"><span class="co" style="color: #5E5E5E;"># # run training loops</span></span>
<span id="cb24-4"><span class="co" style="color: #5E5E5E;"># train_loops(dls, name='No Norm')</span></span></code></pre></div>
</details>
</div>
</section>
<section id="performance-with-global-normalization" class="level2">
<h2 class="anchored" data-anchor-id="performance-with-global-normalization">Performance with global normalization</h2>
<p>Next we normalize each audio waveform and the spectrograms with global, scalar statistics.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><span class="co" style="color: #5E5E5E;"># # data with waveform and global normalization</span></span>
<span id="cb25-2"><span class="co" style="color: #5E5E5E;"># dls = get_dls(item_tfms=[AudioNormalize],</span></span>
<span id="cb25-3"><span class="co" style="color: #5E5E5E;">#               batch_tfms=[audio2spec, GlobalSpecNorm])</span></span>
<span id="cb25-4"><span class="co" style="color: #5E5E5E;"># # run training loops</span></span>
<span id="cb25-5"><span class="co" style="color: #5E5E5E;"># train_loops(dls, name='Global Norm')</span></span></code></pre></div>
</details>
</div>
</section>
<section id="performance-with-channel-normalization" class="level2">
<h2 class="anchored" data-anchor-id="performance-with-channel-normalization">Performance with channel normalization</h2>
<p>Finally, we normalize each audio waveform and the spectrograms with channel-based statistics.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><span class="co" style="color: #5E5E5E;"># # get data with waveform and channel normalization</span></span>
<span id="cb26-2"><span class="co" style="color: #5E5E5E;"># dls = get_dls(item_tfms=[AudioNormalize],</span></span>
<span id="cb26-3"><span class="co" style="color: #5E5E5E;">#               batch_tfms=[audio2spec, ChannelSpecNorm])</span></span>
<span id="cb26-4"><span class="co" style="color: #5E5E5E;"># # run training loops</span></span>
<span id="cb26-5"><span class="co" style="color: #5E5E5E;"># train_loops(dls, name='Channel Norm')</span></span></code></pre></div>
</details>
</div>
</section>
</section>
<section id="discussion" class="level1">
<h1>Discussion</h1>
<p>The results are:</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Normalization</th>
<th style="text-align: center;">Average Accuracy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">None</td>
<td style="text-align: center;">.7110</td>
</tr>
<tr class="even">
<td style="text-align: center;">Global</td>
<td style="text-align: center;"><strong>.7315</strong></td>
</tr>
<tr class="odd">
<td style="text-align: center;">Channel</td>
<td style="text-align: center;">.7144</td>
</tr>
</tbody>
</table>
<p>I ran the cells above several times to make sure these patterns held. Overall, there is a gain from global normalization. Channel-based normalization shows a smaller benefit. While these increases in performance are a good starting point, there are several explanations for this that point us towards other approaches.</p>
<p>For starters, the spectrograms in ESC-50 are very different both within and across classes. In other words the activity in each spectrogram channel changes a lot from sample to sample. A global statistic likely fares better under these unpredictable conditions. If all the audio came from a similar source, like speech, then the per-channel normalization might fare better.</p>
<p>We also process the entire five second files at once, which is a large analysis window by audio standards. This large window means that each sample looks exactly the same in every epoch. If we used a smaller analysis window, say 2 seconds, we could randomly “crop” many spectrogram regions from a single example as a kind of data augmentation. The risk here is grabbing a silent region without any information but still giving it a class label (though an energy threshold can prevent this). Cropping with a smaller analysis window is one way to expose the networks to more samples and variability.</p>
<p>Using the entire waveform at once also means that the waveform statistics need to model a very long-term relationship. Going back to the cricket recording example: we would not expect good normalization statistics for the chirps to be the same as good statistics for the pauses in between chirps. To counter this it is possible to do a “short-time” normalization. Here we pick a sliding window, often much smaller than the whole waveform, and only normalize the data inside as it steps through the waveform. This “short-time” normalization can be applied with or without the global waveform normalization.</p>
<p>Furthermore, the spectrogram is a high-dimensional feature with 201 frequency bins. It is common in audio tasks to reduce this dimension by combining nearby bins. This is done with something called “filterbanks” which usually operate at the Mel frequency scale. <a href="http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/">This tutorial</a> is one of my favorites and gives an incredibly clear description of Mel frequency and the filterbank process. There are other options such as <a href="https://www.mathworks.com/help/audio/ref/gammatonefilterbank-system-object.html">Gammatone filterbanks</a> as well. While this might seem like an expert handcrafted feature, there is good reason for using filterbanks in audio tasks. If we feed in a raw spectrogram, the early convolutional layers tend to learn something like a filterbank anyway! So directly feeding a filterbank into the network lets it focus on more complicated relationships. As a bonus, the channel-based normalization discussed here also works on filterbank features.</p>
<p>We are also training a powerful 18-layer model from scratch with only 1600 images. While deep learning can handle datasets this small, it is usually only through Transfer Learning. But, we stayed away from Transfer Learning because pretrained networks are tightly coupled to their original dataset’s normalization statistics. And the main idea here was to learn our own spectrogram scalings. It is possible that a smaller, simpler network will perform better. Looking at the training logs above, it seems the validation loss was still decreasing. So we’d still have to train for longer to check if the network is actually overfitting and a simpler model is needed.</p>
<p>Lastly, there is no data augmentation even though it is almost de facto when training CNNs. It is possible to use image augmentations (flips, rotations, etc) even though they do not technically make sense on a spectrogram. It might be better to use augmentations directly inspired by signal processing like <a href="https://arxiv.org/abs/1904.08779"><code>SpecAugment</code></a>. By the way, <code>SpecAugment</code> is already included in fastaudio! Along with many other waveform and spectrogram <a href="https://github.com/fastaudio/fastaudio/tree/master/src/fastaudio/augment">augmentations</a>.</p>
<p>To recap, there are many good reasons why normalization only helped a little on the ESC-50 dataset. The points above described some possible next steps to increase performance.</p>
</section>
<section id="conclusions" class="level1">
<h1>Conclusions</h1>
<p>In this post we saw how spectrograms are fundamentally different than natural images. We then explored two ways of normalizing spectrograms when training neural networks: global normalization and channel-based normalization.</p>
<p>Next we implemented these two normalization techniques and tested them against an unnormalized baseline on the ESC-50 dataset. Both normalizations showed a gain in performance, with global normalization outperforming channel-based normalization. We then offered some next steps that could further boost performance.</p>
<p>In the end, the choice of spectrogram normalization will depend on how the system is used. For example, if the system will be deployed in an environment similar to the training environment, then normalizing by spectrogram channels makes more sense. This is because the training statistics will be a good match for the similar patterns and distributions in the deployed environment. However, it is critical to monitor the system in this environment and update the statistics as needed to avoid shifting out of domain.</p>
<p>If the system will instead be used in a completely different environment, of which you have no knowledge, then the global statistics could be a better fit. While not as technically sound, the model will (hopefully) be less surprised by radically new activity across the channels.</p>
<p>To recap, there is no one universally correct way to normalize spectrograms for every audio task. Like many aspects of deep learning, the final choice will be experimental and based on the specifics of both the problem and domain.</p>
<p>I hope this post gave you an idea of how to normalize spectrograms. Even moreso, I hope that it gave you new ideas to try out. The ESC-50 is a great playground for any new ideas. Happy experimenting!</p>
<p>from nbdev.showdoc import *</p>
<p>::: {.cell 0=‘h’ 1=‘i’ 2=‘d’ 3=‘e’}</p>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><span class="im" style="color: #00769E;">import</span> nbdev<span class="op" style="color: #5E5E5E;">;</span> nbdev.nbdev_export()</span></code></pre></div>
</details>
<p>:::</p>
<p>::: {.cell 0=‘h’ 1=‘i’ 2=‘d’ 3=‘e’}</p>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><span class="im" style="color: #00769E;">from</span> nbdev.showdoc <span class="im" style="color: #00769E;">import</span> <span class="op" style="color: #5E5E5E;">*</span></span></code></pre></div>
</details>
<p>:::</p>


</section>

 ]]></description>
  <category>deep learning</category>
  <category>spectrogram normalizations</category>
  <guid>https://enzokro.dev/blog/posts/2022-08-20-spec-norms/index.html</guid>
  <pubDate>Sat, 20 Aug 2022 00:00:00 GMT</pubDate>
  <media:content url="https://enzokro.dev/blog/posts/2022-08-20-spec-norms/violin_spec.png" medium="image" type="image/png" height="81" width="144"/>
</item>
</channel>
</rss>
