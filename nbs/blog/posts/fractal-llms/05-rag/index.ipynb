{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Lesson 5: Processing text documents for LLMs\"\n",
    "author: \"Chris Kroenke\"\n",
    "date: \"10/21/2023\"\n",
    "toc: true \n",
    "badges: true\n",
    "categories: [fractal, python, LLM]\n",
    "image: Fractal_canopy.svg\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Preparing text data for LLM applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro  \n",
    "\n",
    "Welcome to the fifth lesson in the course. Let's recap our progress so far:  \n",
    "\n",
    "- Lesson 1: We made a python environment for LLMs.  \n",
    "- Lesson 2: Set up a personal blog to track our progress.\n",
    "- Lesson 3: Ran our first LLM with the HuggingFace API.  \n",
    "- Lesson 4: Ran a quantized LLM with llama.cpp  \n",
    "\n",
    "So far, we've used LLMs off the shelf as they are. Now we take our first steps towards augmenting our own LLM. \n",
    "\n",
    "Specifically, we will augment an LLM with the [Diátaxis](https://diataxis.fr/) website. Diátaxis is a framework and approach to write technical documents. Our goal is to give an LLM knowledge about Diátaxis and use it to help us write better notebooks.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with our running notebook best practice:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grabbing the Diátaxis data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Diátaxis docs](https://diataxis.fr/) will be the source of knowledge for our LLM. The pages are available in a repo as reStructuredText files with the extension `.rst`.   \n",
    "\n",
    "> Link to [Diátaxis code repo](https://github.com/evildmp/diataxis-documentation-framework) \n",
    "\n",
    "```bash\n",
    "# clone the Diátaxis repo\n",
    "git clone https://github.com/evildmp/diataxis-documentation-framework\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting .rst to .txt files  \n",
    "\n",
    "It is rare that files come in exactly the right format for our ML algorithms. Pre-processing the input is one of the most important steps in ML that often gets overlooked. However, it is a great place to follow one of the Golden Rules of ML: `*always* look at your data`.  \n",
    "\n",
    "All too often, folks jump right into the code and start training models. This a fun step, to be sure, but we can learn so much about both our problem and the domain itself by first looking at the data. Without carefully inspecting data, you are basically flying blind. It is only the sheer and overwhelming power of ML and LLMs that let us get away with it (sometimes), but that doesn't mean we should.  \n",
    "\n",
    "With that said, here we only have to do a little bit of pre-processing. We need to convert the Diátaxis `.rst` files into `.txt` files, then clean up the text a bit.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::: callout-note\n",
    "Make sure you are inside of the `llm-env` virtual environment.\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to install the rst processing libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# installing the rst to txt converter and writer\n",
    "pip install rst2txt docutils\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can modify the example in the [`rst2txt` documentation](https://github.com/stephenfin/rst2txt) to write a function that turns an `.rst` file into a `.txt` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docutils.core import publish_file\n",
    "import rst2txt\n",
    "\n",
    "def convert_rst_to_txt(filename):\n",
    "    \"\"\"\n",
    "    Turns an rst file to a txt file with the same name.\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as source:\n",
    "        publish_file(\n",
    "            source=source,\n",
    "            destination_path=filename.replace(\".rst\", \".txt\"),\n",
    "            writer=rst2txt.Writer()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up, let's grab all of the .rst files in the Diátaxis repository and convert them into .txt files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cck/repos/diataxis-documentation-framework/colofon.rst:62: (ERROR/3) Unknown interpreted text role \"ref\".\n",
      "/Users/cck/repos/diataxis-documentation-framework/colofon.rst:70: (ERROR/3) Unknown interpreted text role \"doc\".\n",
      "/Users/cck/repos/diataxis-documentation-framework/index.rst:23: (ERROR/3) Unknown interpreted text role \"doc\".\n",
      "/Users/cck/repos/diataxis-documentation-framework/index.rst:61: (ERROR/3) Unknown interpreted text role \"ref\".\n",
      "/Users/cck/repos/diataxis-documentation-framework/index.rst:65: (ERROR/3) Unknown directive type \"toctree\".\n",
      "\n",
      ".. toctree::\n",
      "   :maxdepth: 1\n",
      "   :hidden:\n",
      "   :titlesonly:\n",
      "\n",
      "   Home <self>\n",
      "   Tutorials <tutorials>\n",
      "   How-to guides <how-to-guides>\n",
      "   Reference <reference>\n",
      "   Explanation <explanation>\n",
      "\n",
      "/Users/cck/repos/diataxis-documentation-framework/index.rst:76: (ERROR/3) Unknown directive type \"toctree\".\n",
      "\n",
      ".. toctree::\n",
      "   :maxdepth: 1\n",
      "   :hidden:\n",
      "   :titlesonly:\n",
      "\n",
      "   Tutorials vs how-to guides <tutorials-how-to>\n",
      "   Reference vs explanation <reference-explanation>\n",
      "   needs\n",
      "   compass\n",
      "   quality\n",
      "   Complex hierarchies <complex-hierarchies>\n",
      "   how-to-use-diataxis\n",
      "\n",
      "/Users/cck/repos/diataxis-documentation-framework/index.rst:89: (ERROR/3) Unknown directive type \"toctree\".\n",
      "\n",
      ".. toctree::\n",
      "   :maxdepth: 1\n",
      "   :hidden:\n",
      "   :titlesonly:\n",
      "\n",
      "   adoption\n",
      "   colofon\n",
      "/Users/cck/repos/diataxis-documentation-framework/how-to-guides.rst:38: (ERROR/3) Unknown interpreted text role \"ref\".\n",
      "/Users/cck/repos/diataxis-documentation-framework/quality.rst:200: (ERROR/3) Unknown interpreted text role \"ref\".\n",
      "/Users/cck/repos/diataxis-documentation-framework/complex-hierarchies.rst:48: (ERROR/3) Error in \"code-block\" directive:\n",
      "unknown option: \"emphasize-lines\".\n",
      "\n",
      "..  code-block:: text\n",
      "    :emphasize-lines: 8-11\n",
      "\n",
      "    home                      <- landing page\n",
      "        tutorial\n",
      "            part 1\n",
      "            part 2\n",
      "            part 3\n",
      "        how-to guides         <- landing page\n",
      "            install           <- landing page\n",
      "                locally\n",
      "                Docker\n",
      "                virtual machine\n",
      "                Linux container\n",
      "            deploy\n",
      "            scale\n",
      "        reference             <- landing page\n",
      "            commandline tool\n",
      "            available endpoints\n",
      "            API\n",
      "        explanation           <- landing page\n",
      "            best practice recommendations\n",
      "            security overview\n",
      "            performance\n",
      "\n",
      "/Users/cck/repos/diataxis-documentation-framework/complex-hierarchies.rst:216: (ERROR/3) Unknown interpreted text role \"ref\".\n",
      "/Users/cck/repos/diataxis-documentation-framework/complex-hierarchies.rst:254: (ERROR/3) Unknown interpreted text role \"ref\".\n",
      "/Users/cck/repos/diataxis-documentation-framework/tutorials-how-to.rst:34: (ERROR/3) Unknown interpreted text role \"ref\".\n",
      "/Users/cck/repos/diataxis-documentation-framework/tutorials-how-to.rst:127: (ERROR/3) Unknown directive type \"cssclass\".\n",
      "\n",
      "..  cssclass:: lined\n",
      "\n",
      "/Users/cck/repos/diataxis-documentation-framework/tutorials-how-to.rst:129: (ERROR/3) Unknown directive type \"grid\".\n",
      "\n",
      "..  grid:: 1 2 2 2\n",
      "    :margin: 0\n",
      "    :padding: 0\n",
      "    :gutter: 3\n",
      "\n",
      "    ..  grid-item::\n",
      "\n",
      "        A tutorial’s purpose is **to help the pupil acquire basic competence**.\n",
      "\n",
      "    ..  grid-item::\n",
      "\n",
      "        A how-to guide’s purpose is **to help the already-competent user perform a particular task\n",
      "        correctly**.\n",
      "\n",
      "    ..  grid-item::\n",
      "\n",
      "        A tutorial **provides a learning experience**. People learn skills through practical, hands-on experience. What matters\n",
      "        in a tutorial is what the learner *does*, and what they experience while doing it.\n",
      "\n",
      "    ..  grid-item::\n",
      "\n",
      "        A how-to guide **directs the user’s work**.\n",
      "\n",
      "    ..  grid-item::\n",
      "\n",
      "        The tutorial follows a **carefully-managed path**, starting at a given point and working to\n",
      "        a conclusion. Along that path, the learner must have the *encounters* that the lesson\n",
      "        requires.\n",
      "\n",
      "    ..  grid-item::\n",
      "\n",
      "        The how-to guide aims for a successful *result*, and guides the user along the safest,\n",
      "        surest way to the goal, but **the path can’t be managed**: it’s the real world, and\n",
      "        anything could appear to disrupt the journey.\n",
      "\n",
      "    ..  grid-item::\n",
      "\n",
      "        A tutorial **familiarises the learner** with the work: with the tools, the language, the processes and the way that\n",
      "        what they’re working with behaves and responds, and so on. Its job is to introduce them, manufacturing a structured,\n",
      "        repeatable encounter with them.\n",
      "\n",
      "    ..  grid-item::\n",
      "\n",
      "        The how-to guide can and should **assume familiarity** with them all.\n",
      "\n",
      "    ..  grid-item::\n",
      "\n",
      "        The tutorial takes place in a **contrived setting**, a learning environment where as much as possible is set\n",
      "        out in advance to ensure a successful experience.\n",
      "\n",
      "    ..  grid-item::\n",
      "\n",
      "        A how-to guide applies to the **real world**, where you have to deal\n",
      "        with what it throws at you.\n",
      "\n",
      "    ..  grid-item::\n",
      "\n",
      "        The tutorial **eliminates the unexpected**.\n",
      "\n",
      "    ..  grid-item::\n",
      "\n",
      "        The how-to guide must **prepare for the unexpected**, alerting the user to its possibility\n",
      "        and providing guidance on how to deal with it.\n",
      "\n",
      "    ..  grid-item::\n",
      "\n",
      "        A tutorial’s path follows a single line. **It doesn’t offer choices or alternatives**.\n",
      "\n",
      "    ..  grid-item::\n",
      "\n",
      "        A **how-to guide will typically fork and branch**, describing different routes\n",
      "        to the same destination: *If this, then that. In the case of ..., an alternative approach\n",
      "        is to…*\n",
      "\n",
      "    ..  grid-item::\n",
      "\n",
      "        A tutorial **must be safe**. No harm should come to the learner; it must always be possible to go back to the beginning\n",
      "        and start again.\n",
      "\n",
      "    ..  grid-item::\n",
      "\n",
      "        A how-to guide **cannot promise safety**; often there’s only one chance to get it right.\n",
      "\n",
      "    ..  grid-item::\n",
      "\n",
      "        In a tutorial, **responsibility lies with the teacher**. If the learner gets into trouble, that's the teacher's problem\n",
      "        to put right.\n",
      "\n",
      "    ..  grid-item::\n",
      "\n",
      "        In a how-to guide, **the user has responsibility** for getting themselves in and out of trouble.\n",
      "\n",
      "    ..  grid-item::\n",
      "\n",
      "        The learner **may not even have sufficient competence to ask the questions** that a tutorial answers.\n",
      "\n",
      "    ..  grid-item::\n",
      "\n",
      "        A how-to guide can assume that **the user is asking the right questions in the first\n",
      "        place**.\n",
      "\n",
      "    ..  grid-item::\n",
      "\n",
      "        The tutorial is **explicit about basic things** - where to do things, where to put them, how to manipulate objects. It\n",
      "        addresses the embodied experience - in our medical example, how hard to press, how to hold an implement; in a software\n",
      "        tutorial, it could be where to type a command, or how long to wait for a response.\n",
      "\n",
      "    ..  grid-item::\n",
      "\n",
      "        A how-to guide relies on this as **implicit knowledge** - even bodily knowledge.\n",
      "\n",
      "    ..  grid-item::\n",
      "\n",
      "        A tutorial is **concrete and particular** in its approach. It refers to the specific, known, defined tools, materials,\n",
      "        processes and conditions that we have carefully set before the learner.\n",
      "\n",
      "    ..  grid-item::\n",
      "\n",
      "        The how-to guide has to take a **general** approach: many of these things will be\n",
      "        unknowable in advance, or different in each real-world case.\n",
      "\n",
      "    ..  grid-item::\n",
      "\n",
      "        The tutorial **teaches general skills and principles** that later could be applied to a\n",
      "        multitude of cases.\n",
      "\n",
      "    ..  grid-item::\n",
      "\n",
      "        The user following a how-to guide is doing so in order to **complete a particular task**.\n",
      "\n",
      "/Users/cck/repos/diataxis-documentation-framework/reference-explanation.rst:72: (ERROR/3) Unknown interpreted text role \"ref\".\n",
      "/Users/cck/repos/diataxis-documentation-framework/needs.rst:110: (ERROR/3) Unknown interpreted text role \"ref\".\n",
      "/Users/cck/repos/diataxis-documentation-framework/needs.rst:111: (ERROR/3) Unknown interpreted text role \"ref\".\n",
      "/Users/cck/repos/diataxis-documentation-framework/needs.rst:112: (ERROR/3) Unknown interpreted text role \"ref\".\n",
      "/Users/cck/repos/diataxis-documentation-framework/needs.rst:113: (ERROR/3) Unknown interpreted text role \"ref\".\n"
     ]
    }
   ],
   "source": [
    "#| output: false\n",
    "import os\n",
    "\n",
    "# NOTE: replace with your path to the Diátaxis repo\n",
    "path_to_diataxis = '/Users/cck/repos/diataxis-documentation-framework'\n",
    "\n",
    "# find all rst files in the docs repo\n",
    "rst_files = [o for o in os.listdir(path_to_diataxis) if o.endswith('.rst')]\n",
    "\n",
    "# convert all rst files to txt files\n",
    "for rst in rst_files:\n",
    "    convert_rst_to_txt(f'{path_to_diataxis}/{rst}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following subset are the docs with relevant information an LLM would need to write notebooks in the Diaxtaxis style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files with important content about writing docs\n",
    "valid_files = [\n",
    "    'compass.txt',\n",
    "    'complex-hierarchies.txt',\n",
    "    'explanation.txt',\n",
    "    'how-to-guides.txt',\n",
    "    'how-to-use-diataxis.txt',\n",
    "    'needs.txt',\n",
    "    'quality.txt',\n",
    "    'reference-explanation.txt',\n",
    "    'reference.txt',\n",
    "    'tutorials-how-to.txt',\n",
    "    'tutorials.txt',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read in these text files and store them into a `data` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stores the text data\n",
    "data = {}\n",
    "\n",
    "# read in the relevant files\n",
    "for f in valid_files:\n",
    "    with open(f'{path_to_diataxis}/{f}', 'r') as file:\n",
    "        data[f] = str(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `data`, file name are the keys and the values are the text in the files. This is a pretty standard pattern when loading ML data: features are loaded into a map (dictionary), indexed by some unique identifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning up the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a moment to look through the `.txt` files we've loaded, for example `how-to-guides.txt`. One thing should immediately stand out: there are some errors from the conversion process.  \n",
    "\n",
    "Specifically, there are some sections it wasn't able to parse. Here's an example of a broken parsing output:  \n",
    "```\n",
    "<SYSTEM MESSAGE: ... Unknown interpreted text role \"ref\".>\n",
    "```  \n",
    "\n",
    "Thankfully this is isolated to a single line that failed, the rest of the document is ok.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means we have two kinds of text cleanup to do:  \n",
    "1. Standard text cleanup and formatting.  \n",
    "2. Errors from the `.rst` conversion process.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard text cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few best-practices steps to cleaning up text data:  \n",
    "- Remove extra and trailing whitespaces.  \n",
    "- Remove special characters, like HTML tags.   \n",
    "- Properly handle escaped characters (`\\t`, `\\n`, etc).  \n",
    "\n",
    "Other steps like lower-casing, removing numbers, or dropping typical [stop-words](https://gist.github.com/sebleier/554280) are more task-specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a `clean_text` function that cleans up a given string.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans up the headers and footers of the text.\n",
    "    \"\"\"\n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # Define the regex pattern for the headers and footers\n",
    "    pattern = r'[\\*\\=\\^]+'\n",
    "    # Substitute the special sequences with an empty string\n",
    "    text = re.sub(pattern, '', text)\n",
    "\n",
    "    # TODO: any other cleaning you can think of?\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call this cleanup function on the raw text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning up the text\n",
    "data = {k: clean_text(v) for k, v in data.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special text cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can handle the errors that popped up when converting `.rst` documents. Let's split the documents into list of sentences, so we can find the incorrect \"SYSTEM MESSAGE\" lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into a list of sentences\n",
    "def split_sentences(text):\n",
    "    \"Turns documents into a list of sentences.\"\n",
    "    return [o for o in text.split('. ') if o]\n",
    "\n",
    "split_data = {k: split_sentences(v) for k, v in data.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at one of the sentences in the `how-to-guides.txt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How-to guides matter not just because users need to be able to accomplish things: the list of how-to guides in your documentation helps frame the picture of what your product can actually do'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at an example sentence\n",
    "split_data['how-to-guides.txt'][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many processing errors are in this documents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting the number of system messages in how-to-guides.txt\n",
    "doc = 'how-to-guides.txt'\n",
    "\n",
    "def count_errors(text):\n",
    "    \"Counts the number of system messages in the text.\"\n",
    "    return sum(1 for o in text if '<SYSTEM MESSAGE:' in o)\n",
    "\n",
    "count_errors(split_data['how-to-guides.txt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's count the errors in all of the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumErrors compass.txt: 0\n",
      "NumErrors complex-hierarchies.txt: 3\n",
      "NumErrors explanation.txt: 0\n",
      "NumErrors how-to-guides.txt: 1\n",
      "NumErrors how-to-use-diataxis.txt: 0\n",
      "NumErrors needs.txt: 1\n",
      "NumErrors quality.txt: 1\n",
      "NumErrors reference-explanation.txt: 1\n",
      "NumErrors reference.txt: 0\n",
      "NumErrors tutorials-how-to.txt: 3\n",
      "NumErrors tutorials.txt: 0\n"
     ]
    }
   ],
   "source": [
    "# checking the full count of system errors\n",
    "for f in valid_files:\n",
    "    print(f\"NumErrors {f}: {count_errors(split_data[f])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too bad, but still something we want to clean up.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_rst_errors(txt):\n",
    "    \"Only returns items without system messages.\"\n",
    "    return [o for o in txt if '<SYSTEM MESSAGE:' not in o]  \n",
    "\n",
    "# our cleaned up data split into sentences\n",
    "clean_data = {k: clean_rst_errors(v) for k, v in split_data.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then check if the system messages are gone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean NumErrors compass.txt: 0\n",
      "Clean NumErrors complex-hierarchies.txt: 0\n",
      "Clean NumErrors explanation.txt: 0\n",
      "Clean NumErrors how-to-guides.txt: 0\n",
      "Clean NumErrors how-to-use-diataxis.txt: 0\n",
      "Clean NumErrors needs.txt: 0\n",
      "Clean NumErrors quality.txt: 0\n",
      "Clean NumErrors reference-explanation.txt: 0\n",
      "Clean NumErrors reference.txt: 0\n",
      "Clean NumErrors tutorials-how-to.txt: 0\n",
      "Clean NumErrors tutorials.txt: 0\n"
     ]
    }
   ],
   "source": [
    "# checking the full count of system errors\n",
    "for f in valid_files:\n",
    "    print(f\"Clean NumErrors {f}: {count_errors(clean_data[f])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding the Diátaxis data  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a set of clean sentences ready for embedding. Text embeddings are usually placed in vector store databases. There are many startups providing this service, or we could spin up our own. For now, we'll use the `chromadb` embedding storage.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# install chromadb inside llm-env\n",
    "pip install chromadb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "chroma_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client.delete_collection(name=coll_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a collection\n",
    "coll_name = 'diaxtaxis_docs'\n",
    "collection = chroma_client.create_collection(name=coll_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can store the embeddings.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cck/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [01:42<00:00, 814kiB/s] \n"
     ]
    }
   ],
   "source": [
    "# step through our documents and sentences\n",
    "for fid, sentences in clean_data.items():\n",
    "\n",
    "    # metadata for the files\n",
    "    metadatas = [{\"source\": fid}] * len(sentences)\n",
    "\n",
    "    # unique id for each file\n",
    "    ids = [f\"{fid}_{i}\" for i in range(len(sentences))]\n",
    "\n",
    "    # add the documents\n",
    "    collection.add(\n",
    "        documents=sentences,\n",
    "        metadatas=metadatas,\n",
    "        ids=ids,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a stored set of embeddings we can search with queries. Let's try to find some relevant sentences for writing a Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example setup\n",
    "example_prompt = \"Writing code to pre-process and cleanup text.\"\n",
    "\n",
    "results = collection.query(\n",
    "    query_texts=[example_prompt],\n",
    "    n_results=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['how-to-use-diataxis.txt_38',\n",
       "   'tutorials.txt_104',\n",
       "   'reference.txt_43',\n",
       "   'tutorials-how-to.txt_62',\n",
       "   'reference.txt_30']],\n",
       " 'distances': [[1.1993290185928345,\n",
       "   1.2605922222137451,\n",
       "   1.2740986347198486,\n",
       "   1.2925323247909546,\n",
       "   1.304250955581665]],\n",
       " 'metadatas': [[{'source': 'how-to-use-diataxis.txt'},\n",
       "   {'source': 'tutorials.txt'},\n",
       "   {'source': 'reference.txt'},\n",
       "   {'source': 'tutorials-how-to.txt'},\n",
       "   {'source': 'reference.txt'}]],\n",
       " 'embeddings': None,\n",
       " 'documents': [[\"Working like this helps reduce the stress of one of the most paralysing and troublesome aspects of the documentation-writer's work: working out what to do\",\n",
       "   'Provide minimal explanation of actions in the most basic language possible',\n",
       "   'List commands, options, operations, features, flags, limitations, error messages, etc',\n",
       "   'You already know these processes',\n",
       "   'Do nothing but describe  Technical reference has one job: to describe, and to do that clearly, accurately and comprehensively']],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook took the first steps to augment an LLM with extra knowledge. We embedded the Diátaxis documentation to eventually use it for Retrieval-Augmented Generation (RAG). Later on, we will also use other LLMs to generate Question-and-Answer pairs based on these documents, and use them to fine-tune a model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    ":::: {#refs}\n",
    "[Procida D. Diátaxis documentation framework](https://diataxis.fr/)\n",
    "::::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chaski",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
