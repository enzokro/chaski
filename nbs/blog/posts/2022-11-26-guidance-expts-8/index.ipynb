{
 "cells": [
  {
   "cell_type": "raw",
   "id": "39a262fd-a0f5-48b8-bd55-96dced6d64bb",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Classifier-free Guidance with Cosine Schedules Pt. 7\"\n",
    "author: \"enzokro\"\n",
    "date: \"11/27/2022\"\n",
    "toc: true \n",
    "badges: true\n",
    "categories: [diffusion, classifier-free guidance, deep learning]\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714710df-5448-41d1-a36e-8b21c327bbf1",
   "metadata": {},
   "source": [
    "> dynamic Classifier-free Guidance across several Diffusion models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5799b3-e47f-419d-b77a-3387b8108dae",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4bcd26-1a61-4b6e-9552-06cd654e31ca",
   "metadata": {},
   "source": [
    "This notebook is Part 7 in a [series](https://enzokro.dev/blog/posts/2022-11-15-guidance-expts-6/) on dynamic Classifier-free Guidance. It checks whether our proposed schedules and normalizations improve images across Diffusion models.\n",
    "\n",
    "## Recap of Parts 1-6\n",
    "\n",
    "In the first six parts, we found a good set of schedules and normalizations for a dynamic Classifier-free Guidance. The best performing schedules are used in this notebook.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f6284b-74d5-4323-b358-0cff9b3746c4",
   "metadata": {},
   "source": [
    "## Part 7: Improvement across models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6c40da-d93d-4150-9fa8-713050c4be79",
   "metadata": {},
   "source": [
    "Part 7 takes our best schedule so far, `Inverse kDecay`, and tries it on a few different models:  \n",
    "\n",
    "- Stable Diffusion v1-4\n",
    "- Stable Diffusion v1-5\n",
    "- Prompt Hero's openjourney\n",
    "- Stable Diffusion 2-base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9ea840-32dc-406a-ac6a-2d7012f3b2e8",
   "metadata": {},
   "source": [
    "# Python imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b43dae-d6fb-41cf-b04c-256350bd2f2c",
   "metadata": {},
   "source": [
    "We start with a few python imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea1e75a0-0d64-436f-b9d8-d641393dca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from functools import partial\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781bfabc-3659-4372-b876-b47f6ef8c37c",
   "metadata": {},
   "source": [
    "## Seed for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a85966-1de8-472a-80c7-458ef0a3b78e",
   "metadata": {},
   "source": [
    "`seed_everything` makes sure that the results are reproducible across notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d6c482-17da-41df-9605-4759b3281944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed and pseudo random number generator\n",
    "SEED = 1337802893 # inca 977145576 # inca2, warrior\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    generator = torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    return generator\n",
    "\n",
    "# for sampling the initial, noisy latents\n",
    "generator = seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680d6a28-697e-4a04-a481-245304795cae",
   "metadata": {},
   "source": [
    "# Cosine schedules with k-decay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1244f5-ed0c-4bd7-bb03-d72de03c65d3",
   "metadata": {},
   "source": [
    "We create the schedules with different $k$ values using the `cf_guidance` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b0cacb1-b98f-47b2-965f-71c71d03b043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers to create cosine schedules\n",
    "from cf_guidance.schedules  import get_cos_sched\n",
    "\n",
    "# normalizations for classifier-free guidance\n",
    "from cf_guidance.transforms import GuidanceTfm, BaseNormGuidance, TNormGuidance, FullNormGuidance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eff094-8ee6-49e9-b151-068df170841d",
   "metadata": {},
   "source": [
    "For the other schedule parameters, we keep the [same values](https://enzokro.dev/blog/posts/2022-11-20-guidance-expts-2/#default-schedule-parameters) from the rest of the series. The functions below are also shared with previous notebooks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4d2d542-01de-4ca8-bb1f-de35ff167744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default schedule parameters from the blog post\n",
    "######################################\n",
    "max_val           = 8     # guidance scaling value\n",
    "min_val           = 1     # minimum guidance scaling\n",
    "num_steps         = 50    # number of diffusion steps\n",
    "num_warmup_steps  = 0     # number of warmup steps\n",
    "warmup_init_val   = 0     # the intial warmup value\n",
    "num_cycles        = 0.5     # number of cosine cycles\n",
    "k_decay           = 1     # k-decay for cosine curve scaling \n",
    "\n",
    "# smaller values for T-Norm and FullNorm\n",
    "max_T = 0.15\n",
    "min_T = 0.01\n",
    "######################################\n",
    "\n",
    "DEFAULT_COS_PARAMS = {\n",
    "    'max_val':           max_val,\n",
    "    'num_steps':         num_steps,\n",
    "    'min_val':           min_val,\n",
    "    'num_cycles':        num_cycles,\n",
    "    'k_decay':           k_decay,\n",
    "    'num_warmup_steps':  num_warmup_steps,\n",
    "    'warmup_init_val':   warmup_init_val,\n",
    "}\n",
    "\n",
    "DEFAULT_T_PARAMS = {\n",
    "    'max_val':           max_T,\n",
    "    'num_steps':         num_steps,\n",
    "    'min_val':           min_T,\n",
    "    'num_cycles':        num_cycles,\n",
    "    'k_decay':           k_decay,\n",
    "    'num_warmup_steps':  num_warmup_steps,\n",
    "    'warmup_init_val':   warmup_init_val,\n",
    "}\n",
    "\n",
    "def cos_harness(default_params, new_params):\n",
    "    '''Creates cosine schedules with updated parameters in `new_params`\n",
    "    '''\n",
    "    # start from the given baseline `default_params`\n",
    "    cos_params = dict(default_params)\n",
    "    # update the with the new, given parameters\n",
    "    cos_params.update(new_params)\n",
    "    \n",
    "    # return the new cosine schedule\n",
    "    sched = get_cos_sched(**cos_params)\n",
    "    return sched\n",
    "\n",
    "\n",
    "def create_expts(params: dict, schedule_func) -> list:\n",
    "    '''Creates a list of experiments.\n",
    "    \n",
    "    Each element is a dictionary with the name, value, and schedule for a given parameter.\n",
    "    A `title` field is also added for easy plotting.\n",
    "    '''\n",
    "    names = sorted(params)\n",
    "    expts = []\n",
    "    # step through parameter names and their values\n",
    "    for i,name in enumerate(names):\n",
    "        for j,val in enumerate(params[name]):\n",
    "            # create the experiment\n",
    "            expt = {'param_name': name,\n",
    "                    'val': val,\n",
    "                    'schedule': schedule_func(new_params={name: val})}\n",
    "            # name for plotting\n",
    "            expt['title'] = f'Param: \"{name}\", val={val}'\n",
    "            # add it to the experiment list\n",
    "            expts.append(expt)\n",
    "    return expts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ded516-78f4-44da-a2c0-e5fd904eef42",
   "metadata": {},
   "source": [
    "Next we create the best k-decay cosine schedules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fe94d2d-47e6-490d-a491-affa4c1920c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup for the Inverse-k-decay cosine schedules\n",
    "inv_k_params = {'k_decay': [0.15]}\n",
    "inv_k_func = partial(cos_harness, default_params=DEFAULT_COS_PARAMS)\n",
    "inv_k_expts = create_expts(inv_k_params, inv_k_func)\n",
    "\n",
    "# invert the `k` schedules\n",
    "for s in inv_k_expts:\n",
    "    s['schedule'] = [max_val - g + min_val for g in s['schedule']]\n",
    "\n",
    "# put all schedules together\n",
    "all_k_expts = inv_k_expts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b631d08-6d5c-493b-a890-a081977eea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "#| output: true\n",
    "colors=list(mcolors.TABLEAU_COLORS)\n",
    "\n",
    "# setup the plot\n",
    "fig,ax = plt.subplots(figsize=(12,8))\n",
    "plt.title('Inverse Cosine Schedules with K-decay', fontsize='xx-large')\n",
    "plt.xlabel('Diffusion timesteps', fontsize='x-large')\n",
    "plt.ylabel('Guidance parameter', fontsize='x-large')\n",
    "\n",
    "# plot each k values\n",
    "for idx,s in enumerate(inv_k_expts):\n",
    "    ax.plot(s['schedule'], c=colors[idx], label=f'k: {s[\"val\"]:.2f}')\n",
    "    \n",
    "plt.legend()\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacdc11e-b629-43df-8213-4b5d98a969f1",
   "metadata": {},
   "source": [
    "We repeat this for the `T` and `Full` Normalizations as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959f09d8-5a29-4289-bece-c2010572e55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the Inverse-k-decay cosine experiments\n",
    "T_inv_k_func = partial(cos_harness, default_params=DEFAULT_T_PARAMS)\n",
    "T_inv_k_expts = create_expts(inv_k_params, T_inv_k_func)\n",
    "\n",
    "# stores the inverted schedules\n",
    "# invert the `k` schedules\n",
    "for s in T_inv_k_expts:\n",
    "    s['schedule'] = [max_T - g + min_T for g in s['schedule']]\n",
    "\n",
    "all_T_k_expts = T_inv_k_expts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319df1f7-a9d2-4a07-bc67-6b19b33061f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "#| output: true\n",
    "colors=list(mcolors.TABLEAU_COLORS)\n",
    "\n",
    "# setup the plot\n",
    "fig,ax = plt.subplots(figsize=(12,8))\n",
    "plt.title('T Inverse Cosine Schedules with K-decay', fontsize='xx-large')\n",
    "plt.xlabel('Diffusion timesteps', fontsize='x-large')\n",
    "plt.ylabel('Guidance parameter', fontsize='x-large')\n",
    "\n",
    "# plot each k values\n",
    "for idx,s in enumerate(T_inv_k_expts):\n",
    "    ax.plot(s['schedule'], c=colors[idx], label=f'k: {s[\"val\"]:.2f}')\n",
    "    \n",
    "plt.legend()\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9d1ec5-8a92-4455-bb9f-5e18662411db",
   "metadata": {},
   "source": [
    "# Loading different StableDiffusion models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17548253-ffff-41d5-8d01-03f9321c52e9",
   "metadata": {},
   "source": [
    "We need to wrap our experiment pipeline in a single loop so we can easily run it with different models. To do this, we'll move the model loading code below in its own function, and add a function cleanup gpu memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af74809b-8a67-49e9-b435-15556a3fcea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# to load Stable Diffusion pipelines\n",
    "from min_diffusion.core import MinimalDiffusion\n",
    "\n",
    "# to plot generated images\n",
    "from min_diffusion.utils import show_image, image_grid, plot_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9028ce7d-75aa-41fb-8da1-325963735fde",
   "metadata": {},
   "source": [
    "We use it to load the `Stable Diffusion v1-4` model on the GPU, with `torch.float16` precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941fbfca-e503-4207-9a41-d23fb89695af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sd_model(model_name, device, dtype, model_kwargs={}, generator=None):\n",
    "    pipeline = MinimalDiffusion(model_name, device, dtype, generator=generator)\n",
    "    pipeline.load(**model_kwargs);\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24c6755-d924-4119-812c-47592be89690",
   "metadata": {},
   "source": [
    "# Text prompt for image generations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374dfe7a-acac-49d2-8689-c19502119340",
   "metadata": {},
   "source": [
    "We use the familiar, running prompt in our series to generate an image:  \n",
    "\n",
    "> \"a photograph of an astronaut riding a horse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a10cc5-1463-4d96-bba7-b84e8d0e6089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text prompt for image generations\n",
    "\n",
    "# prompt = \"a beautiful painting of an elegant cat, highly detailed, 4K, 8K, trending on art station, Award winning\"\n",
    "\n",
    "# prompt = \"digital painting of hanan pacha, the incan world above us where the sun and moon live, by filipe pagliuso and justin gerard, symmetric, fantasy, realistic, highly detailed, realistic, intricate, sharp focus, tarot card, portrait\"\n",
    "prompt = \"digital painting of masked incan warrior, by filipe pagliuso and justin gerard, symmetric, fantasy, highly detailed, realistic, intricate, portrait, sharp focus, tarot card, face, handsome, peruvian, ax\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48695f66-34e4-4e1c-a474-5e3ebe618253",
   "metadata": {},
   "source": [
    "## Image parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff31e546-6c37-4878-a743-2ca6def0135d",
   "metadata": {},
   "source": [
    "Images will be generated over $50$ diffusion steps. They will have a height and width of `512 x 512` pixels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb50e210-14ed-43a9-a44e-53bff5858db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of diffusion steps\n",
    "num_steps = 50\n",
    "\n",
    "# dimensions for v1 and v2 Stable Diffusions\n",
    "sd2_dims = {'height': 768, 'width': 768}\n",
    "sd_dims  = {'height': 640, 'width': 512} # goddess prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c06af74-23ee-4bc5-9015-a321ce540c2e",
   "metadata": {},
   "source": [
    "# Running the experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1711c3f2-1a7f-480d-95db-697af6ca74f3",
   "metadata": {},
   "source": [
    "We modify the `run` function to now load the Stable Diffusion model internally. This makes it easy to pass in and try different generators. We add a bit of GPU cleanup at the end to make sure there is enough memory for the models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc74e1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(pipeline, prompt, schedules,\n",
    "        guide_tfm=None, generator=None, show_each=False, test_run=False, gen_kwargs={}):\n",
    "    \"\"\"Runs a dynamic Classifier-free Guidance experiment. \n",
    "    \n",
    "    Generates an image for the text `prompt` given all the values in `schedules`.\n",
    "    Uses a Guidance Transformation class from the `cf_guidance` library.  \n",
    "    Stores the output images with a matching title for plotting. \n",
    "    Optionally shows each image as its generated.\n",
    "    If `test_run` is true, it runs a single schedule for testing. \n",
    "    \"\"\"\n",
    "    # store generated images and their title (the experiment name)\n",
    "    images, titles = [], []\n",
    "    \n",
    "    # make sure we have a valid guidance transform\n",
    "    assert guide_tfm\n",
    "    print(f'Using Guidance Transform: {guide_tfm}')\n",
    "    \n",
    "    # optionally run a single test schedule\n",
    "    if test_run:\n",
    "        print(f'Running a single schedule for testing.')\n",
    "        schedules = schedules[:1]\n",
    "        \n",
    "    # run all schedule experiments\n",
    "    for i,s in enumerate(schedules):\n",
    "        \n",
    "        # parse out the title for the current run\n",
    "        cur_title  = s['title']\n",
    "        titles.append(cur_title)\n",
    "        \n",
    "        # create the guidance transformation \n",
    "        cur_sched = s['schedule']\n",
    "        gtfm = guide_tfm({'g': cur_sched})\n",
    "        \n",
    "        print(f'Running experiment [{i+1} of {len(schedules)}]: {cur_title}...')\n",
    "        img = pipeline.generate(prompt, gtfm, **gen_kwargs)\n",
    "        images.append(img)\n",
    "        \n",
    "        # optionally plot the image\n",
    "        if show_each:\n",
    "            show_image(img, scale=1)\n",
    "            \n",
    "    print('Done.')\n",
    "    return {'images': images,\n",
    "            'titles': titles}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289e0000-7d87-4855-85ff-338a45828c22",
   "metadata": {},
   "source": [
    "# Gathering models and arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ab192f-3c28-4735-9308-24fb28c1a12c",
   "metadata": {},
   "source": [
    "Next we create the arguments and parameters to run different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c5e34b-5be8-4579-b4cb-769f49aa9386",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# group the different models to run\n",
    "model_expts = [\n",
    "\n",
    "    # SD v1-4\n",
    "    {'model_name': 'CompVis/stable-diffusion-v1-4',\n",
    "     'model_kwargs': {'better_vae': 'mse'}},\n",
    "    # SD v1-5\n",
    "    {'model_name': 'runwayml/stable-diffusion-v1-5',\n",
    "     'model_kwargs': {'better_vae': 'mse'}},\n",
    "    # openjourney\n",
    "    {'model_name': \"prompthero/openjourney\",\n",
    "     'model_kwargs': {}},\n",
    "    # SD 2-base\n",
    "    {'model_name': 'stabilityai/stable-diffusion-2-base',\n",
    "     'model_kwargs': {'unet_attn_slice': False}},\n",
    "    # # SD 2\n",
    "    # {'model_name': 'stabilityai/stable-diffusion-2',\n",
    "    #  'model_kwargs': {'unet_attn_slice': False}},\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cb8c5f-4249-4ae5-ba7c-a0e9a05b6deb",
   "metadata": {},
   "source": [
    "## Creating the baseline image with $G = 7.5$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d90f3d2-c18a-4d93-aed1-ce719c50158a",
   "metadata": {},
   "source": [
    "First we create the baseline image using a constant Classifier-free Guidance with $G = 7.5$. Since this is a constant schedule, $k$ does not come into play.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4993e135-cf67-4059-821d-203410fc925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the baseline schedule with the new function\n",
    "baseline_g = 7.5\n",
    "baseline_params = {'max_val': [baseline_g]}\n",
    "baseline_func = lambda *args, **kwargs: [baseline_g for _ in range(num_steps)]\n",
    "baseline_expts = create_expts(baseline_params, baseline_func)\n",
    "\n",
    "\n",
    "T_baseline_g = 0.15\n",
    "T_baseline_params = {'max_val': [T_baseline_g]}\n",
    "T_baseline_func = lambda *args, **kwargs: [T_baseline_g for _ in range(num_steps)]\n",
    "T_baseline_expts = create_expts(T_baseline_params, T_baseline_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c694195-9b18-435d-b467-998b20244b27",
   "metadata": {},
   "source": [
    "## Improving the baseline with schedules and normalizations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d261b6aa-1ce2-46e6-a9fd-d0141dc62a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = {}\n",
    "\n",
    "device = 'cuda'\n",
    "dtype = torch.float16\n",
    "\n",
    "for mparams in model_expts:\n",
    "    print(f'Running model: {mparams}')\n",
    "    \n",
    "    model_name = mparams['model_name']\n",
    "    model_kwargs = mparams['model_kwargs']\n",
    "    \n",
    "    # a bit of a manual patch, we need a keyword for openjourney model\n",
    "    if 'openjourney' in model_name:\n",
    "        cur_prompt = \"mdjrny-v4 style \" + prompt\n",
    "    else:\n",
    "        cur_prompt = prompt\n",
    "    print(f'Using prompt: {cur_prompt}')\n",
    "    \n",
    "    if model_name == 'stabilityai/stable-diffusion-2':\n",
    "        gen_kwargs = sd2_dims\n",
    "    else:\n",
    "        gen_kwargs = sd_dims\n",
    "    print(f'Generation kwargs: {gen_kwargs}')\n",
    "    \n",
    "    # load the current Diffusion model\n",
    "    pipeline = load_sd_model(model_name, device, dtype, generator=generator,\n",
    "                             model_kwargs=model_kwargs)\n",
    "    \n",
    "    # make the baseline for this model\n",
    "    baseline_res = run(pipeline, cur_prompt, baseline_expts, gen_kwargs=gen_kwargs,\n",
    "                       guide_tfm=GuidanceTfm, generator=generator)\n",
    "    outputs[(model_name,'baseline')] = baseline_res\n",
    "    \n",
    "    # generate images with different normalizations and schedules\n",
    "    base_norm_res = run(pipeline, cur_prompt, baseline_expts + all_k_expts, gen_kwargs=gen_kwargs,\n",
    "                        guide_tfm=BaseNormGuidance, generator=generator)\n",
    "    outputs[(model_name,'baseNorm')] = base_norm_res\n",
    "                            \n",
    "    T_res = run(pipeline, cur_prompt, T_baseline_expts + all_T_k_expts, gen_kwargs=gen_kwargs,\n",
    "                guide_tfm=TNormGuidance, generator=generator)\n",
    "    outputs[(model_name,'TNorm')] = T_res\n",
    "\n",
    "    full_res = run(pipeline, cur_prompt, T_baseline_expts + all_T_k_expts, gen_kwargs=gen_kwargs,\n",
    "                   guide_tfm=FullNormGuidance, generator=generator)\n",
    "    outputs[(model_name,'FullNorm')] = full_res\n",
    "    \n",
    "    # cleanup the model for the next run\n",
    "    del pipeline\n",
    "    pipeline = None\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fd42cf-5abd-4fe4-8f0a-d25669cc8dc5",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dec1e0-2525-4b15-876c-f507e620bb3d",
   "metadata": {},
   "source": [
    "Let's make some helpers to grab all output images for a given Stable Diffusion model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aad0d5-a319-4818-8904-70a9370ff6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# names of all the models we tried\n",
    "model_names = [\n",
    "    'CompVis/stable-diffusion-v1-4',\n",
    "    'runwayml/stable-diffusion-v1-5',\n",
    "    'prompthero/openjourney',\n",
    "    'stabilityai/stable-diffusion-2-base',\n",
    "]\n",
    "\n",
    "# number of images to plot\n",
    "num_runs = 2\n",
    "num_rows = 1\n",
    "\n",
    "# plot dimensions\n",
    "plot_height, plot_width = 640, 512\n",
    "\n",
    "def get_results(model_name):\n",
    "    types = ['baseline', 'baseNorm', 'TNorm', 'FullNorm']\n",
    "    return [outputs[(model_name,t)] for t in types]\n",
    "\n",
    "def plot_all_results(model_name):\n",
    "    mres = get_results(model_name)\n",
    "    for i in range(num_runs):\n",
    "        image_grid(\n",
    "            [mres[0]['images'][0]] + [o['images'][i] for o in mres[1:]], \n",
    "            title=[mres[0]['titles'][0]] + [o['titles'][i] for o in mres[1:]],\n",
    "            rows=num_rows, width=plot_width, height=plot_height\n",
    "        )\n",
    "        plt.suptitle(f'Model: {model_name} | Output #{i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3dbac1-5766-4f33-99ee-d436032b8e2c",
   "metadata": {},
   "source": [
    "# SD 1-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935cda8e-6ff3-46df-809b-644e1bafce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_results('CompVis/stable-diffusion-v1-4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a19c32a-8a4d-4ac3-9723-1784fcecdafa",
   "metadata": {},
   "source": [
    "# SD 1-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b0297a-ba15-4f66-9779-835f002af7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_results('runwayml/stable-diffusion-v1-5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee213437-67d0-49dc-bcb0-d7b887726812",
   "metadata": {},
   "source": [
    "# openjourney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8057996-d7e0-41e8-8245-b99b4783e42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_results('prompthero/openjourney')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde1faf7-e86f-4fab-8680-0a78567514f0",
   "metadata": {},
   "source": [
    "# SD 2-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cd5518-b1d8-4c10-a4a6-34a5c6b3ddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_results('stabilityai/stable-diffusion-2-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7d3315-4ade-41ff-9ba9-59d18e025768",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
