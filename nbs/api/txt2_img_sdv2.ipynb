{
 "cells": [
  {
   "cell_type": "raw",
   "id": "39a262fd-a0f5-48b8-bd55-96dced6d64bb",
   "metadata": {},
   "source": [
    "#| default_exp txt2img_sdv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714710df-5448-41d1-a36e-8b21c327bbf1",
   "metadata": {},
   "source": [
    "> Running dynamic CFG with the Stable Diffusion v2 model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5799b3-e47f-419d-b77a-3387b8108dae",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b4b9fa-8c0e-4a9e-9e0d-dc81ff12a939",
   "metadata": {},
   "source": [
    "This notebook is an initial exploration of dynamic Classifier-free Guidance using the new Stable Diffusion v2 model.  \n",
    "\n",
    "To leverage the best samplers, we also integrate the [k_diffusion](https://github.com/crowsonkb/k-diffusion/tree/master/k_diffusionhttps://github.com/crowsonkb/k-diffusion/tree/master/k_diffusion) library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b43dae-d6fb-41cf-b04c-256350bd2f2c",
   "metadata": {},
   "source": [
    "We start with a few python imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea1e75a0-0d64-436f-b9d8-d641393dca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import random\n",
    "from typing import Callable, List, Dict\n",
    "from functools import partial\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "# helpers to create cosine schedules\n",
    "from cf_guidance.schedules  import get_cos_sched\n",
    "# transformations for classifier-free guidance\n",
    "from cf_guidance.transforms import GuidanceTfm BaseNormGuidance, TNormGuidance, FullNormGuidance\n",
    "# to load Stable Diffusion pipelines\n",
    "from min_diffusion.core import MinimalDiffusion\n",
    "# to plot generated images\n",
    "from min_diffusion.utils import show_image, image_grid, plot_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a85966-1de8-472a-80c7-458ef0a3b78e",
   "metadata": {},
   "source": [
    "`seed_everything` makes sure that the results are reproducible across notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58d6c482-17da-41df-9605-4759b3281944",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# set the seed for rng\n",
    "SEED = 4191151944 \n",
    "def seed_everything(seed: int) -> torch.Generator:\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    generator = torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    return generator\n",
    "\n",
    "# for sampling the initial, noisy latents\n",
    "generator = seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a155d7-65f5-4ac7-be83-27755827bb84",
   "metadata": {},
   "source": [
    "# Text prompt for image generations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ec08b7-205e-4a3f-be1a-e74cf0e3dd76",
   "metadata": {},
   "source": [
    "Negative prompts appear to be very helpful in `v2`. At least, more helpful than they were for `v1.x` models.  \n",
    "\n",
    "Below, we also borrow a prompt and negative-prompt format that's going around the Stable Diffusion discord. It seems to be a good starting point as the community figures out the new prompt structures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9620a51c-3961-4c75-93af-9121d3938b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def cos_harness(default_params: dict, new_params: dict) -> dict:\n",
    "    '''Creates cosine schedules with updated parameters in `new_params`\n",
    "    '''\n",
    "    # start from the given baseline `default_params`\n",
    "    cos_params = dict(default_params)\n",
    "    # update the with the new, given parameters\n",
    "    cos_params.update(new_params)\n",
    "    \n",
    "    # return the new cosine schedule\n",
    "    sched = get_cos_sched(**cos_params)\n",
    "    return sched\n",
    "\n",
    "\n",
    "def create_expts(params: dict, schedule_func: Callable) -> List[Dict]:\n",
    "    '''Creates a list of experiments.\n",
    "    \n",
    "    Each element is a dictionary with the name, value, and schedule for a given parameter.\n",
    "    A `title` field is also added for easy plotting.\n",
    "    '''\n",
    "    names = sorted(params)\n",
    "    expts = []\n",
    "    # step through parameter names and their values\n",
    "    for i,name in enumerate(names):\n",
    "        for j,val in enumerate(params[name]):\n",
    "            # create the experiment\n",
    "            expt = {'param_name': name,\n",
    "                    'val': val,\n",
    "                    'schedule': schedule_func(new_params={name: val})}\n",
    "            # name for plotting\n",
    "            expt['title'] = f'Param: \"{name}\", val={val}'\n",
    "            # add it to the experiment list\n",
    "            expts.append(expt)\n",
    "    return expts\n",
    "\n",
    "\n",
    "# text prompt for image generations\n",
    "prompt = \"((an armored winged valkyrie charges into the fray of battle)), ((by Oswaldo Guayasamin)), studio lighting, High quality, professional, dramatic, cinematic movie still, very detailed, character art, concept art, focused, subsurface scatter\"\n",
    "prompt = \"the eternal, cosmic Mother. The Source. The eternal truth that we are all connected. we are all loved. we are all one. Love through genuine hope and authenticity. a full and complete rediscovery of the Self. hyperbolic consciousness\"\n",
    "\n",
    "\n",
    "# a good negative prompt\n",
    "neg_prompt = \"ugly, stock photo, tiling, poorly drawn hands, poorly drawn feet, poorly drawn face, out of frame, mutation, mutated, extra limbs, extra legs, extra arms, disfigured, deformed, cross-eye, body out of frame, blurry, bad art, bad anatomy, blurred, text, watermark, grainy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb50e210-14ed-43a9-a44e-53bff5858db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of diffusion steps\n",
    "num_steps = 30    \n",
    "\n",
    "# larger image dimensions\n",
    "height = 1024 # 768\n",
    "width  = 1024 # 768\n",
    "\n",
    "# set the k-diffusion scheduler\n",
    "use_k_diffusion  = 'k_dpmpp_sde'\n",
    "hf_scheduler_kls = 'dpm_multi' # NOTE: only used for alpha_cumprod at the moment\n",
    "\n",
    "# whether to use the Karras sigma schedule\n",
    "use_karras_sigmas = True\n",
    "\n",
    "# group the argument for generate function\n",
    "gen_kwargs = {\n",
    "    'height': height,\n",
    "    'width': width, \n",
    "    'negative_prompt': neg_prompt, \n",
    "    'steps': num_steps,\n",
    "    'use_karras_sigmas': use_karras_sigmas,\n",
    "}\n",
    "\n",
    "# Default schedule parameters from the blog post\n",
    "######################################\n",
    "baseline_g        = 8    # default, static guidance value\n",
    "max_val           = 9    # the max scheduled guidance scaling value\n",
    "min_val           = 6    # the minimum scheduled guidance value\n",
    "num_warmup_steps  = 0    # number of warmup steps\n",
    "warmup_init_val   = 0    # the intial warmup value\n",
    "num_cycles        = 0.5  # number of cosine cycles\n",
    "k_decay           = 1    # k-decay for cosine curve scaling \n",
    "\n",
    "\n",
    "# group the default schedule parameters\n",
    "DEFAULT_COS_PARAMS = {\n",
    "    'max_val':           max_val,\n",
    "    'num_steps':         num_steps,\n",
    "    'min_val':           min_val,\n",
    "    'num_cycles':        num_cycles,\n",
    "    'k_decay':           k_decay,\n",
    "    'num_warmup_steps':  num_warmup_steps,\n",
    "    'warmup_init_val':   warmup_init_val,\n",
    "}\n",
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4993e135-cf67-4059-821d-203410fc925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the baseline schedule with the new function\n",
    "baseline_params = {'max_val': [baseline_g]}\n",
    "baseline_func = lambda *args, **kwargs: [baseline_g for _ in range(num_steps)]\n",
    "baseline_expts = create_expts(baseline_params, baseline_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fe94d2d-47e6-490d-a491-affa4c1920c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the inverse kDecay cosine schedules\n",
    "k_decays = [0.1, 0.2, 0.3, 0.5]\n",
    "inv_k_params = {'k_decay': k_decays}\n",
    "inv_k_func = partial(cos_harness, default_params=DEFAULT_COS_PARAMS)\n",
    "inv_k_expts = create_expts(inv_k_params, inv_k_func)\n",
    "\n",
    "# invert the schedules to turn them into a type of warmup \n",
    "##TODO: move into the scheduler helper\n",
    "for s in inv_k_expts:\n",
    "    s['schedule'] = [max_val - g + min_val for g in s['schedule']]\n",
    "\n",
    "# put all schedules together\n",
    "all_k_expts = inv_k_expts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67c5e34b-5be8-4579-b4cb-769f49aa9386",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# group the different models to run\n",
    "diffusion_runs = [\n",
    "\n",
    "    # Stable Diffusion 2\n",
    "    {'model_name': 'stabilityai/stable-diffusion-2',\n",
    "     'model_kwargs': {\n",
    "         'unet_attn_slice': True,\n",
    "         'scheduler_kls':   hf_scheduler_kls,\n",
    "         'use_k_diffusion': use_k_diffusion,\n",
    "         'generator':       generator,\n",
    "    }},\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "941fbfca-e503-4207-9a41-d23fb89695af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc74e1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sd_model(model_name, device, dtype, revision, model_kwargs={}):\n",
    "    '''Loads the given `model_name` Stable Diffusion in `dtype` precision.  \n",
    "    \n",
    "    The model is placed on the `device` hardware. \n",
    "    The optional `generator` is used to create noisy latents.  \n",
    "    Optional `model_kwargs` are passed to the model's load function.\n",
    "    '''\n",
    "    pipeline = MinimalDiffusion(model_name, device, dtype, revision, **model_kwargs)\n",
    "    pipeline.load()\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def run(pipeline, prompt, schedules, gen_kwargs={},\n",
    "        guide_tfm=None, generator=None, show_each=False, test_run=False):\n",
    "    \"\"\"Runs a dynamic Classifier-free Guidance experiment. \n",
    "    \n",
    "    Generates an image for the text `prompt` given all the values in `schedules`.\n",
    "    Uses a Guidance Transformation class from the `cf_guidance` library.  \n",
    "    Stores the output images with a matching title for plotting. \n",
    "    Optionally shows each image as its generated.\n",
    "    If `test_run` is true, it runs a single schedule for testing. \n",
    "    \"\"\"\n",
    "    # store generated images and their title (the experiment name)\n",
    "    images, titles = [], []\n",
    "    \n",
    "    # make sure we have a valid guidance transform\n",
    "    assert guide_tfm\n",
    "    print(f'Using Guidance Transform: {guide_tfm}')\n",
    "    \n",
    "    # optionally run a single test schedule\n",
    "    if test_run:\n",
    "        print(f'Running a single schedule for testing.')\n",
    "        schedules = schedules[:1]\n",
    "        \n",
    "    # run all schedule experiments\n",
    "    for i,s in enumerate(schedules):\n",
    "        \n",
    "        # parse out the title for the current run\n",
    "        cur_title  = s['title']\n",
    "        titles.append(cur_title)\n",
    "        \n",
    "        # create the guidance transformation \n",
    "        cur_sched = s['schedule']\n",
    "        gtfm = guide_tfm({'g': cur_sched})\n",
    "        \n",
    "        print(f'Running experiment [{i+1} of {len(schedules)}]: {cur_title}...')\n",
    "        with torch.autocast('cuda'):\n",
    "            img = pipeline.generate(prompt, gtfm, **gen_kwargs)\n",
    "        images.append(img)\n",
    "        \n",
    "        # optionally plot each generated image\n",
    "        if show_each:\n",
    "            show_image(img, scale=1)\n",
    "            \n",
    "    print('Done.')\n",
    "    return {'images': images,\n",
    "            'titles': titles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d261b6aa-1ce2-46e6-a9fd-d0141dc62a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: {'model_name': 'stabilityai/stable-diffusion-2', 'model_kwargs': {'unet_attn_slice': True, 'scheduler_kls': 'dpm_multi', 'use_k_diffusion': 'k_dpmpp_sde', 'generator': <torch._C.Generator object at 0x7f446e41bc90>}}\n",
      "Generation kwargs: {'height': 1024, 'width': 1024, 'negative_prompt': 'ugly, stock photo, tiling, poorly drawn hands, poorly drawn feet, poorly drawn face, out of frame, mutation, mutated, extra limbs, extra legs, extra arms, disfigured, deformed, cross-eye, body out of frame, blurry, bad art, bad anatomy, blurred, text, watermark, grainy', 'steps': 30, 'use_karras_sigmas': True}\n",
      "Using prompt: the cosmic, eternal truth that we are all connected. we are all loved. we are all one. embracing and enveloping in warmth, love. hope and authenticity. an integration of the Self. hyperbolic consciousness\n",
      "Enabling default unet attention slicing.\n",
      "Using scheduler: <class 'diffusers.schedulers.scheduling_dpmsolver_multistep.DPMSolverMultistepScheduler'>\n",
      "Using Guidance Transform: <class 'cf_guidance.transforms.GuidanceTfm'>\n",
      "Running experiment [1 of 1]: Param: \"max_val\", val=8...\n",
      "Using negative prompt: ugly, stock photo, tiling, poorly drawn hands, poorly drawn feet, poorly drawn face, out of frame, mutation, mutated, extra limbs, extra legs, extra arms, disfigured, deformed, cross-eye, body out of frame, blurry, bad art, bad anatomy, blurred, text, watermark, grainy\n",
      "NOTE: Generating with k-diffusion Samplers: k_dpmpp_sde\n",
      "Using Karras sigma schedule\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cde0c6381ad42209d4ae61c35a4422c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Using Guidance Transform: <class 'cf_guidance.transforms.GuidanceTfm'>\n",
      "Running experiment [1 of 4]: Param: \"k_decay\", val=0.1...\n",
      "Using negative prompt: ugly, stock photo, tiling, poorly drawn hands, poorly drawn feet, poorly drawn face, out of frame, mutation, mutated, extra limbs, extra legs, extra arms, disfigured, deformed, cross-eye, body out of frame, blurry, bad art, bad anatomy, blurred, text, watermark, grainy\n",
      "NOTE: Generating with k-diffusion Samplers: k_dpmpp_sde\n",
      "Using Karras sigma schedule\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be940ddd74347b29de10d546c2c8566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment [2 of 4]: Param: \"k_decay\", val=0.2...\n",
      "Using negative prompt: ugly, stock photo, tiling, poorly drawn hands, poorly drawn feet, poorly drawn face, out of frame, mutation, mutated, extra limbs, extra legs, extra arms, disfigured, deformed, cross-eye, body out of frame, blurry, bad art, bad anatomy, blurred, text, watermark, grainy\n",
      "NOTE: Generating with k-diffusion Samplers: k_dpmpp_sde\n",
      "Using Karras sigma schedule\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5e70edf4a64044b47e796aba970533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment [3 of 4]: Param: \"k_decay\", val=0.3...\n",
      "Using negative prompt: ugly, stock photo, tiling, poorly drawn hands, poorly drawn feet, poorly drawn face, out of frame, mutation, mutated, extra limbs, extra legs, extra arms, disfigured, deformed, cross-eye, body out of frame, blurry, bad art, bad anatomy, blurred, text, watermark, grainy\n",
      "NOTE: Generating with k-diffusion Samplers: k_dpmpp_sde\n",
      "Using Karras sigma schedule\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "349ef3f8d58342e494b14df4309bac77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment [4 of 4]: Param: \"k_decay\", val=0.5...\n",
      "Using negative prompt: ugly, stock photo, tiling, poorly drawn hands, poorly drawn feet, poorly drawn face, out of frame, mutation, mutated, extra limbs, extra legs, extra arms, disfigured, deformed, cross-eye, body out of frame, blurry, bad art, bad anatomy, blurred, text, watermark, grainy\n",
      "NOTE: Generating with k-diffusion Samplers: k_dpmpp_sde\n",
      "Using Karras sigma schedule\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2ff185777b4175a722f6b5c8f2800c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# stores the generated images\n",
    "outputs = {}\n",
    "\n",
    "# load the model on the GPU in full precision\n",
    "device = 'cuda'\n",
    "dtype = torch.float16\n",
    "revision = \"fp16\"\n",
    "\n",
    "# step through the Diffusion models\n",
    "for dparams in diffusion_runs:\n",
    "    # parse out model name and its custom args\n",
    "    model_name   = dparams['model_name']\n",
    "    model_kwargs = dparams['model_kwargs']\n",
    "    \n",
    "    # view some info about the run\n",
    "    print(f'Running model: {dparams}')\n",
    "    print(f'Generation kwargs: {gen_kwargs}')\n",
    "    print(f'Using prompt: {prompt}')\n",
    "    \n",
    "    # load the current Diffusion model\n",
    "    pipeline = load_sd_model(model_name, device, dtype, revision, model_kwargs=model_kwargs)\n",
    "    \n",
    "    # run the baseline, static Guidance\n",
    "    baseline_res = run(pipeline, prompt, baseline_expts, gen_kwargs=gen_kwargs,\n",
    "                       guide_tfm=GuidanceTfm, generator=generator)\n",
    "    outputs[(model_name,'baseline')] = baseline_res\n",
    "    \n",
    "    # run the scheduled Guidances\n",
    "    base_norm_res = run(pipeline, prompt, all_k_expts, gen_kwargs=gen_kwargs,\n",
    "                        guide_tfm=GuidanceTfm, generator=generator)\n",
    "    outputs[(model_name,'scheduled')] = base_norm_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fd42cf-5abd-4fe4-8f0a-d25669cc8dc5",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73aad0d5-a319-4818-8904-70a9370ff6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "\n",
    "# names of all the models we tried\n",
    "model_names = [\n",
    "    'stabilityai/stable-diffusion-2',\n",
    "]\n",
    "\n",
    "# plot dimensions\n",
    "plot_height, plot_width = height, width\n",
    "# for the grid layout\n",
    "num_scheds = 4\n",
    "num_rows = 1\n",
    "\n",
    "def get_results(model_name):\n",
    "    types = [\n",
    "        'baseline', \n",
    "        'scheduled', \n",
    "    ]\n",
    "    return [(outputs[(model_name,t)], t) for t in types]\n",
    "\n",
    "def plot_all_results(model_name):\n",
    "    mres = get_results(model_name)\n",
    "    for i in range(num_scheds):\n",
    "        image_grid(\n",
    "            [mres[0][0]['images'][0]] + [o[0]['images'][i] for o in mres[1:]], \n",
    "            title=[mres[0][0]['titles'][0]] + [f\"{o[0]['titles'][i]}_{o[1]}\" for o in mres[1:]],\n",
    "            rows=num_rows, width=plot_width, height=plot_height\n",
    "        )\n",
    "        suptitle = \"Inverse-kDecay Cosine\" if i else \"Constant\"\n",
    "        plt.suptitle(f'Model: {model_name} | {suptitle} Schedule')\n",
    "        \n",
    "# plot_all_results('stabilityai/stable-diffusion-2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
