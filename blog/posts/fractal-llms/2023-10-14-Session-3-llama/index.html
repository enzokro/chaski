<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Chris Kroenke">
<meta name="dcterms.date" content="2023-10-14">

<title>chaski - Running LLMs with llama.cpp</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<link href="../../../../favicon.png" rel="icon" type="image/png">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Rosarivo">
<meta property="og:title" content="chaski - Running LLMs with llama.cpp">
<meta property="og:description" content="">
<meta property="og:image" content="https://enzokro.dev/blog/posts/fractal-llms/2023-10-14-Session-3-llama/llama-cpp-logo.png">
<meta property="og:site-name" content="chaski">
<meta property="og:image:height" content="640">
<meta property="og:image:width" content="1280">
<meta name="twitter:title" content="chaski - Running LLMs with llama.cpp">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="https://enzokro.dev/blog/posts/fractal-llms/2023-10-14-Session-3-llama/llama-cpp-logo.png">
<meta name="twitter:image-height" content="640">
<meta name="twitter:image-width" content="1280">
<meta name="twitter:card" content="summary_large_image">
</head><body class="nav-fixed"><header id="custom-site-header" class="custom-nav page-columns page-rows-contents"> 
    <nav class="custom-nav-content">
        <div class="navbar-brand-container">
            <a class="navbar-brand" href="http://enzokro.dev/">
                <span class="navbar-title custom-title">Chaski</span>
            </a>
        </div>
    </nav>
    <div class="custom-nav-sidebar">
        <div id="quarto-search" title="Search"></div>
    </div>
</header>


<link rel="stylesheet" href="../../../../styles.css">




<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../../../index.html">
    <span class="navbar-title">chaski</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/enzokro_" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/enzokro" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#intro" id="toc-intro" class="nav-link active" data-scroll-target="#intro">Intro</a></li>
  <li><a href="#llama.cpp" id="toc-llama.cpp" class="nav-link" data-scroll-target="#llama.cpp">llama.cpp</a></li>
  <li><a href="#running-mistral-v0.1-with-llama.cpp" id="toc-running-mistral-v0.1-with-llama.cpp" class="nav-link" data-scroll-target="#running-mistral-v0.1-with-llama.cpp">Running Mistral-v0.1 with llama.cpp</a>
  <ul class="collapse">
  <li><a href="#building-llama.cpp" id="toc-building-llama.cpp" class="nav-link" data-scroll-target="#building-llama.cpp">Building llama.cpp</a></li>
  <li><a href="#downloading-a-mistral-v0.1-model" id="toc-downloading-a-mistral-v0.1-model" class="nav-link" data-scroll-target="#downloading-a-mistral-v0.1-model">Downloading a Mistral-v0.1 model</a></li>
  <li><a href="#running-the-mistral-model" id="toc-running-the-mistral-model" class="nav-link" data-scroll-target="#running-the-mistral-model">Running the Mistral model</a></li>
  </ul></li>
  <li><a href="#running-mistral-v0.1-with-python" id="toc-running-mistral-v0.1-with-python" class="nav-link" data-scroll-target="#running-mistral-v0.1-with-python">Running Mistral-v0.1 with python</a>
  <ul class="collapse">
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/enzokro/chaski/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Running LLMs with llama.cpp</h1>
  <div class="quarto-categories">
    <div class="quarto-category">fractal</div>
    <div class="quarto-category">python</div>
    <div class="quarto-category">LLM</div>
  </div>
  </div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Chris Kroenke </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">October 14, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<blockquote class="blockquote">
<p>Building llama.cpp and running a Mistral-v0.1 model.</p>
</blockquote>
<section id="intro" class="level1">
<h1>Intro</h1>
<p>This notebook runs an LLM using the <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a> library. Specifically we run the powerful, recently released <a href="https://mistral.ai/news/announcing-mistral-7b/"><code>Mistral-7B-Instruct-v0.1</code></a> model.</p>
</section>
<section id="llama.cpp" class="level1">
<h1>llama.cpp</h1>
<p>llama.cpp is designed to run quantized LLMs on a Mac. Despite its name, the project supports many other models beyond Llama and Llama-2. There are even <a href="https://github.com/abetlen/llama-cpp-python">python bindings</a> to make our lives easier.</p>
<p>The picture below comes from project’s README, and shows low-level details about how the repo works and what it supports.</p>
<p><img src="llama_description.png" class="img-fluid"></p>
<p>llama.cpp was originally hacked together in a <a href="https://github.com/ggerganov/llama.cpp/issues/33#issuecomment-1465108022">single evening</a>, and has since become arguably the SOTA for deploying LLMs on CPUs. This is in large part thanks to the incredibly helpful and responsive community behind it.</p>
<p>Below we can see the full list of models that llama.cpp supports as of writing.</p>
<p><img src="llama_model_support.png" class="img-fluid"></p>
<p>The benefits of llama.cpp go beyond its code or models. Folks are always collaborating in <a href="https://github.com/ggerganov/llama.cpp/pulls">Pull Requests</a> to bring in the latest, greatest advances from the flood of LLM progress. Tracking these PRs is a great way of keeping up to date with the field. Thankfully, the community is very open to hackers and new ideas: if something works and there’s proof, then it gets merged in.</p>
<p>Next, let’s use llama.cpp to run a <code>Mistral-v0.1</code> model.</p>
</section>
<section id="running-mistral-v0.1-with-llama.cpp" class="level1">
<h1>Running Mistral-v0.1 with llama.cpp</h1>
<p>In this section we cover the following:<br>
- Installing the <code>llama.cpp</code> repo<br>
- Downloading a <code>Mistral-v0.1</code> model<br>
- Running the model directly with <code>llama.cpp</code><br>
- Running the model in a Jupyter Notebook</p>
<p>First, we create a mamba environment to keep our work isolated. Then we download and install the repo.</p>
<p>Next we download the actual Mistral model from the HuggingFace Model Hub.</p>
<p>Lastly, we run the Mistral model on a sample input.</p>
<section id="building-llama.cpp" class="level3">
<h3 class="anchored" data-anchor-id="building-llama.cpp">Building llama.cpp</h3>
<p>Let’s get started. First create a new python3.11 mamba environment:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create an environment for llama.cpp</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="ex">mamba</span> create <span class="at">-n</span> llama-cpp python=3.11</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This isn’t <em>strictly</em> necessary for llama.cpp since it uses C++. But we will need it later on for the python bindings. And in any case, it’s best practice to keep our projects in isolated environments.</p>
<p>Next activate the new environment:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># activate the environment</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="ex">mamba</span> activate llama-cpp</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Then go ahead and clone the repo. Once it’s cloned, we can move inside it and prepare for the build.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># clone and move into the llama.cpp repo</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">git</span> clone https://github.com/ggerganov/llama.cpp</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> llama.cpp</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>There are two options to build llama.cpp:<br>
- <a href="https://www.gnu.org/software/make/">GNU Make</a><br>
- <a href="https://cmake.org/">CMake</a></p>
<p><code>make</code> works great on Linux, but I’ve had mixed results on Mac. For that reason we’ll stick with <code>CMake</code> instead.</p>
<p>The safest bet is to grab the CMake installer from the <a href="https://cmake.org/download/">official site</a> and run it. But any reasonable package manager for Mac and Linux (e.g.&nbsp;<code>brew</code> or <code>apt</code>) should also work.</p>
<p>With CMake installed we can now follow a standard build process. Start by creating and moving into a special <code>build/</code> folder:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create a build directory and move into it</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mkdir</span> build</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> build</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Then run the <code>cmake</code> command to prepare the build. We can also specify special build options. For example, on Mac we can pass the <code>LLAMA_METAL=1</code> flag to use the GPU, or on Linux we can pass the <code>LLAMA_CUBLAS=1</code> flag to use an NVIDIA GPU.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># prepare the llama.cpp build with Mac hardware acceleration</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cmake</span> <span class="at">-DLLAMA_METAL</span><span class="op">=</span>1 ..</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># # or, use the line below on Linux/Window to build for NVIDIA GPUs</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># cmake -DLLAMA_CUBLAS=1 ..</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>With the setup files ready, we can now build the project with the command below:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># build the accelerated llama.cpp project</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cmake</span> <span class="at">--build</span> . <span class="at">--config</span> Release </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Once the build finishes, the output binaries will be inside the <code>build/bin</code> folder. This folder has an executable binary file called <code>main</code>. <code>main</code> is how we’ll be calling llama.cpp to run LLMs.</p>
<p>We are now ready to grab the Mistral model.</p>
</section>
<section id="downloading-a-mistral-v0.1-model" class="level2">
<h2 class="anchored" data-anchor-id="downloading-a-mistral-v0.1-model">Downloading a Mistral-v0.1 model</h2>
<p>We will run a <code>Mistral-7B-Instruct-v0.1</code> model. What exactly does its name mean? Let’s breakdown it down a bit: - <code>Mistral</code> is the name given by the developers, in this case the <a href="https://mistral.ai/">Mistral.ai team</a> - <code>7B</code> means that the model has 7 billion parameters<br>
- <code>Instruct</code> means that it was trained to follow and complete user instructions<br>
- <code>v0.1</code> is the release version for this model</p>
<p>Below is the link to the model in the HuggingFace Hub</p>
<blockquote class="blockquote">
<p>HuggingFace link to <a href="https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF"><code>Mistral-7B-Instruct-v0.1</code></a></p>
</blockquote>
<p>Follow the link above, then click on the <code>Files and version</code> tab near the top. You’ll see a list of models that were quantized in different ways:</p>
<p><img src="mistral_quantized.png" class="img-fluid"></p>
<p>These names can be overwhelming. Let’s break them down at a high level. Feel free to skim the next couple of paragraphs, they are not critical to running the model itself.</p>
<p>You can see that each file ends with a format like this: <code>Q*_*.gguf</code>. For example one model from the list is: <code>mistral-7B-Instruct-v0.1.Q4_K_S.gguf</code>. The <code>Q4</code> part means that the model was quantized with 4-bits. The <code>K_S</code> part refers to the specific flavor of quantization that was used.</p>
<p>There is an unfortunate tradeoff between quantization and performance. The fewer bits we use, the smaller and faster the model will be but the worse its performance. And the more bits we use, the better its performance but the slower the model. In general, the <code>Q4</code> and <code>Q5</code> models offer a good balance between speed, performance, and size. Now let’s get back to running the model.</p>
<p>We choose the <code>Q5_K_M</code> model which is a bit larger than the <code>Q4</code> models but makes up for it in performance.</p>
<p>To grab this model, first make sure the huggingface-hub CLI is installed:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># install a tool to download HuggingFace models via the terminal</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install huggingface-hub</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Then move into the <code>models/</code> folder inside of the llama.cpp repo and download the model with the following command:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># download the Mistral Q5_K_M model</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="ex">huggingface-cli</span> download TheBloke/Mistral-7B-Instruct-v0.1-GGUF <span class="dt">\</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    mistral-7b-instruct-v0.1.Q5_K_M.gguf <span class="dt">\</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">--local-dir</span> . <span class="dt">\</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">--local-dir-use-symlinks</span> False</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Once the model has downloaded, we are ready to run it.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># from build/, run the official example to see Mistral-v0.1 in action</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="ex">./bin/main</span> <span class="at">-m</span> ../models/mistral-7b-instruct-v0.1.Q5_K_M.gguf <span class="dt">\</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">-p</span> <span class="st">"Building a website can be done in 10 simple steps:\nStep 1:"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="running-the-mistral-model" class="level2">
<h2 class="anchored" data-anchor-id="running-the-mistral-model">Running the Mistral model</h2>
<p>We’ll use the <code>main</code> binary inside of the <code>build/</code> folder from before to run the <code>Q5_K_M</code> model.</p>
<p>Run the following command to see the Mistral LLM in action! Here we ask to tell us how to build a website in 10 steps.</p>
<p>The <code>-m</code> flag points to the model file, which we stored under <code>models/</code>. The <code>-p</code> flag is the prompt for the model to follow.</p>
<p>Here’s a short snippet from my output after running the command:</p>
<pre><code>Building a website can be done in 10 simple steps:

Step 1: Choose a domain name. A domain name is the unique address of your website on the internet, which is what people will use to find it. Consider choosing a name that reflects the purpose or brand of your website.

Step 2: Choose a hosting provider. Your website needs to be hosted by a server so that it can be accessed by others on the internet. Choose a reliable hosting provider that suits your budget and technical needs.

Step 3: Install a content management system (CMS). A CMS is software that allows you to create, manage and publish content on your website without needing to know how to code. Examples of popular CMS platforms include WordPress, Drupal, and Joomla.</code></pre>
<p>And that’s it! We have now done the following:<br>
- Installed llama.cpp.<br>
- Downloaded a Mistral-v0.1 model.<br>
- Ran the Mistral model on a sample input.</p>
<p>Everything so far was done in C++. Next we run the Mistral model inside a Jupyter Notebook with the llama.cpp python bindings.</p>
</section>
</section>
<section id="running-mistral-v0.1-with-python" class="level1">
<h1>Running Mistral-v0.1 with python</h1>
<p>Start by installing the llama.cpp python bindings in the mamba environment.</p>
<p>Here are the instructions for the full <a href="https://github.com/abetlen/llama-cpp-python/blob/main/docs/install/macos.md">Mac installation</a>. The pair of pip commands below will install the bindings.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># install the python bindings with Metal acceleration</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> uninstall llama-cpp-python <span class="at">-y</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="va">CMAKE_ARGS</span><span class="op">=</span><span class="st">"-DLLAMA_METAL=on"</span> <span class="ex">pip</span> install <span class="at">-U</span> llama-cpp-python <span class="at">--no-cache-dir</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The command above does the following to make sure the python bindings are up to date:<br>
- Uninstalls older versions of the bindings, if any are found.<br>
- Installs the bindings with Metal (Mac GPU) acceleration.</p>
<p>After installing the bindings, run the following code snippet. This will check if the bindings were installed correctly.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># check if we can import the llama.cpp python bindings </span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> llama_cpp <span class="im">import</span> Llama</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>If the command above works, we can now run the Mistral-v0.1 model inside a Jupyter Notebook. We instantiate the <code>Llama</code> class by pointing it to the model weights we downloaded earlier. Make sure to change the paths to match your own.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># point the Llama class to the model weights we downloaded in the previous sections</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>work_dir <span class="op">=</span> <span class="st">"/Users/cck/repos/llama.cpp/"</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>llm <span class="op">=</span> Llama(<span class="ss">f"</span><span class="sc">{</span>work_dir<span class="sc">}</span><span class="ss">/models/mistral-7b-instruct-v0.1.Q5_K_M.gguf"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># asking Mistral to help us build a website</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> <span class="st">"Building a website can be done in 10 simple steps:</span><span class="ch">\n</span><span class="st">Step 1:"</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>output <span class="op">=</span> llm(prompt, max_tokens<span class="op">=</span><span class="dv">512</span>, echo<span class="op">=</span><span class="va">True</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-overflow-wrap code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>output[<span class="st">'choices'</span>][<span class="dv">0</span>][<span class="st">'text'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>'Building a website can be done in 10 simple steps:\nStep 1: Define the Purpose of Your Website\nBefore you start building your website, it’s important to determine its primary purpose. This may include selling products or services, promoting a business or organization, providing information, or entertaining visitors.\nStep 2: Choose Your Web Design\nNext, decide on the design and layout of your website. This can include selecting a template or creating a custom design. Consider using a responsive design that adjusts to different screen sizes.\nStep 3: Purchase a Domain Name\nChoose a domain name that is easy to remember and reflects your brand. Register it with a domain registrar like GoDaddy or Namecheap.\nStep 4: Choose a Hosting Provider\nA web host provider will store your website files and make them available to visitors. Some popular options include Bluehost, HostGator, and DreamHost.\nStep 5: Create Your Website Content\nCreate the content for your website, including text, images, and videos. Use clear and concise language that is easy to read. Make sure to optimize your content for search engines (SEO) by using relevant keywords.\nStep 6: Design and Develop Your Website\nUsing a website builder or content management system (CMS) like WordPress, design and develop your website. Customize the layout, color scheme, and fonts to match your branding.\nStep 7: Test Your Website\nBefore launching your website, test it thoroughly to make sure everything is working properly. This includes checking for broken links, ensuring that forms are functioning correctly, and testing on different devices.\nStep 8: Launch Your Website\nOnce you’re satisfied that your website is ready, launch it to the public. Promote your website through social media, email marketing, and other channels to attract visitors.\nStep 9: Monitor and Update Your Website\nKeep an eye on your website analytics to see how visitors are interacting with your site. Use this information to make updates and improvements to your website as needed.\nStep 10: Keep Your Website Secure\nFinally, keep your website secure by regularly updating software, using strong passwords, and implementing security measures like SSL certificates and firewalls.'</code></pre>
</div>
</div>
<p>Congrats! We’ve now ran the <code>Mistral-7B-Instruct-v0.1</code> model with llama.cpp in both C++ and python. The C++ version is ideal for a server or production application. And as for python version, we can now bootup a handy LLM assistant in a Jupyter Notebook, and ask it questions as we code or develop.</p>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>This notebook covered the llama.cpp library and how to use it to run LLMs. We then ran a <code>Mistral-7B-Instruct-v0.1</code> model with llama.cpp in both C++ and python.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="enzokro/chaski_comments" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->



</body></html>