{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Syllabus: Fractal-U Course on LLMs\"\n",
    "author: \"Chris Kroenke\"\n",
    "date: \"09/25/2023\"\n",
    "toc: true\n",
    "badges: true\n",
    "categories: [fractal, python, LLM]\n",
    "image: fractal-llm-mascot.png\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Overview and motivations for the Fractal-U LLM Course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this course, we will create our own AI Assistant. The assistant will be created by augmenting and fine-tuning an open-source Large Language Model (LLM).  \n",
    "\n",
    "So what exactly is an AI Assistant, and why would we want to make one?  \n",
    "\n",
    "There is a lot of hype around AI Assistants at the moment. Folks are imagining a future where we all have powerful, personalized helpers at our fingertips. These Assistants promise to make our lives easier and more comfortable. They will be the AIs of Science Fiction made manifest: TARS from Interstellar, HAL 9000 from Space Odyssey, Iron Man's Jarvis, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realistic Assistants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the breakneck speed of LLM progress, AI Assistants as powerful as those are still a ways off. The exact timelines are hard, if not impossible, to predict. For now it is safe to say that Assistants of that caliber won't be here anytime \"soon\". But, barring some force majeure, they *will* exist at some point.   \n",
    "\n",
    "The gap, then, is between the advanced Assistants folks are promising and dreaming about, and the LLM hallucinations and steep compute requirements we are still dealing with one the ground.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an AI Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Where does that leave us? Well, as a recent announcement [from OpenAI](https://twitter.com/gdb/status/1694107518488981868) shows, fine-tuning a GPT-3.5 model on small, clean datasets can even surpass GPT-4 on certain tasks.  \n",
    "\n",
    "*That's* what we are aiming for. In other words, we already have the ability to develop outrageously powerful tools by fine-tuning LLMs on small, clean datasets.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So while we won't make Iron Man's Jarvis, we are aiming for far more than a simple chatbot. Think of our Assistant like a smart Rubber Duck. For reference, a Rubber Duck is anything that you keep around your desk and talk to about your work. It is a physical tool for thought, since it's so often helpful to speak out loud the swirl of thoughts inside our heads.  \n",
    "\n",
    "Our simple Assistant will be a Rubber Duck that we can talk to, and that talks back. When we ask it a question about our work, it will respond given what it knows about the project as a whole. Or, if we are simply verbalizing a thought to untangle it, the Assistant can give us feedback or suggest other ideas.  \n",
    "\n",
    "If we can be so bold: our Assistant will be a mini-Jarvis laser-focused on a specific task. Then, as both the tools and field progresses, we will have a full development stack ready to unlock even more capabilities from this smart Rubber Duck."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Course Summary: We will fine-tune and augment an LLM on a small, clean dataset to build an Intelligent Rubber Duck.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each lesson lives inside a Jupyter Notebook. The notebooks build on each other, but they are also  self-contained and reviewable on their own.   \n",
    "\n",
    "\n",
    "Here is an outline of the lessons:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Python environments for LLMs**  \n",
    "\n",
    "> Using mamba and pip to create isolated, reproducible python environments.   \n",
    "\n",
    "**2. Blogging with nbdev**    \n",
    "\n",
    "\n",
    "> Setting up a blog with nbdev and github pages.    \n",
    "\n",
    "**3. Running HuggingFace NLP models**    \n",
    "\n",
    "> Using the HuggingFace API to run NLP models.\n",
    "\n",
    "**4. Running optimized LLMs with llama.cpp**    \n",
    "\n",
    "> Running quantized, optimized LLMs.      \n",
    "\n",
    "**5. Processing text documents for LLMs**    \n",
    "\n",
    "> Preparing text data for fine-tuning and Retrieval Augmented Generation (RAG)    \n",
    "\n",
    "**6. Fine-tuning LLMs on a GPU**    \n",
    "\n",
    "> Scripts to efficiently fine-tune LLMs    \n",
    "\n",
    "**7. Running fine-tuned LLMs locally on your phone**    \n",
    "\n",
    "> Deploying fine-tuned, quantized LLMs on mobile devices   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a public-facing course. Students should write about their journey to both cement and track their progress.  \n",
    "\n",
    "Publishing is a powerful tool for learning since it casts a piece of work under a new, critical light. Your understanding of a topic is also crystallized by seeing other's work, highlighted from different angles. \n",
    "\n",
    "Blogging out in the open can be scary, but here we aim to make it as easy and helpful as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course Philosophy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter Notebooks are the modern, programming version of field journals. The inspirational samples from [this Wired article](https://www.wired.com/2011/07/science-field-notes-gallery/) below show what science, at its best and most alive, can be:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](field-notes-butterflies.jpg)\n",
    "![](field-notes-grinnell.jpg)\n",
    "![](field-notes-lynx.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's focus on the last example: the field notes about a lynx. Notice that we're not reading a long description of what a Lynx is *supposed* to look like. And we're not looking at a series of diagrams without context either. We're getting the best of both worlds: short and relevant descriptions right next to clear, working examples. Field notes bridge the gap between the written, theoretical and the actual, practical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebooks can do for code what the field notes above did for the lynx. We can interactively show people the data, describe what's being done, and make sure that the results are correct. We can even show any mistakes and struggles along the way.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tight loop between what you're doing (*code*), describing what you're doing (*documentation*), and making sure it's correct (*tests*) is a great way to approach research. More than that, it is an incredibly powerful way to communicate and share ideas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each lesson is like an interactive field journal. You should feel as if someone is walking you through an experiment, going step by step and talking through the process along the way. And you should feel like an active participant in the research: you can always modify a cell or insert new ones to try out your own ideas.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook introduced our goals and approach for the Fractal-U LLMs course. In summary, we will fine-tune and augment an open-source LLM to create a simple AI Assistant that can help us better learn and create."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you for coming along on this journey! I promise that we will learn a ton, and have lots of fun along the way.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
